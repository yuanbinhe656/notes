## 目录

- 2021 / 9 /
- 2021 / 9 /
    - 词法分析...........................................................................................................................
    - Token串的定义................................................................................................................
    - 用正则语言描述Token....................................................................................................
    - MaximalMunch（最大吞噬原则）................................................................................
- 2021 / 9 /
    - 用DFA判定属于哪个token集合...................................................................................
    - 用描述token的正则表达式来构造NFA........................................................................
    - NFA转化为DFA................................................................................................................
    - 用查表来描述一个DFA...................................................................................................
    - 压缩DFA的状态数量......................................................................................................
    - 让DFA支持MaximalMunch和PriorityRule.................................................................
    - Lex工具.............................................................................................................................
- 2021 / 9 /
    - 语法分析...........................................................................................................................
    - 用上下文无关文法(CFG)来描述语法..............................................................................
    - CFG的歧义.......................................................................................................................
    - 递归下降法构造parsetree.............................................................................................
- 2021 / 9 /
    - 左递归和消除左递归.......................................................................................................
    - LL( 1 )...................................................................................................................................
    - LL( 1 )的ParsingTable.........................................................................................................
    - LL( 1 )Parsing算法.............................................................................................................
    - 构造LL( 1 )ParsingTable....................................................................................................
    - First集合和Follow集合..................................................................................................
    - 出错处理...........................................................................................................................
    - LRParser............................................................................................................................
- 2021 / 10 /
    - Shift和Reduce.................................................................................................................
    - LR( 1 )...................................................................................................................................
    - LR( 1 )item..........................................................................................................................
- 2021 / 10 /
    - LALR( 1 ):合并LR( 1 )的DFA状态.......................................................................................
    - 语法分析工具yacc...........................................................................................................
    - AST.....................................................................................................................................
- 2021 / 10 /
    - 语法分析工具Bisonc++...................................................................................................
- 2021 / 10 /
    - SymbolTable...................................................................................................................
- 2021 / 10 /
    - TypeChecking..................................................................................................................
- 2021 / 10 /
    - Tiger中的递归声明........................................................................................................
    - Tiger中的递归函数调用...............................................................................................
    - ActivationRecord（Frame）..........................................................................................
- 2021 / 10 /
    - Displays............................................................................................................................
    - Access..............................................................................................................................
    - EscapeAnalysis................................................................................................................
- 2021 / 11 /
    - TreeLanguage.................................................................................................................
    - Expression.......................................................................................................................
    - Statement........................................................................................................................
- 2021 / 11 /
    - 数组和Record的翻译...................................................................................................
- 2021 / 11 /
    - 第八章：BasicBlocksandTraces...................................................................................
    - CanonicalForm................................................................................................................
- 2021 / 11 /
    - 第九章：InstructionSelection.......................................................................................
    - MaximalMunch（局部最优）......................................................................................
- 2021 / 11 /
- 2021 / 11 /
    - ProcEntryExit
    - ProcEntryExit
    - GlobalOptimization........................................................................................................
    - 变量活跃的条件.............................................................................................................
    - 死码删除.........................................................................................................................
    - LivenessAnalysis：数据流方程.....................................................................................
    - 常数传播.........................................................................................................................
    - 常数传播的八条规则.....................................................................................................
    - 常数传播算法.................................................................................................................
    - 常数传播算法的中止性.................................................................................................
- 2021 / 11 /
    - InterferenceGraph..........................................................................................................
    - Kempe’sAlgorithm..........................................................................................................
    - ActualSpill（寄存器溢出）...........................................................................................
    - Briggs算法......................................................................................................................
    - George算法....................................................................................................................
    - ConstrainedMove（受限的Move操作）...................................................................
- 2021 / 11 /
    - 在Tiger中寄存器分配的实现......................................................................................
    - ControlFlowGraph.........................................................................................................
- 2021 / 12 /
    - 在Tree上做寄存器分配................................................................................................
- 2021 / 12 /
    - MarkandSweep..............................................................................................................
    - MarkAndSweep的开销................................................................................................
    - ExplicitStack....................................................................................................................
    - PointerReversal..............................................................................................................
    - ReferenceCount..............................................................................................................
    - Deferreducingthereferencecount................................................................................
    - RC的性能开销高...........................................................................................................
    - RC不能解决相互引用的问题.......................................................................................
    - Copy算法........................................................................................................................
    - Cheney’sAlgorithm.........................................................................................................
- 2021 / 12 /
    - CopyCollection的开销..................................................................................................
    - GenerationalGarbageCollection....................................................................................
    - IncrementalCollection（增量回收）............................................................................
    - Baker’sAlgorithm............................................................................................................
- 2021 / 12 /
    - GC的实现.......................................................................................................................
    - DataLayoutDescription..................................................................................................
    - ExactRootDescription....................................................................................................
    - ModernGCinJava..........................................................................................................
- 2021 / 12 /
    - Fun-tiger..........................................................................................................................
    - 闭包（Closure）.............................................................................................................
    - PureFun-Tiger..................................................................................................................
    - ImmutableVariables（不可变形）...............................................................................
    - Continuation-basedI/O..................................................................................................
- 2021 / 12 /
    - inlineexpansion..............................................................................................................
    - UnnestingLet..................................................................................................................
    - ClosureConversion..........................................................................................................
    - EfficientTailConversion..................................................................................................
    - LazyTiger.........................................................................................................................
- 2021 / 12 /
    - Call-by-need....................................................................................................................
    - Lazy函数式程序的优化.................................................................................................
    - 单一继承.........................................................................................................................
    - 多重继承.........................................................................................................................
- 2021 / 12 /
    - GlobalGraphColoring.....................................................................................................
    - MembershipTesting........................................................................................................
- 2021 / 12 /
    - De-virtualizing.................................................................................................................
    - MoreC++.........................................................................................................................
    - RAII（ResourceAcquisitionisInitialization）................................................................

### 2021 / 9 / 14

#### 编译核心来做就是拿到一个源程序(C/JAVA/...)编译成目标程序，当然编译可能不通过，会出

现需要fix的error/warning。

#### 源语言通常算是比较高级的语言，C语言其实可以内联汇编，是比较低级的程序。ML是这

本书的作者偏爱的语言。这些语言是偏函数式的。Verilog(FPGA,小板子编程)。

目标语言通常是机器的语言：汇编语言、二进制语言（可执行文件中的 0 和 1 ）。用objdump  
可以dump出来汇编代码，这两个是等价的。目标语言也可以是高级语言，这就是sourceto  
sourcecompiler。比如把其他语言翻译成js，来放到web里去跑；或者把web代码部署到安  
卓上去运行。编译器的种类是很多的，和源语言、目标语言的多样性有关。

不同的编译器结构：  
Single-pass 走一轮就结束了，现在比较少了，通常来说编译的源语言和机器码差别是很大的，  
各种各样的类型都不存在了，过程是比较复杂度。  
multi-pass市面上的大部分编译器  
Load-and-go像用IDE，点一下run就执行完成了。把程序直接映射到内存里运行。把编译  
和执行的边界就模糊掉了。对内存要求比较高，因为要把生成的多个文件直接放进内存里。  
Debugging：调试器也有编译的内容，比如单步执行可以模拟代码执行，这就需要知道代码  
在做什么

Optimizaing：需要分析代码，知道语义，再去做针对性的优化。也会用到编译的结构。

Basic解释器，它是一行行读入解析的。读一行模拟执行一行。这就不像gcc中生成可执行  
文件再去执行。

编译是整体把程序编成了一个可执行的东西，再去执行。解释器和编译器差别比较大，但是  
在解释的时候也会用到一些编译的思路。像Python，是翻译成了中间表达，再去解释执行。

Compiler的历史，第一个compiler是 1953 年......

我们用的是虎书，还有一个比较有名的是龙书。虎书的guided多一点。第一部分就是自己  
写一个编译器，第二部分就是内存管理、面向对象语言设计、函数式语言设计、后端优化的  
介绍。

这是一个lab，我们定义了一个简单语言，没有分支，一条条执行了看，有赋值、输出、  
可以用分号隔开来执行，有expression包含加减乘除变量etc。认为每个指令都是有值的。  
Statement是没有返回值的，expression是有返回值。Expressionsequence要求最后一个指令  
一定是expression。

因为expression或者一个代码块是有返回值的，可以作为一个返回值赋值给别人。  
怎么去定义这个语言呢？这里就需要用到词法和文法。在学英文的时候，词法就是字母  
表有哪些。计算机语言相对比较严谨，词法通常使用正则表达式。语法可以来定义哪些指令  
是允许的和不合规的指令。

对于这个语言，文法定义是比较简单的。竖线表示的是或。Vocabulary对应的是变量和  
数字。\*表示 0 个或多个。在别的地方，+表示 1 个或多个。

#### 语法的基本结构左边表示需要解析的一个符号，右边就是解析出来的结果。我们会给不

#### 同的推导命名。

```
CompoundStm(混合statement)
ExpList可以传入一个表达式的list，变长print。
Binop：加减乘除
```

#### 我们简单给了一个上下文无关文法的定义，在第三章会详细结束。

Token（终结符，terminalsymbol）：不能再继续推导的内容，比如加减乘除、括号  
非终结符：可以继续推导的符号，比如explist。  
我们的语法就是包含了推导规则，左边是非终结符，右边数终结符和非终结符。并且要  
求给定一个开始推导的符号。  
Eg：

#### 更简洁的写法：

#### 第二个问题：怎么内部表示一个程序

#### 编译器的基本结构:大体也可以分成前端（分析，把源代码编译成中间表达）和后端（合

#### 成）

#### 一个递归向下的树的结构。

#### 我们可以把树的结构和语言对应起来。

使用c++写lab，比如说compound是有一个构造器。

两个工作： 1 .写一个maxargsprint最多包含了多少个argument，比如print(explist)，注意在  
expressionlist可能会分裂成更多的expression，需要递归判定

2. 解释，把程序通过解释的方法去执行一下。对不同的结构需要写不同的interp函数。

实现lab 1 需要的东西，symboltable，对应的一个是映射，变量id到数字(int)的映射。  
已经实现好了这样的一个表，有一个tail把它们连起来。核心函数就是lookup（拿到key找  
value）和update（放到table里去）

在解释的时候用到这个table，只需要拿这个statement去做相应的解释。我们不希望有  
side-effect，也就是我们不会去修改已有的值。也就是straight-lineprograminterpreter不依赖  
硬件去执行，比如我们赋值c= 7 ，那么在所有硬件和操作系统，都应该c= 7 。

#### 给定一个树，每个子树有我们定义的虚函数执行一下，最终执行根节点。值得一提的是

interp的返回值是一个table和一个int（存的是返回值），我们维护的就是这么一个环境，  
表达的是变量和值之间的映射。

#### 类型和方法：首字母大写，上驼峰；变量：下划线。

第三部分：怎么把源语言转化为Internal.  
刚才我们看到的树（AST），有了这个以后我们怎么做转化呢？涉及到scanner（词  
法分析）和parser（文法分析）

Source传过来只是一个个字符，通过scanner就识别出了其中的token，给到parser就  
会根据我们定义的语法规则，生成中间表达，也就是我们的抽象语法树。

为什么是preliminary，是比较原始的。如果a只有可能是 0 和 1 ，并且后面有一句if(a>  
2 )，那么后端检测到以后就可以去掉，而在前端里面只是最简单的存储。  
比如a:=a- 1 ，分解成a赋值再一个a- 1 ，scanner可以得到a的类型。换句话说scanner

的责任就是把字符映射到终结符(token)，做完词法分析以后，对语法分析来说没什么差别。  
因为格式被整理过了。

很多c++的错误是语法分析的错误，还有一些是语义分析的错误（类型、强制转换）。  
语法分析器还会尝试做一些errorcorrection，为的不是通过编译，而是为了找到后面的bug，  
尽可能一次性把所有的语法分析都报告出来。这里要提的是parsergenerator，现在的parser  
是自动生成的，需要给的就是语法规则。

后端职责：拿到前端的中间表达转成机器码，需要给每个中间表达选择instruction。我  
们希望尽可能把所有的东西都存到寄存器里，这就是寄存器分配，后端编译器优化比较重要  
的方面。最后一个就是要和systeminterface兼容，有些平台无关的语言（java）就要为不同  
的硬件去适配接口，需要后端完成。所以目前后端还是很少有在做自动化的东西。

Source到target差距实在是太远了，所以拆成两个IR，把High-level的IR（接近源代码，  
还原了source中的语义）转化为 low-level的IR（接近target，里面会有move，load之类的  
指令）。最终我们通过codegen转化为机器码。实际的编译器可能更加复杂，就有多层IR，  
随着结构复杂，对IR的需求也会不一样。

#### 这里给了一个优化器的介绍，我们之前都在讲前端的词法分析和文法分析。优化器的目

标就是分析IR和改变IR，就是在树上不断地做遍历，找到一些匹配的pattern去做优化。优  
化本质就是效率导向的模块。这里的目标是优化不能违反原本程序的语义，需要preserve  
原先的value。

```
这个是课程的flow，元编译器通过parse后面有语义分析和中间检查。......
```

### 2021 / 9 / 17

#### 今天讲第二章，我们先要讲一下虎书

#### 编译有三本书，第一本是龙书，是两个图灵奖写的，是用的比较多的一本编译书，但是

#### 读完以后写不来编译器。

```
我们这本书的作者自己设计了一个tigerlanguage，
```

#### 很多东西都是一个表达式，函数式的语言。前边这部分就是一个定义，定义完了以后去

执行try。主体比较简单，大头在前面的定义部分，var是变量的定义，type是类型的定义，  
还定义了两个函数printboard和try。这个例子在我们树上的例子有，也就是用tigerlanguage  
来模拟八皇后问题。里面有控制语句也有循环结构。:=赋值，=判等。在tiger中只有两个  
build-intype，int和string，因为这是一个教学用的语言，所以为了保持简单性，没有浮点数

及其计算。intArray实际上就是整数数组，row和col在tiger中都是一维数组。print函数和  
C的概念差不多，属于标准库。

第二个例子是mergesort这个例子，里面有更复杂的类型。之前看到的数组和整数，这  
里我们看到结构这样的类型。Getchar()是标准库中得到一个字符，就有字符串变量buffer。  
如果有返回值，返回值是写在函数名字后面的:int，并且函数可以嵌套，里面的函数的作用  
域只在里面有效。在ICS中，i要么应该是栈上的局部变量，i要么是全局变量。这里i也应  
该在栈上的，理论上另一个函数应该是没有办法访问到的。在C中是没有碰到过的，而在  
tiger中会作为一个问题。  
List就是一个record结构类型，l是类型为list的变量。nil就是一个空指针。在tiger中  
没有显式的pointer变量声明，而在此array变量和record都是指针。我们在C中如果说一  
个变量是一个structrue，array代表了这个首地址，而structure代表了内存中的一块东西。  
这里就是判定一个array或者一个record有没有初始化。Tiger语言复杂的都在let这部分。  
一有let就可以在let中定义一些东西，再把函数体写在in这部分。这本书附录对tiger的描  
述需要大家多多去翻。

Tiger语法上的情况，比如tiger中支持递归的数据类型和支持的函数调用。比如我们要  
定义一个二叉树或者定义一个链表，我们经常会使用递归的方式去定义。在tiger中定义，  
必须是两个东西挨着的。Tree的儿子的节点构成了一个链表。这边的递归我们可以看到，自  
己和自己递归，在定义tree的时候用到了treelist，在定义treelist的时候用到了tree，tiger  
要求这两个是互相挨着的，我们之后会学到这样要求会使得处理起来相对简单一点。同样的，  
函数递归调用。Treeleaves调用treelistleaves，而treelistleaves调用treeleaves，这也要求两  
个函数挨在一起。

上节课我们讲过，给一个sourceprogram，出来一个汇编。前端：把source变成计算机  
更加容易处理的数据结构。比如lab 1 中变成了一个tree和一个table，这就在计算机上非常  
容易做了。我们从第二章~第五章，我们要做的事情就是把程序变成树和表，让程序自动来  
做。在自动做的时候，又分成两步。一步是词法分析，现在我们的sourceprogram是一个字  
符串的序列，然后经过词法分析要变成一个token序列（变量、函数都是token），把没有  
意义的字符串序列变成有意义的单词序列，再把词法分析出来的单词接口变成段落文章，这  
部分就是语法分析。

#### 在这个过程中，经常拼错或者少一个分号之类的，所以会报错会有一个出错处理的机制，

#### 碰到错误以后希望能够容忍这个错误继续编译下去找到更多的错误报告给用户。

### 词法分析...........................................................................................................................

词法分析要把字符串序列变成token序列，我们下面的词法分析就是两件事情

1. 划分，tab是没有用的，if是一个对象，==又是一个pattern，我们要把这样的序列  
    做一个切分，然后做一个分类。
2. 分类，比如tab、空格、回车都是没用的东西，i、j、z都属于变量，if、else都属  
    于关键字。

所以我们词法分析好以后，把原来的一串字符串变成了一个token串，它相当于是一个  
类型，和自然语言中的名词、动词、形容词，然后就可以分出主谓宾、定语状语之类的。在  
程序设计语言中，比如有identifier，keyword，integer，relation(==),whitespace(tab,space,  
enter)。我们把字符串变成token串以后，对于我们的语法分析就很重要。我们的语法分析  
是基于这个token串来做的。

### Token串的定义................................................................................................................

什么叫做token呢？Token是字符串的集合。Tiger中的变量（identifier）一定要是字母  
开头的，keyword是tiger中自己规定的。每个集合就是一个token  
Lexeme是集合当中的一个元素，所以我们前面看到的第一步划分出来的时候，i、j、==  
都是集合中的一个元素，这就是lexeme。分类以后就是token。所以词法分析出来得到的就  
是一个token和lexeme。  
Non-token就是我们的注解的一些宏定义，就需要用预处理去处理掉。在tiger中，  
comments是可以嵌套的，允许/_/__/_/的嵌套匹配。

```
下面我们就要来讲怎么实现这件事情。
```

划分出substring，以及lexeme属于的那一类，然后把这个返回给parser。我们再以刚  
才的字符串为例

这个就是我们第二个lab，给大家这样的一个字符串序列，大家要做的事情就是把这样的一  
个token-lexeme串生成出来，大家还要处理nontoken之类的东西。  
在我们识别出来了这些东西以后，为了改善我们程序的可读性，我们认出的东西如果会  
直接扔掉。只会传递下去有意义的东西。我们能不能先做一些预处理，比如先把comments  
和whitespace先处理掉呢？答案：有些程序是可以的，有些程序是不行的。比如在C中，  
一个字符串中放了一个\\_，在另一个字符串里头放了一个_//，如果我们在预处理的时候把  
中间的都去掉了，也不是那么容易去掉的。

比如上例的空格如果被处理掉了，本来应该出错的地方就编译通过了。Fortran里头是，  
有没有这个空格没事，一概会被处理掉。

Do就是一个for， 5 就是一个label，到了label这个地方就结束了。因为空格会自动去  
除，如果把逗号写成了句号，就会把循环写成一个DO 5 I的变量赋值  
下边我们要来分割字符串，然后分类分成token，token就是一个字符串的集合，这个  
字符串要么是一个有限的集合，要么是字母开始的变量，要么数字开头的非空数字串。我们  
用这样的自然语言来描述token，我们希望用形式化的方法来描述token，也就是正则语言、  
上下文无关文法。

### 用正则语言描述Token....................................................................................................

我们先用regularlanguage来描述token。Regularlanguage很简单也很有用，易于理解和  
实现。

Tiger语言所有允许的字符都会出现在这个字母表中。

#### 英语中字典中的单词是合法的，其他单词是不合法的。程序设计中也是这样。

#### 在正则语言当中，语言首先是字符串的集合。下面对于我们词法分析比较重要，首先这

#### 个字符串是不是属于一个合法的字符串，如果合法那它属于哪一类。把合法的字符串怎么识

别怎么分类，就用到了regularexpression来描述这样一个东西。正则表达式是正则语言的一  
个notation，A是一个表达式，它所描述出来的那些字符串，就是一个语言。正则表达式和  
正则语言相当简单，

第一类正则表达式就是singlecharacter，有两个正则表达式，其实的就是singlecharacter。  
Concatenation:A和B就是，A中的字符串和B中的字符串连在一起，也是我们的正则语言。

第三个就是Union，A|B也是一个正则语言。这样我们就可以把之前构造出来的keyword  
用union放在一起变成了一个keyword的集合。

刚才表达出来的表达式都是有限的，要定义一个无限的，就是用repetition（星号）规  
则。

这样就可以写出一个keyword这样的一个regularexpression。

整数是一个非空的数字串，可以空的数字串就是digit_，要保证非空就要在前头加一个digit。  
后面可以跟任意多的数字。我们可以用A+来替代AA_

Identifier：字母开头，后面可以跟任意多的字母和数字。

Whitespace包含空格、tab和回车

用regularexpression可以描述我们日常生活中比较简单的东西，比如电话号码。这只是形式  
上合法，并不是任意三个组合都是一个有效的电话号码。

```
我们下面要知道词法分析怎么做。
```

1. 先要定义number、keyword、identifier，也就是tiger语言中有哪些词法成分。
   
2. 用regularexpression定义token。
   
3. 然后整个语言合法的子串写了有限个，这些合到一起都是我们合法的substring。下  
    面我们还要做一件事情。一个字串是不是合法的会有方法来判定。如果s属于L(R)，就判断  
    这个s是合法的字串。编译器里一定要落实到哪一个子类Ri。
    
4. 比如我们输入一个串 _x_ 1 ,, _xn_ ，如果 _x_ 1 ,, _xi_  _L_ ( _R_ )，一定 _x_ 1 ,, _xi_  _L_ ( _Rj_ )，
   

一边做一边remove掉这些东西。

### MaximalMunch（最大吞噬原则）................................................................................

#### 有了这些过程，我们来看以下这个例子

我们碰到F一定是和identifiermatch的，一个个匹配完remove掉。最后我们就识别好了。  
是不是真的这么简单呢？  
我们尝试换一个输入

如果f匹配了直接remove，就会出问题，我们发现到了foo还是，还是foo+不是了。我们  
还要尽量往后看，这就不是正则语言能干的事情了。Maximalmunch规则，也就是如果都属  
于L(R)的话，我们要选择更长的。

第二件事情，我们要把这个语言改一改，加了一个keyword叫做new，new既满足keyword  
还满足identifier。当同时满足的时候，我们选择前边的这个，也就是优先级规则，需要在规  
则中制定好优先级。

最后是处理出错的情况，出错的字符串属于哪里呢？我们要在规则中加一个Errortoken，不  
在前头的东西就属于error。

我们要做词法分析的时候，首先要用正则表达式来把token精确地描述出来，描述完了  
以后要做一个extension，我们要知道词法规则是若干个union出来的。分类的时候就会有一  
些二义性，需要用到maximalmunch和priorityrule。这样的话把我们的词法的描述，以及在  
识别的过程中碰到问题怎么处理讲清楚了。  
接下来，给你一个字符串怎么判断属于这个集合。判定这件事情，我们用的就是有限自  
动机。

#### 自动机首先有一个字母表、状态集合、初始状态、一个终止状态集合、状态的转移。

### 2021 / 9 / 24

```
上节课我们说可以用regularexpression来标识我们的词法，我们下面的问题转换成了：
```

### 用DFA判定属于哪个token集合...................................................................................

给定一个regularexpressionL(R)，我们要判定这个字符串是不是属于这个regular  
expression的定义中。这时候我们就要引入自动机（automaton）。接下来我们会讨论怎么  
通过这个regularexpression自动化生成代码，会介绍自动化工具。今年得图灵奖的两位aho  
和ullman，当年在自动化这个方面做了很多的工作。然后就是maximalmunch和priorityrule，  
我们需要加入这些extensionrule。

**DFA** 的定义

#### 自动机在这里就是一个五元组：一个字母表，一个状态，开始状态，接收状态的集合

_F_  _S_ 和transition。

```
系统在状态s 1 的时候接收到字符a，就转换到了状态s 2 。输入是一串字符串走到
最后，如果进入了一个acceptstate，这个输入就被这个自动机接收了，那么字符串就
属于这个自动机对应的regularlanguage了。
```

Eg：一个只接受“ 1 ”的正则语言对应的自动机

Eg：只接受一串 1 之后跟了一个 0 的有限自动机

比如接收 1110 ，而 11101 就会reject 0 后的 1

**NFA** 的定义

一个有限自动机接收的是从start\_state出发一个个状态走，最终走到acceptstate的字  
符串。刚才这些例子，在一个状态上，我们看到一个字符以后，transition是确定的。我们  
看如下的这样一个自动机。这时候就会有不一样了，在start\_state的时候看到 1 有两种  
transition。

这也是一类自动机，但是和之前的transition确定的情况是不一样的。而且我们在两个  
状态之间加上一个转移。说明可以不接收字符就可以无条件从A转移到B。

上面这两种就是我们的NFA（nondeterministicfiniteautomata）。不管是DFA还是NFA，  
都是一个非常简单的计算模型，我们在实现的时候，只需要当前状态和input就可以决定我  
们的动作，和之前无关，同时状态的数量也是有限的。

来了 0 之后，我们就会有多个transition，可以同时处于这两个状态。再来一个 1 ，如果  
在左边状态，那么就继续停在原地，而中间状态的状态接收到 1 了以后就可以到acceptstate。  
所以 101 就是这个NFA可以接收的字符串。

#### 结论 1 ：NFA和DFA能够识别的东西是相同的。

结论 2 ：DFA写出来的代码是很容易的，只需要n\*n的一张transition表就可以了。  
a 1 ...... am  
S 1  
...... S’  
Sn  
也就是Si和aj可以转化到S’状态，一张表查表就可以了。

查表的程序是一样的，我们只需要自动生成这张表就可以了。我们声明的regular  
expression，直接构造DFA会比较困难，我们可以先用regularexpression来构造NFA。  
Eg：识别同一个语言的NFA和DFA比较，DFA的transition会比较复杂一些。

#### 同一个NFA变成DFA的时候，有可能其状态会指数增长。

### 用描述token的正则表达式来构造NFA........................................................................

下边我们来看一下，我们用regularexpression来描述词法，描述好词法以后，我们希望  
用这个regularexpression来构造出NFA，再转化成DFA，然后就变成一个查表判定的过程。

Regularexpression也就是 5 个构造的法则。

1. 法则
2. singlecharacter  
    图上一根线代表进去的地方，后面有一个状态。我们假设regularexpressionA的图是这  
    样，B是对应下图的那样。Cat法则就是结束节点连一根线到下一个的开始状态。

Union我们就使用连起来。  
A_的话就是在acceptstate能够非确定性地转移到开始，当然空字符串也可以识别。所  
以要再加一根的线。  
这样我们就可以把一个regularexpression画出一个NFA的状态转移图。  
考虑正则表达式( 1 | 0 )_ 1

最后把图画完以后，我们再把start和final加进去，有了这两个才真正把图变成了状态  
转移图。这就是我们把一个regularexpression变成一个NFA的过程。

### NFA转化为DFA................................................................................................................

#### 接下来我们要把NFA变成DFA，NFA是不确定的不可能是查表的过程，所以我们要转化

为DFA再进行查表。在NFA中一个Input会同时到好几个状态中去，我们用DFA中模拟NFA  
的这个过程，模拟过程中DFA的状态是NFA的状态的子集（若干个状态，non-emptysubset  
ofstatesofNFA）。NFA同时到几个状态的时候，DFA中就是一个状态。  
构造出来的DFA的初始状态是什么？NFA看似初始状态只有一个，其实开始状态能够  
到达的状态都记为DFA的初始状态。  
从一个状态S接收一个字符a到另一个状态S’，我们要看看碰到每个字母表中的字符会  
变到哪里去，从而增加状态转移。

#### 按照这个步骤执行肯定是可以把一个NFA转换成DFA的，只是可能指数爆炸。

### 用查表来描述一个DFA...................................................................................................

#### 用表来描述一个DFA

#### 上表中，横轴是字符集合，纵轴是状态集合。

有了这个表以后，我们就从start\_state开始一个个字符走，比如我们在状态i接收到了字符  
a，直接查T\[i,a\]=k跳转到状态k即可。如果走到一半的时候走不下去了，也是reject。

我们有一些自动化的工具，一般叫做lex，比如flex和jlex。也就是我们写regular  
expression，它会生成NFA,DFA，DFA的表，然后我们就可以进行查表判定。实际上有时候  
DFA会比较大，也不一定要完全变成一个DFA，可以中间自己多记录几个状态。

### 压缩DFA的状态数量......................................................................................................

正规式->最小化DFA说明 https://zhuanlan.zhihu.com/p/ 37900383

#### NFA变DFA的状态会有很多，我们希望对DFA的状态进行化简一下，压缩一下状态。

#### 比如说我们有上面的这个DFA，有 7 个状态ABCDEF。要做化简实际上是做一个等价类，也

就是说当我们状态S 1 能够接收字符串s的时候，S 2 也能接收s。  
一开始我们可以把自动机的状态分成两类:

1. 非终结状态(non-final)集合
2. 终结状态集合

#### \===MINIMIZE==>

#### 步骤如下：

1. 将Ｍ的状态分为两个子集一个由终态 _k_ 1 { _C_ , _D_ , _E_ , _F_ }组成，一个由非终态

_k_ 2 { _S_ , _A_ , _B_ }。

2. 考察 _k_ 2 { _S_ , _A_ , _B_ }是否可分，因为状态A读到a之后到达了状态 _C_  _k_ 1 ，而状态

S和状态B读到a之后到达状态 _A_  _k_ 2 ，所以可以分成 _k_ 3 { _S_ , _B_ }和 _k_ 4 { _A_ }

3. 考察 _k_ 3 { _S_ , _B_ }是否继续可分，因为S读到b之后到达状态 _B_  _k_ 3 而B读到了b

之后到达状态 _D_  _k_ 1 ，所以可以继续拆分成 _k_ 5 { _S_ }和 _k_ 6 { _B_ }

4. 我们继续考察 _k_ 1 { _C_ , _D_ , _E_ , _F_ }是否可分，因为C,D,E,F读到a和b都是转移到 _k_ 1 ，

所以 _k_ 1 不再可分。我们可以选用其中的一个状态来代替所有状态，比如我们选择D。

```
5. 重新连接对应的边即可。
```

```
Regularexpression->NFA->DFA->Table这就是一个table-driven的algorithm。
```

```
因为我们的词法分析不是回答yes/no的事情，它的specification是这样写的
R  R 1 | R 2 |...| Rn | error ，而我们输入的是x 1 x 2 ...xn，我们是要切割出x 1 x 2 ...xk，判断它
```

是不是属于 _L_ ( _Ri_ )，还要满足maximalmunch和priorityrule。已经落到某一类的时候，我们

需要继续往前走来找到更长的符合条件的情况。  
所以刚才那个table我们只是有了一个基础的这个东西，我们要把这个东西扩展，扩展  
成我们的词法可以用的这个东西。

### 让DFA支持MaximalMunch和PriorityRule.................................................................

#### 这就是一个词法

分别keyword(if),identifier(返回ID),number,实数，注解（两个”--”+一串字母+\\n，或者space,  
\\n,tab），错误（如果前面的都不能匹配，就报错了）

现在我们Input：if--not-a-com  
到if--not都能识别，但是-a我们不能识别出来，就报错了。

这么 5 ~ 6 个regularexpression，画出来的图是这样的。

#### 14 期末考试，给 3 个正则表达式画一下这张图。期中考试就是画这种图，两个小时三道题。

#### 这个过程需要练习一下。

#### 我们现在有了这张图以后，我们需要识别输入的字符串。我们需要增加一些状态。

因为我们碰到maximalmunch，比如i进入到了id的acceptstate，我们不能直接作为结  
果，读到f以后就变成了keyword，如果读到了if 0 ，那么它又是一个identifier。所以我们要  
继续读到后面。我们遇到if后的空格时，自动机报错我们就要回退。上一次进入final的时  
候，我们要记录一下。一开始是三者合一的工字型。一旦到了 2 以后，就有：

```
因为maximalmunch，我们需要继续往前走。
```

#### 这时候空格转移不出去，我们就报错了。所以我们只要知道|和T之间的时候，我们就

可以说这之间的是我们的lexeme。所以我们只要知道 3 这里的token是if即可。然后我们继  
续回退空格，从空格开始继续走状态机。

我们回退到-即可，输出space为token。

#### 我们退回到第一个横杠，就报错。退回到 9 的情况：

报错两次以后，我们就会认为not是一个identifier，-是一个错，a是一个identifier，-继续  
报错，com是一个identifier。

```
所以在实际执行的时候，我们需要有三个position才能实现往前走+回退的机制。这是
```

maximalmunch需要的事情。  
第二个事情是我们的priority-rule。

显然abb是a\*b+的子集，但是abb优先，同时进入 4 和 6 作为acceptstates的时候，应该  
是 4 优先，因为 4 的优先级高。我们把NFA画成DFA。

#### 有问题的就是{ 4 , 6 }这个状态，到了这个状态的时候，同时是 4 和 6 的时候我们只能是 4 ，需

#### 要在最后这个DFA中去掉优先级较低的 6 。注意前面压缩DFA的时候不能随便压缩了。

### Lex工具.............................................................................................................................

#### 到这里，我们工具的原理都讲完了，我们也处理了两条规则。

```
接下来我们来介绍lex工具。
```

我们写代码的时候还是写一串declearation，我们还需要写一串花括号。报错的时候我  
们要往前走。我们不但要有识别，我们还要做一些动作。花括号里的东西都是C程序。

我们写一些declearation（regularexpression）和action（C），有一个简单的编译器生  
成C代码。生成了C以后，就可以放到编译器里头，编译出可执行的文件。a.out就是输入  
一个tigerprogram，通过a.out运行以后能就变成了一个token串。

Lex分成三个部分：

1. 第一个部分是%{...%} 这是我们的一串C代码。有include，也会定义一些union。  
    Tokens.h就会定义一些token的类型。因为我们的每个token有一个lexeme（真正的字符串  
    是什么），对于tokennumber的话，一个lexeme是真正要变成一个整数值的。Identifier、  
    if的话就是变成字符串，实数的话要变成double。不同token的lexeme是不一样的，我们  
    就用到了一个yylval这个union，里面可能是整数、字符串或double。还有我们当前character  
    的这个位置，一开始都是 1 ，每一次可以调整。可以算当前吃到的lexeme有多长。调整的  
    话就是error的地方。
2. 第二部分就是lexdefinition，可以定义一些宏，比如用digits替换掉\[ 0 - 9 \]+
3. 第三部分就是两个%%开始，把我们的regularexpression一行行写出来，每个后面

都有一个action。if的话直接往前走；identifier，除了继续往前走以外，还要把lexeme算出  
来，其中yytext就是|到T之间的字符串，有了它以后我们就可以转化为string；整数、浮点  
数同理。红色的都是lex提供的。

处理嵌套注释

最后我们来讲一下怎么处理嵌套的comments。它在lex里头是可以支持的，这个支持  
就是说我们会有两个start\_state。一个叫inital，一个comment，在lexdefinition声明了两个  
初始状态。正常情况下都是initial的if，字符串。如果我们碰到了(_，就说明我们进入了一  
个可能comments的情况，也就是我们进入了一个新的start\_state（COMMENT），在这个状  
态下碰到任意输入都无所谓，直接过滤掉。过滤掉以后，一直到_)，它要回到INITIAL的情  
况。一开始我们想让它进入INITIAL状态，我们就用最后一行。也就是BEGININITIAL；吃掉  
的一个字符要还回去，也就是yyless( 1 )。

#### 这个东西还不能直接处理嵌套。嵌套是要回去自己想的。

### 2021 / 9 / 26

```
使用lex的好处
```

只需要写之前所提到的pattern，只需要写少量代码。这种方式就叫做声明式的过程。  
真正的代码和控制流是由lex帮我们实现。好处就是代码量比较少，但是pattern写错的时  
候，debug的技巧就和平时不一样了。

接下来我们介绍tiger语言，第二个lab交的时候需要加上tiger.lax，说一些怎么处理的  
comment,errorhandler,etc.  
这本书编译器的前端相对比较简单。

```
Tiger语言在lex中有
1 .保留字（reservedword）:while,for,to,break,let,etc...
2 .标点符号：-,:;等
3 .Identifier，开始必须是字母，是字母数字和下划线的组合
4 .Comments:/**/，允许嵌套
5 .整数常量，只支持非负整数，如果是负的就相当于一个表达式。
6 .String常量，引号之间的printablecharacter,space,escapesequences（转义串）。
```

最典型的是换行符和tab用\\n和\\t表示。\\ddd是可以用ASC 2 的八进制表示来表示一个  
ASC 2 字符。在字符串里头出现引号的时候，我们就要使用\\”的情况。在两个斜杠中呢出现  
的格式化的字符就是要在字符串中踢掉的。最后它还支持^c的情况，它实际上就代表了特  
殊的字符。

词法分析我们讲了regularexpression，我们写好regularexpression的declearation给到  
lex就可以产生出相应的程序。

### 语法分析...........................................................................................................................

#### 下面我们来讲语法分析，语法分析显然比词法分析更重要。

#### 首先，我们来简单看一下。做语法分析的时候，它们都有一些理论来支持（形式化语言）。

#### 有限状态的自动机，输入比较长的时候一定会重复的进入某些状态。像计数这种事情在FA

#### 中不太可能去做这件事情，因为FA里面是一张表是有限内存，只能数一个事先给定的长度。

#### 像要容易匹配的括号对是不能实现的。

像comments嵌套其实就是再做上面的这样的一个匹配。我们知道lex可以解决这个问  
题。因为lex本身它不是一些regularexpression。

```
所以我们需要CFG来表示我们程序的语法。
词法分析器：把程序原先的字符串变成了token串。
语法分析器：拿到token串以后生成parsetree（语法树）。
```

Parser的作用就是生成一个parsetree，但是input是token串，有可能还是错的token  
串。所以parser要先把非法的token串排除掉，对于合法的就构造出一个parsetree。我们  
构造语法就是通过CFG。它来自于这个启发：我们的程序的构造都是递归构造出来的。递归  
的定义就是有一些开始的部分，比如一个identifier可以作为最基础的部分。两个表达式通  
过运算符连起来的还是表达式，(statement,expression)也是一个表达式。这种就是我们语言  
construct，都是recursivedefined。

### 用上下文无关文法(CFG)来描述语法..............................................................................

Terminal是预先定义的，non-terminal是需要定义的，non-terminal中有一个startsymbol。  
接下来我们需要用production来定义non-terminal。

在我们的讲义中non-terminal都是大写的，terminal都是小写的。Start-symbol就是第一  
个production最左边的。以下是一些简写的规范。

#### 以下定义了一个简单的加和乘的表达式：

在做语法分析的时候，是给定一个token串构造出一个parsetree。这个production在  
构造parsetree的时候起到的是replacementrules，也就是X出现的地方用Y 1 ...Yn替换掉，

( _X_  _Y_ 1  _Yn_ )。从startsymbol开始，我们反复使用替换规则。我们不断地把non-terminal

换成另外的non-terminal和terminal。最后我们希望产生出一串terminal，是正好和我们输  
入一致的，这就是一个parser的过程。

在每一步怎么选择合适的production去做替换，这就是语法分析中很重要的事情。我们  
从startsymbol开始用不同的方式去做替换，最后我们替换出sequenceofterminal。

CFG是个语法，它可以推导出来的terminal串，就是这个语法构造出的语言。对于一个  
程序设计语言，如果我们用cfg构造出来以后，所有我们合法的程序就构成了我们的语言。

用这个CFG可以描述出这个括号匹配的集合，而regularexpression不行。

#### 我们要做的事情

#### 1 .判断这个语言是否属于某个集合

```
2 .构造parsetree
3 .出错处理
```

实际上对于一个language，我们可以用多个grammar或者多个regularexpression来描  
述。在语法分析的过程中，因为我们最后是使用工具来构造它。工具对语法是比较敏感的，  
比如说我们有两种写法，可能一种工具能处理而另一种写法工具不能处理（工具会报错处理  
不了）。Lex做词法分析的时候也敏感但是碰到的少一些。  
从Startsymbol开始通过一系列的替换，出现了 一串terminal，这个过程叫做derivation  
（推导），它也对应了一个parsetree。在推导的过程当中，一个non-terminal被右边替换  
掉了的话。这个non-terminal就成为父节点，而推导出的就变成了子节点。Parsetree的叶  
子结点一定是terminal。我们对于叶子结点按顺序来看，一定是我们最初的input。Parsetree  
还能反映出是先乘后加还是先加后乘。  
实际上id\*id+id这个表达式我们在不知道先验优先级的时候，我们是不知道乘和加的  
顺序。

```
但是这个parsetree我们就很明显的知道是先乘后加的。
```

在替换过程中选择先替换谁都不是什么问题，但是有可能的两种我们需要额外关注一  
下。中间的叶子结点在某一步上有很多的non-terminal，一个选择是替换最左边的那个，另  
一个选择是替换最右边的哪一个。上例中就是最左推导。下图就是最右推导的例子，不断替  
换最右边的non-terminal。两种情况只是parsetree出现的时间不一样，但最后的结果是一  
样的。

下面我们来讲一下歧义，一个语法构造完以后，可能会有不同的parsetree。可能最后  
这些不同的production最后得到的序列是一样的。

### CFG的歧义.......................................................................................................................

左图是最左推导出来的parsetree，左边的加法是先执行的（左结合）。我们也可以像右图  
一样最右推导，加法就变成右结合了。实际上我们希望的肯定是加法符合左结合。

另外一个就是int\*int+int  
左图就是先乘后加，而右图就是先加后乘。显然我们希望的是先乘后加，但是在原始输入的  
时候是没有优先级这个信息的。这就导致了我们用CFG去描述的时候出现了这两种不同的  
情况。  
这种我们就称之为ambiguous，也就是有歧义的语法。  
对于某些串来说，出现多个最左推导和最右推导。这个时候就是有歧义的，也就是  
ill-defined。歧义性的消除需要我们事先的约定，eg:先乘除后加减、加法都是左结合。

我们可以重写一个没有歧义的语法。我们修改原先的文法，引入一个term的东西。T\*  
int而不是T\*T就表现了乘法是左结合的。E+T而不是E+E，也能保障加法是左结合的。E和  
T分开是现有T再有E，这就保证乘法是有限的。有了这样的情况以后，我们就只能推导出  
来合法的情况了。

If-then-else的情况，它可以是只有if-then，也可以都有.

此时的else和哪组if-then就有两种情况了。

我们可以rewrite这个CFG，要求else要match最近的then。我们把IF分成两类（一类是  
if-then-else，另一类是if-then的if）。MIF中要求里面都是Match的，UIF只有可能在else  
中有unmatchif。  
如果碰到歧义了，我们就要去修改这个文法，但是修改这个文法没有什么通用的技巧，  
也不可能用一个自动的东西把一个有歧义文法翻译成一个没有歧义的文法。  
在文法中有歧义事实上也是有好处的，我们发现fix后的无歧义的文法都比较复杂，而  
原始的有歧义的文法是比较简洁的。我们可以想想怎么就用原先的有歧义的文法去消除歧  
义。  
我们可以给一些规则来消除歧义。

#### 我们只要声明一下，加法是符合左结合律的，以及乘法的优先级比加法高。那在这个过

#### 程中自然消除掉了。%是一种声明，说明乘法和加法都是左结合的，在后面的优先级比前面

#### 高。我们就可以在工具中增加一些规则去消除这些歧义。

#### 给定一个语法，我们要用CFG来描述，然后那个工具就会告诉我们是否合法并且工具

会构造一个parsetree。剩下的就是写程序比较容易解决的事情。

### 递归下降法构造parsetree.............................................................................................

Top-down的方法就是从根节点开始，从左向右逐个消除non-terminal。最后试图得到一  
个parsetree，从叶子节点来看和我们的输入是一样的。

#### 我们写了一个加分和乘法右结合、乘法优先级比加法高的情况。

```
因为我们有两个production，一开始我们就随便选一个，第二件事情是要把T 1 给
消除掉，T 1 又有 3 个production。我们发现(E)是和Int不匹配的；我们发现int虽然和
int 5 匹配了，但是T+E需要有个加号，是不匹配的；我们选择int*T的话，我们发现int
```

```
和*对了，剩一个T要消除，然后我们再去看，发现int都对了。但是我们发现最后的
T+E会多一个+E出来。我们只能在第一个推导E的时候选择推导出T。也就是退回到第
一次推导的时候，再继续尝试E->T。我们一个个去试，T只能再选择int 5 *T。然后T
再推导出int 2 。
这种我们叫做递归下降法（recursivedescentparsing），也就是从根节点开始一个
个去试，一旦发现unmatched，就回退（有可能回退多级）。这就是带回溯的递归。要
把中间状态记住。这个东西手工实现是比较容易的，但是不是总能很好的工作。
```

### 2021 / 9 / 28

#### 上节课介绍了CFG，以及怎么用CFG描述我们的文法。有了CFG可以定义一个CFL，可

以定义出一系列的terminal串来属于这个语言，下面给定一个terminal，我们怎么判定在不  
在这个语言中，方法分两种：

1. top-down方法，其中又分为递归下降法（实际上就是，从一个startsymbol  
    开始，每一个production都去尝试一下，见上面int 5 \*int 2 的例子，如果不符合就有一个回  
    退的过程。）  
    从startsymbol开始对所有可能性做尝试，从某个时间点来看，前面t 1 ...tk都是terminal  
    了，而A是第一个non-terminal节点，把A的所有production都拿过来试一下。

### 左递归和消除左递归.......................................................................................................

Recursive-decentparser是比较容易实现的，也开始流行使用ANTLR方法。Top-down方  
法比较害怕的是一个production情况：S->Sa，这样它就会变成死循环，一直在尝试消除S。  
这种情况我们称之为左递归文法。不仅仅是S->Sa，还包括通过一系列的推导后，间接地变

成这样 _S_  _S_ ，也属于左递归文法（left-recursivegramma）.

#### 我们可以消除左递归，也就是要重新写一下这个文法。通常情况下，我们把不属于左递

#### 归的拿出来和S’连接，然后S’中放入左递归即可。可以自动地消除左递归。在实际的情况下，

#### 有很多的文法是不需要回退的。

比如E和T在T+E中二选一的情况下，因为我们有一串INPUT，我们把input和E的推  
导放在一起，实际上是可以预测选择的。所以，我们现在用的比较多的是predictiveparser。  
我们在做basic解释器的时候，会碰到IF,GOTO。这是整句statement的第一个token，拿到  
以后整句话的语义就清楚了。

### LL( 1 )...................................................................................................................................

一边topdown地消除non-terminal，一边扫描我们的input。每次我们都是在消除最左  
边的non-terminal（left-mostderivation），以及从左向右扫描Inputterminals（left-to-right）。  
像一般的语言，看一个token就可以了，如看到了IF,GOTO,LET等。根据Inputtoken来决定  
我们选择哪个production。往前看几个决定了k到底是几。

定义了begins 1 ;s 2 ;snend和beginsend。这样我们可以先把token定义出来。词法分析就  
是getToken，拿出下一个扫描到的token。

我们定义一个S函数，也就是我们想看到if/begin/print作为合法的开头。看到了以后，  
我们就eat掉，让token前进一格。比如看到if的时候要求中间一定要看到then和else。

#### 我们可以进一步构造L和E，这两个都比较好写。

```
LL( 1 )语言处理statement比较方便，也就是token开头看到了它就可以知道了整个
statement长什么样子。在basic中，expression我们用的是中缀变后缀的方法，栈上的
东西根据操作符的优先级进栈/出栈。
```

#### 我们定义了右结合的乘法和加法，还有括号表达式。在这个里头我们要消除E的时

```
候，我们没有办法确定是int还是int*，这时候我们就来一个左分解，相当于是提取公
因式，我们把E改成TX，公共部分T被提取出来了。这样原本LL( 1 )只往前看一步解决
不了的文法就可以处理了。
```

### LL( 1 )的ParsingTable.........................................................................................................

左边都是non-terminal，上面是当前的input是什么。我们可以根据文法构造出这张表，  
来替换。空格就是出错的情况。上面的$符号就是我们在token串的最后加一个符号代表了  
token结束。换句话说，当我们消除X且发现token串已经到最后的时候，我们直接消除为  
即可。

我们给定一个文法，有可能构造出这个表，有了这张表以后就可以查表做parser了，  
也是可以用一个自动工具来实现这件事情。我们去查询S,a对应的表的产生式，可以把S替  
换掉。

查表消除的例子如上图所示，栈顶和Inputmatch后，就可以直接消掉了。

### LL( 1 )Parsing算法.............................................................................................................

算法的形式化定义如上图所示：如果栈顶是一个nonterminal，我们拿这个来查表，如  
果表里有这个东西，我们就用表里的元素来替换这个东西。如果栈顶是一个terminal，如果  
匹配了，那么next指针就往后移动一个。一直到栈为空或者中间报错。这里要求表上的替  
换是唯一确定的，如果表里有多个production，那么我们就不知道要选谁了。

### 构造LL( 1 )ParsingTable....................................................................................................

```
下面我们来说怎么来构造这张表，LL( 1 )替换到某个时刻，parsingtree的叶子结点会呈现
```

出 _A_ ，最左边是一串终结符，然后出现一个非终结符A，然后跟一串symbol（可能是

终结符也有可能是非终结符），我们用表示。这样子如果这个推导最后是match的话，我

们假设接下来输入的第一个token为b，那么整个需要parsing的token串就长成 _b_ 。

即：

树上的叶子节点： _A_ 

正在处理的字符串： _b_ 

在这个情况下，我们拿到了一个A和一个b，我们希望找到一个production _A_ 来  
把A替换掉。替换出来的结果一定是希望最后换到的东西的开头是b。

在能够正确识别的情况下，就等于我们有这么一个推导 _S_ \* _A_ ，且我们看到了b，

我们最后一定要推导出 _b_ 。存在两种可能：

```
1. b确实是通过A推导出来的，那么我们可以使用任何一个能够推导出第一个字符是
```

b的推导 _A_ ，这种我们就称之为 _b_  _First_ ( _A_ )。

2. b不是通过A推导出来的，换句话说， _A_ ，而b是通过A后的推导出来的。

这意味着在最终的推导中，b会出现在A之后，也就是 _S_ \* _Ab_ ，在这种情况下，我们

就说 _b_  _Follow_ ( _A_ )。并且在这种情况下，我们会选择任意一个最终能使得A扩展成的推

导 _A_ 。那么我们就有 _First_ ( _A_ )。

### First集合和Follow集合..................................................................................................

所以我们定义了first和follow：  
如此，我们就定义了这两个集合：  
First集合

_First_ ( _X_ ){ _b_ | _X_ \* _b_ }{| _X_ \*}

并且终结符的First就是它本身：First(b)={b}

First一个symbol，也就是从这个symbol出发可以推出一系列东西，第一个元素就叫做  
Frist(X)。Terminal的first就是它自己。  
左边的X就是我们要计算的Symbol，我们就来看第一个A 1 的first都是X的first，除了  
的情况。如果不属于A 1 的话，此时这个事情就结束了First(A 1 )=First(X)，但是如果A 1  
被消除掉的情况，A 2 就会起作用了。如果中间都停不了，A 1 到An都是，那么我们才  
认为是First(X).

```
举个例子来说：
```

第二个我们要算follow，每一个Symbol的first是从这个symbol开始推导出一串东西，  
这个东西是以这个东西开始的。

而follow是从startsymbol开始，b跟在X后面，计算follow的时候，需要计算出所有  
的first，然后再加一个$到其之后。

我们找到一个productionX，X后面的这一串东西和之前的first计算是一样的，如果A 1  
能被消掉，那么A 2 的first就followX，如果X是最后一个（A 1 到An都被消掉的情况），那  
么Y的follow就是X的follow。

+和_，因为我们E和T的first我们都有，所以就加入(，int。而左括号后面跟了E，所  
以就加入E的first。而E的follow，包括有括号，E还出现在X->+E，我们不知道followX是  
谁，但是E又是startsymbol，我们会把dollar加进去，但是我们不知道X的follow是谁，  
暂时我们只能算成这样，等一下X算完还要迭代回来。X在这，X的follow就是E的follow，  
而E的follow包含了X的follow，这样X和E的follow就可以唯一确定了。T出现在E->TX  
和Y->_T，Y的follow我们还不知道，First(X)是+和，因为代表了X被消掉了，那么我们  
还要加入Follow(E)，还要加入$进来。接下来我们看有括号，因为其在最右边，所以就是  
Follow(T)和$。Int的话首先要加入First(Y)，因为First(Y)中包含，所以我们还要加入follow(T)

根据CFG，我们设立这些规则来构建这张表。如果 _A_ \*，那么我们可以加入T\[A,  
Follow(A)\]= 

我们就一个个production看，然后填到表里去。有了这个表以后，刚才的推导我们就有  
了。

### 出错处理...........................................................................................................................

#### 我们讲了一种通用的方法来构造表，根据查表用产生式来替换。还有一种就是我们最早

#### 讲的手写代码。

#### 接下来以手写代码为例来讲出错处理，我们希望尽量恢复报错继续做下去。这时候就有

#### 几种办法：

```
1. 假装插入一个token
```

#### 下面这个东西就用Y去分析，如果我们碰到错误就往里插入的时候，可能它就停不下来

#### 导致死循环。

```
2. 删除一些token
```

#### 因为我们是想分析出一个T，我们分析出这里肯定不是一个Y，但是我们希望一个Y，

```
我们找到一个T的follow停下来，之前的都认为是T。把前面的这一段都当成是Y处理
掉。
```

这个就是我们的LL( 1 )parsingtable的情况。并不是所有文法都可以构造出这张表来，比  
如有歧义，比如不能左递归。对于大部分语法来说，就不是LL( 1 )，比如表达式就是一个左  
递归的。所以LL（自顶向下方法）是一个比较简单的语法分析方法，具有比较多的限制。

### LRParser............................................................................................................................

我们接下来介绍LRparser，刚才的方法是自顶向下的方法从startsymbol开始逐步  
expand我们的叶子结点。而我们的LRparse是从叶子节点开始逐步地向上伸展来构造出一  
个根节点。L（token串从左到右扫描）R（每次消除右边的），好处就是可以处理左递归也  
不需要左分解。我们考虑E->E+(E)|int，怎么构造出int+(int)+(int)呢？

我们不断地从inputstring中，不断地找出β使得A->β，然后我们把β替换成A。一直  
换掉最后变成了一个startsymbol就结束了。

#### 我们把这个过程反过来看就是最右推导的过程，整个过程就是最右推导的逆过程。

### 2021 / 10 / 8

上节课讲了LLparser，如果说用递归下降的方法，它的适应性强一些，后来用的predictive  
LLparser，根据当前状态和当前token，马上做出一个决定用哪个production来替换  
non-terminal，我们看到的东西比较少，所以LL( 1 )的能力比较弱。  
上节课还提到了LRparser（L指的是从左到右扫描token串，R指的是right-most  
derivation）。为什么是right-most呢，上节课我们提出了如下的这个grammar。

这是一个左递归的文法，LL是不能用的。对于LL，是自顶向下看到一个non-terminal，  
把production的左边替换成右边。而LR是bottom-up，把看到的一串terminal串，规约成  
production的左边。

我们把string中的β换成这个A，那么我们的string就从αβγ变成了αAγ，直到这个  
string变成了我们的startsymbol。  
我们就要按照刚才的说法，把输入串int+(int)+(int)规约。

·LRparser其实就是记录了最右推导的逆过程，所以在一个string中要identifiy一个β然后  
替换成A，在这个过程中有一个性质，就是γ本身都是terminal，而α就不一定了不能  
non-terminal和terminal都有，因为我们把β替换成A的过程是最右推导的逆过程，所以A  
是最右推导的第一个non-termial，所以γ肯定都是terminal。  
因此我们在刚才算法中，有一个string这个东西，一开始都是terminal，过程中逐步地  
变成了non-terminal。因此，我们把这个string分成两部分，一部分是γ这部分全部是terminal，  
剩下的左边的部分就可能都存在。

```
就引入了这个split符号。
```

### Shift和Reduce.................................................................................................................

```
Shift就是把右边spring的symbol放到左边来，而reduce就是把β变成A的过程。
```

一开始是一个inputstring，不断去做shift和reduce，逐渐替换为一个startsymbol，parser  
任务就结束了。

```
Shift的过程就是不断向右移动竖线，然后左边string就会发生变化，我们左边的实现就
```

可以使用栈来实现，我们总是把栈顶的东西换掉。这也是符合之前的 _A_ ，其中的

肯定是我们栈顶上的东西，因为要符合最右推导。

### LR( 1 )...................................................................................................................................

一个东西进栈，要么让更多的东西进栈（shift），要么对栈顶做reduce。到底怎么决定  
呢？我们可以根据栈上的内容来决定。左边的这些non-terminal和terminal符号串，怎么来  
决定呢，在我们的例子中，我们可以构造出一个DFA。这个DFA，有状态的transition， 9 这  
个状态看到了E以后，input就是string中左边的东西。

#### 不一样的就是在 1 , 2 , 5 , 7 , 11 ，这几个状态后头跟了一个东西，这个东西代表到了这个状

态之后要做一些reduce的action。比如 9 读到了一个E到了 10 ， 10 可能是一个终结状态，  
当前为E+(E|)，我们从 0 出发走到了 6 ，然后我们shift一个看到了右括号，我们再重新走一  
遍，走到了 7 ,到了 7 这个状态，栈上一定有E+(E)这个东西，有可能要做reduce操作。使用  
E->E+(E)是有条件的，要么后面（γ的第一个）必须跟了$或者+，才能使用这个production  
来做reduce。  
这个就叫做LR( 1 )parser。  
一开始栈上为空，就从startstate从 0 开始，停止在 0 这个状态。然后我们看到了γ的  
第一个是int，那么 0 有转移到int跑到 1 状态的transition，所以可以做shift。把int吃掉以  
后就听到了 1 这里，int可以变成E的条件是后面有$或者+，确实是这样，我们就可以做reduce  
了。所以根据栈上的状态和γ的第一个字符是什么，就可以判断是做shift还是reduce还是  
error。在 2 这个地方既可以做reduce也可以做shift，如果后面跟的是+，就可以做shift，如  
果是$就可以做reduce。走到 3 以后，有一个左括号transition，确实match的情况下，我们  
就可以shift一个，走到了 4.

#### DFA每次都要重走，很麻烦。DFA要实现的时候就是一个 2 维的表，行代表状态，

列代表symbol。

#### 状态机对应了这么一张表，代表了在 3 这个状态看到左括号进入 4 这个状态。只有这张

表就只有状态转移，而我们还需要把reduce的动作告诉我们，所以还需要再来一张action  
表。

也就是 5 看到+和)要做reduce，所以上面这张action表是DFA表的扩展。  
我们可以把这两张表合并一下，成为一张combine表。

然后我们把最右边一些分成GotoTable。因为从 4 看到E，一定这个E是在栈上的，  
一定是要继续走到下一个状态的，所以这里不能做shift或者reduce。表的最终状态如  
下：

```
如果我们把状态机扩展一下，栈上除了有symbol以外，还有symbol停在的状态上，其
```

中 _statek_ 就是走到symbolk的时候停在的状态。

在每次shift操作或者reduce操作后，我们需要在空栈上重新走一遍这个DFA，比较耗  
时。我们就可以在每个栈中的元素维护一下走到这个元素时，到了DFA中的哪个状态。

TheLRParsingAlgorithm

最初始的时候，没有东西在栈上，我们用dummy来代替。然后我们根据栈顶的状态和next  
token去查actiontable，然后就会告诉我们是shift还是reduce，  
Shift:比如s 8 就是shift后状态变成 8 了，然后就把当前symbol和对应的转移到的状态压栈。  
然后就不需要从头走了。  
Reduce:reduce的production是在action中有的，栈顶的symbol一定是，pop掉对应元素  
后，再填入<X,Goto\[top\_state(stack),X\]>

```
||
```

```
1 , 1 , , , , 1 , 1 , , ,

```

_sym state_  _symk statek symk_  _statek_   _symn staten_

```
t
```

```
X
state 0 * statek  state ，根据gototable就可以知道， statet  Goto ( statek , X )，然后
```

我们把state填回去就行了：

_sym_ 1 , _state_ 1 ,, _symk_ , _statek_ , _X_ , _statet_

#### LR的特性：

·LR一定能够处理更多的文法，因为在LL的时候，根据当前的状态和下一个symbol，一定  
要找到自己的产生式。而LR，确定不了的时候可以进栈，比如可以shift三次，再来做决定。  
所以LL是看到了马上要做决定，而LR做不了决定的时候可以进栈，之后再做决定，所以LR  
比LL要powerful，大部分程序设计语言都是可以变成LR的。  
·LR的核心就是一个table，有了这个table就是上面很简单的algorithm，输入、查表、做  
action。

这张表也可以通过构造出来，根据DFA构造表是讲词法的时候讲的，是很容易的事情，  
所以核心就是构建我们的DFA。

DFA做的事情：栈上有一堆symbol，下面就是我们想通过DFA知道当前我们正在找哪  
一个non-terminal，这实际上就是找non-terminal对应production的右边，比如我们拿到了  
一个X，我们一定是看栈顶上是不是有α，可以把α规约成X。可能只走了一半，栈中只有  
一半的α，此时可能就选择shift操作。

比如我们想把目前的栈上符号规约成非终结符 X，对应的规则是 _X_ , _a_ ，也就

是已经看到了这部分，在这种情况下因为我们还没看完，是要做shift，此时要看下一个  
token。

### LR( 1 )item..........................................................................................................................

```
一个LR( 1 )item是一个pair， X , a
其中第一个元素是一个推导规则，而第二个元素是一个终结符（也叫作前看终结符）
这个pair描述了parser的一个语义，我们最终希望规约出X，栈顶已经有了α，希望结
```

束的时候停在了Xa这个状态。所以下边要做的事情就是看看剩下的 _a_ 和当前的input：

```

```

| _tk_  1 ,, _tn_ 。

DFA的目的就是描述出上面这些东西。  
我们规定startsymbol只有一个production： _S_  _E_ 。最初的状态是把inputstring换成  
S，我们希望后头看到的是个E并且跟了一个$，这样我们的目的就达成了。我们的期望是这  
样子。

```
最初的parse上下文就是 S  E ,$，且栈为空，我们尝试从E$规约出S来。
那么，我们继续有如下的LR( 1 )item。
```

我们有了这个期望以后，就会有·E在这个地方。因为是E是一个non-terminal，比较  
难处理。

· _E_  _E_ ( _E_ ),，直接做shift，也就是如果我们看到左括号之后，就可以进入

_E_  _E_ ( _E_ ),。如果后头没有跟左括号就报错。

· _E_  _E_ ( _E_ ), 此时一点跟在最后，那也是简单的，直接做reduce。

但是 _E_  _E_ ( _E_ ),这种情况比较复杂，因为点在non-terminal前，稍微复杂一点，

我们希望看到E，但是E是non-terminal的，所以我们需要根据E的两个production来把后  
面的terminal串规约出E来，这两个production为：

( ),)

```
int,)
E E E
```

```
E
 
```



所以希望看E就转换成了希望看到int)或者E+(E))，而到了这里 _E_ int,)就是比较好

处理的情况了，第二种还是non-terminal的情况。但是这是我们希望看到E后头跟加号的情  
况。

这个红点如果跟在non-terminal前头，我们就把这个non-terminal用production来扩展，  
就有更多的东西出现，这些东西都叫做一个LR( 1 )的item（含红点的production和逗号后的  
symbol）。

对于一个LR( 1 )item： _X_  _y_ , _a_ ，因为点跟在一个非终结符y前面，这说明了我

们的希望，但是没有办法来做动作。此时我们就把y的所有production都拿过来，有了这个

东西以后，然后我们取出 _First_ ( _a_ )，加到item里头，这时候就是算一个closure（闭包），

这样做了以后有可能就出现红点+terminal的情况，但是还可能继续出现红点+non-terminal  
的情况，一定要继续展开，直到集合中的东西不断变大，token、production、红点的位置都  
是有限的，只要的这个过程不断去重复，最后这个东西一定就稳定了，不会再变化了。

使用item扩展context的操作叫做closureoperation。注意 _First_ ( _a_ )就是它能够推导出

的所有字符串的第一个字符的集合。

#### 这样就把我们的希望换成了一些具体的行动，一开始我们看到这些东西：

原先我们只有 _E_  _E_ ( _E_ )和 _E_ int这两个production。我们从 _S_  _E_ ,$开始

expand，最后就变成了三个item。这就是开始状态的closure。

```
这个closure算出来以后，就是我们DFA的一个状态。如果某个状态包含了
```

item\[ _X_ , _b_ \]，此时就可以做reduce。

```
从状态 0 ，我们要 构造出状态 1 和状态 2.
```

如果 _statek_ 中包含了\[ _X_  _y_ , _b_ \]这个item，y是一个symbol，它可以是terminal

也可以是non-terminal，下面我们想构造出一个从 _statek_ 到 _statek_  1 的transition。 _statek_  1 一

定包含了\[ _X_  _y_ , _b_ \]这个item。

从开始状态 0 开始，小红点后面跟了int或者E，所以出现了状态 1 和状态 2 ，对于状  
态 1 ，小红点在最后了，此时做reduce。对于状态 2 ，读到了一个E以后，小红点移到后面  
一个，也就是shift一次，对于状态 2 中的一个小红点在最后的情况，做一次reduce，也就  
是accept的action。状态 3 就是状态 2 的小红点+terminal的情况，直接shift即可。状态 3  
到状态 4 同理。状态 4 依旧需要算closure。然后根据小红点后面跟了什么，继续expand。  
走到最后，状态不再增加的时候，这个DFA就构造出来了，我们通过这个方法，从一个最  
初的状态通过计算closure算出了状态 0 的所有的item，然后通过transition派生出其他的状  
态，逐步把DFA的状态一个个派生出来，DFA的每个状态就告诉我们希望干什么和已经干了  
什么，有了这个状态以后就可以自动做LR( 1 )parser了。

### 2021 / 10 / 12

#### 上节课讲到了这么根据CFG来自动地构造DFA，这个事情可以自动地来做，但是问题是

说，我们构造出DFA以后，我们的parsergenerator就产生了呢?我们需要的不仅仅是构造出  
自动机来，在自动机上还有action（shift或reduce），当我们在DFA上设置action的时候会  
不会出什么问题。很有可能在构造DFA的时候，一个个item是一个集合，每个集合是item  
的集合。

```
这是shift-reduceconflict，因为是我们的语法有二义性
```

当我们看到else应该是做reduce还是shift，我们在文法中是没有界定清楚的

1. 修改文法，使得文法没有二义性，但是这没有自动化方法，需要人手动去写
2. 让parsergenerator在发现shift-reduceconflict的时候，让它自己选一种（现在的工具默  
    认都会选择shift）。  
    像这样有二义性的文法还是挺多的，比如加法和乘法在一起的优先级顺序、是否左结合、  
    右结合。所以在构造DFA状态的时候不可避免会出现这个情况：

```
显然乘法的优先级比加法高，所以我们希望做的是reduce。
```

```
同样的，此处我们如果选择reduce，就代表加法是左结合的；如果选择shift，那
么就代表加法是右结合的。所以我们就定义了在自动生成之外的规则来解决这个问题。
```

所以在bison中，可以定义结合律和优先级的顺序（写在后面的优先级高），当我们定  
义完了以后，我们就根据三条准则来选取shift，只有在这三个条件都不满足的情况下，就选  
择reduce。我们这些定义的优先级都是对于token和terminal定义的，production的优先级  
是由这个production的最后一个token来确定的。  
·如果说production和terminal都没有优先级的时候，就使用shift，也就是如果  
if-then-else没有定义优先级的情况下，默认选择shift。  
·输入的terminal大于production的优先级的情况，选择shift，比如E->E+E,\*的时候，  
因为乘法的优先级大于加号（production）的优先级，我们就做shift。  
·优先级一样的时候，就要看结合律了，右结合做shift而左结合做reduce，对于幂次

运算，它是右结合的，eg： 43 49  
2  
.

```
我们为了避免这个情况，最好是让我们的parsetree没有那么多的二义性。
```

下面的叫做reduce-reduceconflict，也就是栈上是要把不同的东西规约为不同的  
non-terminal，这时候可能做两种不同的动作，这也是因为文法中的二义性导致的。

这个文法定义了任意长度的id串，如果不写中间这个，就没问题了，但是为了让文法有二  
义性，就多写了一个production，但是写不写定义出来的文法是一样的。对于id这个叶子结  
点，我们可以使用两种不一样的tree的形式来导出它，这就会产生一个conflict。

在转移后的新的state中，我们看到了有两个reduce，这就导致了reduce-reduceconflict。把  
这个二义性消掉的话就重写一下这个文法。

这样的话，parsergenerator是根据一个给定的CFG，可以构造出一个DFA，然后我们用  
规则来消除一些conflict，这样我们消除conflict规则是自动的，构造DFA方法也是自动的，  
所以最后根据一个inputoftokens来走这个DFA，走的时候会有一个栈来放symbol 和状态，  
走一遍全部reduce成一个startsymbol和$的时候，就成功了；如果中间停下来不能走了，  
那么就是error。

### LALR( 1 ):合并LR( 1 )的DFA状态.......................................................................................

到这里这件事情似乎结束了，但是真的parsergenerator没有到此为止，理由是因为LR( 1 )  
的构造出来的DFA的状态太多了，一个很小的语言就会有几千个状态，效率比较差。进一  
步研究，我们就发现很多state状态长得差不多。

我们发现上例中，rule（production）是一样的，只是followedsymbol是不一样的，我  
们就想把这样的状态做一个合并，我们把前头一样的部分叫做core，也就是我们希望把相同  
core的state合并。

```
LRitems的core就是集合里每个item的第一部分，构成的这个集合就是core。
```

原来我们是LR( 1 )，我们就把core一样的做一个合并，合并完以后的状态叫做LALR( 1 )  
状态。LA叫做lookahead。这样的合并会把状态减掉十倍。

```
在前面做DFAminimize的时候，我们做过类似的事情。
```

我们把两个LALR( 1 )的状态合并之后，会引入一些conflict。

这就会导致新的reduce-reduceconflict，幸运的是这种情况非常少见。

#### 我们的工具是对文法非常敏感的，那么文法首先分成LL和LR，我们只讲了LL( 1 )和LR( 1 )，

我们也可以往前看k个。我们这里也没讲什么都不看的情况。

一般做parser，是基于CFG的；手写的parser，就基于LL( 1 )即可，要处理比较general  
的language，就可以使用LR( 1 )，为了提高效率，我们就可以使用LALR( 1 )。

```
我们再讲一下errorrecovery，遇到error可以分成以下几类：
1. 立即停止，解决一个问题要重新编译一次。
2. 记录错误，并且尝试继续，一个问题可能造成一大堆的错误。
```

如果不让它停下，我们就要做errorrecovery，让程序尽可能地parser下去。Recovery  
的方法是删除、加入和替换。Recovery还分成localrecovery（一点报错就在这一点插入删除  
替换）、globalrecovery（一点的错误，在这点之前的地方也去做插入删除替换）。

比如我们在处理expression的时候碰到问题的时候，我们怎么来recover。其实我们都  
是要增加一个出错处理的production，加的时候就有点技巧了，其中的error是人为构造出  
的新的token，当我们发现error的时候，我们是想找error后头的一个token，其实也就是  
synchronizingtoken，比如说上例中的右括号和分号，一旦我们出错的情况下，我们就会：

```
我们需要把栈上的东西pop掉，然后shift一个errortoken进来。
```

第二种方法是global的，这个时候我们就是说我们要做插入删除和替换，当我们发现出  
错的时候，我们在出错之前的地方去做插入删除和替换。具体的有个方法是Burke-Fishererror  
repair方法，当前我们发现了一个error，我们往前退k个token，在这k个token中，我们  
来做singletoken的操作，要么插入一个、要么删除一个、要么替换一个。比如说，我们的  
parser在第 500 个的时候出错了，我们就在 480 ~ 500 的范围内来做动作。我们做了一个动作  
以后，我们就去做parser，我们就去看最长的parse是我们要的repair。

对于k个token来说，delete可以k个；插入有k+ 1 个位置，选择有N种；替换有k个  
位置，选择有N- 1 种，所以一共有 _N_  2 _KN_ 种操作，每次做完操作我们还要停下来parse  
一次。也就是在错误不常见的时候，勉强能来做这个事。因为出错的时候需要往前退K个，  
所以我们需要两个栈。始终保持oldstack和newstack之间保持K个的差距。

### 语法分析工具yacc...........................................................................................................

#### 最后我们来讲一下工具，

一上来是%{C代码 %}，然后定义哪些是token、terminal、startsymbol，再往下还可以  
定义一些结合律和优先级之类的；%%后面就是production。

前面lex帮我们做好了，拿来给我们的parser用。在下面我们可以定义token和  
non-terminal。然后就是一些我们定义的production。

注意其中左结合和优先级（负号的优先级最高）的定义方法。注意最后一条，在lex的时候，  
我们认为- 1 和 2 - 1 中的minus是同一个token，但是我们又想保证负号的优先级比减号高，  
那么我们可以附加定义最后一条规则的优先级为UMINUS，这条规则的优先级变高了。

注意，在上面这个语法中，a+b&c是符合语法的，但是不符合语义，到时候我们还会做  
一次typechecking来做语义分析。

在ML-Yacc中，是支持Burke-Fishererrorrepair方法的。可以用%value去指定一些值。  
有了这些东西，recovery就可以做了。还有一个就是这个方法一次只能换一个，当我们想换  
多个的时候，不能枚举去换，但是我们可以指定某些替换。使用%change来把equal替换成  
assign。

第四章：分析程序对错的时候，我们要生成内部表示。Sourceprogram是asc 2 字符构成  
的，在编译的时候要引入中间结构。是有很多层级的IR的，最高层级的IR是抽象语法树，  
它像我们的高级语言。一个syntaxtree是要记录程序的层次结构，而符号表是在程序中有很  
多的变量、函数、用户定义的类型，这些都是符号，所以我们需要记录下来。我们还需要知  
道变量的类型、如果变量是一个数组，那么我们还需要知道变量元素的类型是什么；函数的  
参数和返回类型是什么；user-definedtype到底是什么type。

### AST.....................................................................................................................................

#### AST（抽象语法树）是一个树，我们现在已经教过些什么呢？程序的组成是递归定义的。

描述这样的构造就是CFG，它对应的是一个parsetree，树可以表示为一个层次结构。  
Syntaxtree和parsetree有一点点区别，syntaxtree中没有必要把parsetree中的一些中  
间结果保留，比如parse中有E->T-> 1 ，我们在syntaxtree中只需要一个 1 就行了。

我们要引入attribute（属性）的概念，我们在描述文法的时候是用CFG，其中的terminal  
和non-terminal都是grammarsymbol，接下来我们要给每个symbol对应一个value。在我们  
构造syntaxtree的时候，对应的value就是树的根。我们一边在parser的时候，一边要计算  
它的value。

```
也就是每一个symbol现在有了一个value，也就称为attribute。Parser的过程也就是把
```

_E_ 1  _T_ 规约成E，显然前面两个pointer已经有了。

```
我们有一些函数mknode,mkleaf。
```

那么我们就可以对应地去写sementicrule了，如果T->(E)，那么T的节点就直接赋值给  
E，是一个压缩的过程，没有冗余了。这里我们都是通过右边的attribute来计算左边的。

刚才是构造树的过程，我们也可以构造一个计算器，一边parser，一边把结果算出来。  
Eg:构造计算器的过程

这样在parsergenerator的时候，栈上多了一列以后，就可以把attribute记录进去了。  
Eg：栈上的例子

### 2021 / 10 / 15

上节课我们讲了一边parser一边做动作。早期的编译器没有那么多动作，一边做parser  
一边生成汇编，这件事比较复杂。现在我们在做语法分析的时候就生成AST（抽象语法树），

上节课还举了一个例子，一边parse一边生成计算结果，所以也不是要一定生成AST。

### 语法分析工具Bisonc++...................................................................................................

最早用的是yacc，现在我们比较用的多的是BisonC++，这次我们的lab和书上是不一样  
的，一开始也是：

这个type是生成terminal和non-terminal的。它会跟一个symbollist。然后我们有优先  
级，leftright还有non-associative。

上节课我们讲yacc的时候是没有后头这个东西。今天我们实际上就是说要把semantic  
action（一边做parser的时候一边做什么动作）加进去。上例是计算器的例子，每一个表达  
式中间都有semanticvalue，这就是我们的值。当我们把int规约为expression的时候，int  
的semanticvalue就被赋值给了expression。左边的semanticvalue就用$$来表示，右边的符  
号比较多，就从左到右按照$ 1 ,$ 2 ,$ 3 来表示。  
给定一个存在+-\*的表达式，它就可以把对应的值算出来。这就像在basic解释器中，表  
达式我们中缀变后缀的时候，一边变、一边把值算出来，这就和我们这里一边分析一边求值  
一样。  
下面我们再举一些例子来看看bisonc++。

#### 勘误：上文的L->应该为L->E

这是我们在lab 1 中使用的语句。Expressionsequence：S,E 也就是statement先算，然后再  
来计算这个表达式。  
在这个里头，因为我们碰到了id，id可能会被赋值，执行到某个地方id的值可能会变  
掉，所以处理id变量的时候是用一个table。Table是不覆盖的，有一个新的值就把值插入在  
最前面，虽然在表中可能出现了好几次，但是我们只返回第一个找到的值。

这个table数据结构提供了查询、update操作。

然后我们来看我们的bison，第一行讲的是和scanner相关的东西。  
第二个部分的东西是和我们parser相关的一些内嵌的C++的代码。其他东西都一致，和我们  
的文法相关。比如int和id都是一个terminal，还有一些terminal都是assgin、分号、括号  
等。然后下面这个地方是exp，它是一个non-terminal，value是number。然后我们定义了  
左结合的COMMA，+-\*/，并且乘除在最后，说明其优先级最高。

把statement规约为program，是没有action的。Action都在每个单独的statement里头，  
在我们赋值的时候，id有一个新的value，要去修改这个表，$ 1 的value就是string，$ 3 的  
value就是number。碰到print的时候，里面已经打印过了，外面只需要再打印一个回车即  
可。注意我们这里的action是有副作用的。某些semanticaction不该发生的发生了，或者应  
该发生了但是没发送。在parser到expsCOMMAexp，我们只需要打印新的expression就可  
以了，因为前面的exps的东西已经都在之前被打印过了。

COMA的最终结果是最后的expression的表达值。当我们在表达式中碰到ID的时候，就要  
把对应id的值拿出来，然后赋值给expression的semanticvalue。这样我们一边做语法分析，  
一边打印出中间的结果。

Side-effect对siderecovery是有影响的，比如我们出错的时候，需要把栈上的一系列东  
西pop掉，找一个synchronizingtoken，比如找到左括号，其后前的全部pop掉。我们在  
semanticaction中，遇到左括号就nest+ 1 ， 遇到右括号就nest- 1 ，在出现error的时候，很  
多东西pop掉了可能导致到最后左右括号就不一致了。所以我们最好的方法是在semantic  
action的时候不要做有副作用的动作。

```
所以我们要选用side-effect-free的semanticaction。
```

这个插入的时候是一个token，token有时候需要semanticvalue，我们就可以使用%value  
的方式去说明这些在parser中插入的token的value是什么。

下面我们就来说tiger中的SyntaxTree，在lab 3 中，我们需要一边做parser，一边生成  
syntaxtree。比如我们这里有一个Var，这个变量是tiger中的变量，它是一个类，并且有几  
个子类，这些子类公共的部分只有一个pos\_，其他东西都在我们的子类中。变量的子类有  
三个，而表达式的子类有一大堆。

先要表明我们的expression在源文件的哪一个位置上，这个东西主要是在我们需要报错  
的时候，在第五章我们做类型检查的时候，如果发现要把字符串要赋值给一个整数，这就会  
报错，我们需要报出它在哪个位置上出了错，大家在做lex的时候这件事很简单，因为lex  
是一边扫描一边定位。而当我们AST都产生的时候，parser已经扫描过一边文件了，这时候  
如果我们使用扫描位置来报错，那么都在文件结束的地方，所以我们报错的时候需要这个来  
报出对应的位置。  
我们要去做一个可变参的插入的事情。任何一个变量都在symboltable上做。所以简单  
变量最终要的事情就是找到这个table。

Tiger中只有变量和表达式，没有statement。Symbolvariable和fieldvariable。第一个就  
是pos，简单变量的话就是跟了symbol。而fieldvariable，比如a.f，其中是Symbol指的就  
是f。SubscriptVar的节点中，左儿子就是a，右儿子就是一个整数表达式。  
字符串、整数、functioncall、双目运算、record都是表达式。

#### 像这样的一个东西，这是我们第一节课中举的例子。

```
a= 5 ;a+ 1 是我们straight-line语言中的sequenceexpression，
a的位置是 2 ，冒号的位置是 4.
```

正如之前所说，在AST中，我们需要维护pos来便于报错。在parsergenerator的时候，  
有一个DFA，它在做的时候就是在进栈，一开始我们进栈的时候，只进了一些Symbol，因  
为DFA每次大家都要从头走，比较naive，先进terminal和non-terminal，然后再把state放  
在里面，然后因为我们要做semanticaction，所以我们又多了一些放入semanticvalue，下面  
我们要做position的话，那么就再加一列。

```
所以Bison就帮我们做了这件事情，为了支持pos，我们需要修改我们原先的数据结构。
```

我们还需要增加position的semanticvalue。所以我们增加一个类型叫pos，也就是一个  
non-terminal叫position，它的semanticvalue就是position。这样我们就可以在栈上拿到这  
个position的值。我们在表达式的时候，我们想把position放到什么地方，让pos代表什么  
位置，那么我们就在表达式中放到哪里。

#### 介绍完了前面的变量和表达式之后，我们来看一些声明：变量声明、类型声明、函数声

明，我们现在来看函数声明，我们需要让它支持递归调用。那么这个f和g在tiger中必须  
是挨着的（连续声明的），那么f和g才可以递归调用。这样定义我们处理起来稍微简单一  
点。

一开始我们要定义一个functiondeclerationlist，FuncDec是我们真正的函数声明，函数  
有函数名、参数、返回类型、函数体。Record中一般都有a:int,b:int,c:string。返回类型也是  
一个symbol，因为在tiger中是支持变量声明的，是可以通过type来声明一个类型名。第四  
个参数就是函数体就是一个表达式。

我们在这里声明了一些semanticvalue，哪些是token，哪些是non-terminal，和之前说  
过的都是一样的，只是最后的semanticvalue会发生一些变化。

#### 剩下的事情就差不多，现在我们构造了一棵树。

```
我们再回到这个函数递归调用的情况，我们来看一下这个tiger程序。
```

所以一开始是LetExp然后是DecList，Call的时候因为没有参数，所以第二个参数为NULL。  
Dec中包括了两部分，一个是a的变量声明以及指明其类型，因为一开始没有指明a的类型，  
所以a的第二个参数类型为NULL，到第五章中，需要根据赋的初值的类型补回a的类型。  
回过来看我们的dec有函数声明、变量声明和类型声明。  
我们接下来来看FunctionDec。里面是一个FuncDecList，里面有f和g的函数声明。f的  
参数为空、返回值为int。而g是有参数。

```
有些ast中有的，我们ast中不表示，直接处理掉了。
```

### 2021 / 10 / 19

上节课我们提到了AST，比如变量和function怎么表示。在生成AST的时候生成了很多  
接口。但是tiger中还有很多语法运算没有用AST表达出来，比如逻辑运算或者单目运算符  
负号。我们在做parser的时候要做一个变换，e 1 &e 2 可以被翻译成ife 1 ,thene 2 ,else 0 ，e 1  
|e 2 可以被翻译成 ife 1 then 1 elsee 2 。-i可以被翻译成 0 - i，但是这样我们就不能表示 2 ’s  
complement的最小数了。这里强调的是并不是每个语法结构都需要一个AST，而是可以转  
化成别的表达来减少我们AST的类型，AST的类型少了，我们在马上要做的语义分析里头，  
也会减少一些工作。我们变化以后，如果真的检查出错误来，可能就和原来不太相关了。  
我们再提一下，在AST中有很多identifier，表现形式就会有很多符号。

有很多符号a和b，出现的时候都是字符串，在我们的tiger中，要把字符串处理掉，  
我们并不是直接来存字符串，而是用指针指向字符串的位置。我们通常用Symbol来表示字  
符串，这样它的大小就统一了，是类似指针一样的东西。可以通过这种指针拿回字符串。

在第五章很快就会介绍symboltable，是记录符号的数据结构。它要把嵌套的、类型和  
变量分开。FuncDec怎么用AST来表示，它的node有很多

1. 参数，在其中我们需要考虑参数名和参数类型
2. 返回值的类型
3. 函数名
4. 函数体是什么  
    所以FunDec中就有name,FieldList(形参),result(返回类型),exp（函数体，所有计算的代  
    码都是表达式）。因为我们在semanticanalysis的时候需要方便我们报错，所以还有一个pos  
    记录当前的位置。  
    每一个Field其中就是一个参数名、一个参数类型。  
    在我们parser的时候，把所有东西都当字符串处理存进去。但是我们的类型，比如int  
    是有意义的，在生成AST的时候，都当字符串处理。在我们语义分析的时候，我们再把这些  
    有意义的字符串提取出来处理。

我们还要提一下，在AST里头，当我们到registerallocation的时候，有些变量是要进寄  
存器的，还有一些变量是不能进寄存器的，比如C语言里，我们希望取变量的地址，那么这  
个变量不能放到寄存器了。又比如我们是struct变量、数组变量，都是不能放到寄存器里的。  
在tiger里头，虽然没有指针，但是有record和array，这种变量都需要放到内存里，而不能

#### 放到寄存器里。

}

}

.... ;

(int ){

int ;

( ){

_a x_

_g y_

_a_

_f x_

 

Tiger还有函数嵌套，也就是在f的声明里头可以声明另一个g，在f里面g前声明了a，  
那么在内函数g中可以使用到a。这种内函数调用的外函数的变量a、x，也不能放到寄存器  
里，因为进到里面的函数的时候，会更新寄存器，我们需要把a、x放到内存中。

在tiger的AST里头，一个变量声明的时候有一个escape，说明是不是要放到寄存器里  
去。Expinit是初始化的时候的表达式，目前这个VarDec中是没有escape变量的。

AST我们讲完了，前面构造AST都是使用Bison来构造的，在每个production的最后，  
有一个semanticaction，在规约的时候我们生成一个AST。我们在top-downparsing的时候，  
这件事情是怎么做的。

我们使用CFG来定义这个语法，定义完我们就知道了每个production代表什么含义，  
这个例子是支持加减、括号的计算器。而我们现在topdown是LL文法，不支持左递归，所  
以我们先要消除左递归。

消除左递归后，我们会得到E->TR，那么消除左递归后，semantic该怎么办呢？它就会  
变得复杂，我们先碰到T，算完T.value以后，我们要去处理这个R，但是第一个T的这个值  
对R是有用的，我们需要根据T和R的value来算出E的value。  
所以在这边，我们给R两个semanticvalue，R.i和R.s。如果R为空，那么把R.i赋给R.s，  
R.s是R的最终的值，然后我们通过第一行的”E.val=R.s”就可以把右边最终的值赋值给E。

Attribute分为两类，R.i的特征是由它的parent和sibling来计算的，而R.s的特点是它  
的值都是由children来计算出来的。  
我们Parser生成AST都需要把semanticaction在最后，是bison可以处理的东西，而action  
写在中间的情况下，这叫做TranslationScheme（可以出现在production的任意地方），bison  
可能不能处理这种。

对于每个non-terminal都有一个函数，函数体其实就是把production写进去。对于每个  
production有terminal和non-terminal，遇到terminal，我们就使用eat把对应的terminal吃  
掉，继续往后走，对于每个non-terminal，就调用对于的名字。这个只能判定是否正确，不  
能做动作、不能生成AST，我们要做动作的话，我们就要把translationscheme放进去。

我们先来看红色的，分成inheritedattributeR.i是R的初值，而R.s是R的终值，所以我  
们做如下处理:  
·每个non-terminal还是对应一个函数，但是这个函数是有参数的，我们把inherited  
attribute作为函数传入的，把synthesizedattribute就作为函数的返回值。

其中用到的attribute，都作为这个函数的局部变量，下面我们来改写一下上面的图，改  
写成我们想生成一个AST。

```
第一步规约完了以后，我们把R 1 的treenode给成R的treenode。
```

刚才我们提到R有两个attribute，一个作为参数、一个作为返回值。当我们看到加号的  
时候，把加号吃掉，然后我们调用T，它会生成一个T的语法树。我们把这两个加一下，构  
成一棵新的语法树。调用R以后，返回值是R.s（synthesizedattribute），这里也就是，如果  
在产生式中有non-terminal的情况下，会有参数传进去。

我们把T和R之间的action直接copy过来。这就是Top-downparsing，一般现在我们都  
用bison来做，不会牵涉到这个top-downparsing生成AST。

### SymbolTable...................................................................................................................

我们现在开始讲第五章的SymbolTable，它里面还有一个SymbolicTable。基于Symbolic  
Table我们构造了SymbolTable。为什么要有SymbolTable呢？在第四章中，我们把所有东西  
都放进了AST里去了，我们在做语法分析的时候生成了AST，在生成AST的时候能不能搞清  
楚x是一个变量、类型是int呢？也不是不行。但是我们现在语法分析的时候，尽量用bison  
处理semanticaction。如果semanticaction太复杂跑到中间去了，bison可能就不能处理这件  
事情了。  
现在第五章还是前端的部分，前端的目的是把源文件变成一个中间表示，AST是中间表  
示的一部分。我们lab 1 里，除了有AST以外还有SymbolTable，变量是要写到SymbolTable  
里头的，所以我们在表示frontend的时候，需要有tree和symboltable。其包含定义了哪些

变量、类型是什么，我们还需要表示出变量的有效范围（scope）这件事情。比如letDinEend，  
D中声明的变量的有效范围只有在E中。一个SymbolTable里面要存所有变量及其类型：

我们把D声明的变量叫做一个environment，它包含了很多变量的声明。在程序中  
environment就有可能嵌套：

最早的environment是参数env。如果进入函数体之前，外面的env叫做 0 。函数的参

数定义是在 1 。后面一行print\_int(a+c)，a和c会先去找 1 ，找不到的情况下才会找 0 ，

再找不到就报错。在第三行开始，又开始一个新的environment 2 ，并且声明了a把之前的

a覆盖掉了。注意第三行的a还是 1 中的a。所以，我们就会发现在扫描我们语法树的时候，

environment会变化。  
Environment会起什么作用？

Scopeinformation，在后序扫描（先扫描儿子再扫描父亲）语法树的时候，我们扫描到  
父节点的时候，environment就变掉了，我们在语义分析的时候有两种处理方式，  
· 1 .functionalstyle，每次发生变化的时候老的都保留着。  
· 2 .imperativestyle，有了新的就看不到老的，但是我们退出scope的时候还能回得去。  
还有些语言支持多个symboltable。

第一遍扫描只是构造出这个symboltable，第二遍扫描扫描引用，看到哪个引用就去查  
对应的symboltable。  
接下来，我们来看一下怎么实现symboltable。Tiger中用的是一个open-hash。

它就声明了一个开链的hash，其中有一个key，有一个binding。Pop操作，给定一个key，  
把链里头的第一项给它拿掉，相当于一个delete。

### 2021 / 10 / 22

```
SymbolTable类似是一个hashmap，把变量和函数定义为原先的类型。
Imparativestyle就是直接插入。
```

我们在imparative中写的是X=X+Y，算完就把原先的X覆盖了，而在function中就不  
存在覆盖的情况，如果要赋值就创建一个新的值，也就是function-style是有“不可更改性”。  
这个方法的好处就是可以控制对一个变量的修改，那么我们很容易控制一个变量有多个读者  
而只有一个写者。  
对应到SymbolTable中，X和Y对应是两个SymbolTable，编译器的分析中有不同的Scope，  
从父函数进入到子函数的Scope中，会声明一些新的declaration、定义一些新的（局部）变  
量，这就是一个不断叠加的过程。在imperative中，全程只有一个SymbolTable，进入的时  
候更新SymbolTable，退出的时候做减法。而在Function中，X和Y和X+Y都存在。  
在functional里面，hash的效率可能比较差。

非覆盖的更新对于哈希实现是比较低效率的。当我们想插入binding的时候，我们可以  
复制array，不过bucket可以共享，然后再加入一个新的binding。

左图是插入前复制完的情况，而右图就是插入完的情况，插入了Mouse的情况。如果  
我们把新创建的Array删除了，那么原先的Array还可以使用。

这个教材提出不要使用哈希表来避免copy，它提出的二分搜索树。左子树小于当前节  
点、右子树大于当前节点。

#### \- >

使用二叉搜索树的好处是我们不需要copy整个hasharray，我们只需要复制个别节点就  
可以了，当我们需要插入一个新的节点在第n层的时候，只需要copy上面的n- 1 层节点即  
可。  
为什么我们要复制一边dog节点呢？对于dog来说原先左儿子是bat，右儿子是null；  
而更新完dog左儿子是bat，右儿子是mouse。dog节点左右节点不一样了，我们可以理解  
为copyonwrite的操作，所以我们需要复制一份dog。  
二叉搜索树的深度不会很高，所以每次更新的效率也在logN，可以接受。

SymbolTable是装table的。我们可以把string换成引用。所有的string，如果内容一样  
应该map到同一个symbol。这里给了一个静态方法unique\_symbol

这个table里存的一个是binder（bucket的数组）。这个table就是我们比较熟悉的哈希表，  
增删改查都齐了。

为什么要引入top呢？因为在SymbolTable有嵌套的Scope，eg：  
{  
inta= 10 ; \[a->int\]  
{  
doublea= 20 ; \[a->double\]  
//这里要用到a的话，肯定得到的是 20 ，此时用到的a，其double要覆盖int  
}  
}

我们分析到红色}的时候，我们需要把double重新改为int，方法一是我们往上回溯，然  
后一个个去掉，教材中的方法是我们记录到上一个{是在哪开始的，记录其开始的位置，我  
们不断pop，这样就可以把它清空了。  
所以实际上\[a->int\]和\[a->double\]是相连的，在pop的时候，我们会先pop\[a->double\]，  
然后再去pop\[a->int\]。如果我们只是这样做，我们其实不知道pop到哪结束。这里就加了  
新的symbol 也就是symbol来表示我们开始了。所以在具体实现的时候，会是这样  
的：\[a->int\]->\[\->null\]->\[a->double\]，我们在pop的时候，pop直到mark。

BeginScope的实现，就是把Marksymbol插入到表中，而EndScope就是如果不是mark  
symbol的话就不断Pop.

然后我们来看一下binding，每一个symboltable中都有一个binding，也就是映射中的T  
要对应一个值，在tiger中把类型的命名空间和函数、变量的命名空间是分开的。

比如上图中的定义在tiger语言中是允许的，即类型系统的名字和变量系统的名字是分  
开的。那么我们怎么判断呢？如果一个指令是合法的语法指令，我们是可以判断出来的。  
比如 VARID:ID:=exp，那么我们是可以知道哪个是哪个的。  
所以我们需要搞两个SymbolTable，一个做变量检查，一个做类型检查。在后面做语义  
分析的时候，就会越来越多地用到这样的类型。

```
这里大概展示了一些实现，这里是一些抽象的定义。这里要再讲第一下，explist
左节点是一个exp，右节点是一个explist，这在树中是很自然的递归类型，但是在C++
中不太好做，所以我们上右图中给出的是std::list。所以我们整体的list结构都统一成右
图这样。
```

在tiger中，哪怕名字不同、也是不相同的；但是类型别名的情况是可以这样做的。我  
们刚才说了变量和类型的namespace是分开的。

```
TEnv中，其实key就是Symbol，而value是type::Ty结构。我们有预定的类型去做初始
```

#### 化。

```
上节课讲到了Type，这节课我们讲valuebinding，其分为变量和函数。
```

变量记录的是类型，而function要记录的是参数类型和结果的返回值类型。我们引入  
environment的这个概念，里面也是哈希表的结构。

为什么需要readonly\_呢？在for循环中我们可以定义i= 1 ，后面我们就不能赋值i= 3 了，  
tiger中不支持在循环体中对循环变量赋值，所以这里我们为这种情况添加了readonly\_变量，  
如果我们尝试对readonly\_变量赋值，那么会报出一个readonly\_的语义错误。  
Tiger中是不允许隐式的类型转换的，但是在别的语言中很常见，我们可以定义一个  
EnvEntrye=true,因为EnvEntry说白了就是一个readonly和一个变量。我们这样写就会隐式  
地转化为了EnvEntrye=EnvEntry(true); 为了避免这样的隐式转换，我们这里加了一个  
explicit，要求代码必须显式的调用这个构造函数。

### TypeChecking..................................................................................................................

函数为空的时候是VoidTy，NilTy是record类型，后面几种就是真正的类型消息。NameTy  
是类似一个占位符。

不同的类型，我们都定义了这样一个SemAnalyze的方法，任务就是对不同的类型写一  
个semanticanalysis。

```
这里展示了一个Opexp，左边要通过semanticanalysis拿到真实的类型。然后我们判
```

operation是不是这四种，+-\*/，别的不支持，如果是这四种，那么我们进入，并且我们只支  
持int的加法，所以要求两边的类型都是int。c++中也可以在运行时得到变量的typeinfo，如  
果left\_ty和right\_ty的type不相等，那么就报错左右两边不相等。

现在我们去判断variable（简单变量、record、array），我们在symbolVar中引入  
SemAnalyze。

```
我们再复习一下两个Entry的定义。在c++中nullptr表示为指针为 0
```

也就是我们拿到SymbolVariable在Venv中找一下，看看entry是哪个，如果entry不为  
空，先判断一下它所表示一个VarEntry，如果是就直接返回了。  
最后是declareation:

简单来说，stdlist我们拿出来以后可以简单的用for循环去访问它。接下来我们拿到  
body，如果body是空，那么返回一个void。否则我们就对body做semanticanalysis。  
这是let的。

```
后面我们先复习一下语法树的node：
```

在语法解析的时候，也有一些type的内容，在语法解析的时候，我们大概知道有些内  
容是什么。比如 a:int= 3 ,我们可能定义为的不是int而是abstractiontype，在做类型检查的  
时候我们需要进一步翻译一下，还有一些field，定义一个record的时候需要定义一些fieldlist。  
Explist的话就是需要重新分析一遍。

前面我们一直在讲这个是怎么用的，在expression中我们拿到的是直接从semantic  
analysis中拿出来的。换句话说，我们之前的都是从venv中lookup出来对应的symbol，而  
上图是指我们在定义变量的时候，我们找到Symbol对应的type是什么，然后加入到venv  
中。  
比如varx:type\_id:=exp，这个情况我们需要检查type\_id和exp的类型是否是一致的。  
还有一个是初始化nil的时候，前面一定是record类型。

```
上图复习了一下ASTNode
```

我们拿到name\_ty调用SemAnalyze，它会分析出RecordTy。第一步语法解析的时候，  
我们是粗略地分析成了absyn::RecordTy，然后这里我们分析成了type::Record放进tenv\_。  
至少大家要写一个for循环，都扫描一遍然后enter进去。

函数的定义，就是找一下第一个，然后去判。参数的类型还是abstract::Ty，这里面就会  
做一个转换，变成formals。这里我就会使用迭代器去写for循环。

自递归问题，这是C里面的代码，其实cell_在cell定义前出现了，并且cell里面用了  
cell_

还有一种可能是functiona里面会调用b，functionb里面又会调用a。思路就是我们放  
一个占位符进去。第一遍我们做a的时候看到b，知道肯定b是个函数，同理b调用a的时  
候，我们也知道a是个函数。第二遍的时候，我们再去检查类型是不是符合。

### 2021 / 10 / 26

### Tiger中的递归声明........................................................................................................

在tiger中，所有的array和record都是一个指针。第一部分把TypeName拿出来，也就  
是先定义好list（把类型List登记到typeenvironment里去），然后一遍扫描写进去即可。

```
通过structure引入的环是允许的。
```

#### 而这种环就不允许了。

### Tiger中的递归函数调用...............................................................................................

Node里是一个list，下面是一个个的func。也是分两步，第一步处理functionname、formal  
parameters、returnvalue，把这些登记到变量表里去。第二遍我们扫描的时候，除了函数名  
以外，还有个函数体。我们从变量环境中可以找到这些参数。对于递归的函数，f调用了g，  
g里又调用了f。总会有一个函数先引用再被定义。在C++中，就是先定义其prototype：f(),g()。  
而C里比较特殊，C引用函数的时候如果还没有定义，会自动把缺省值补上。而tiger中选  
了一个折中，只要我们放在一起定义，就可以通过两边parse处理掉。

刚才我们提到了name-equivalent和structure-equipment。Cell就是一个list，第一部分  
是information，第二部分是个list。实际上next和last、p、q、r都是指向cell的指针，但是  
如果在tiger中，它就会认为next、last和p、q、r不是同一个东西。这就是name-equivalent，  
这就是把每个名字当做不同的类型，这在处理递归的时候是比较简单的，我们可以停在name  
这里，不需要再去展开。而另外一种就是structure-equivalence，替代掉以后就是同一个东  
西。我们要判断两个类型是不是结构等价的话，我们可以通过递归来做：基础类型（primitive  
type）是可以比较的，然后根据array和record构造出的更加复杂的类型。我们不关心field  
的name，我们只关心field的类型是什么。

#### 如果我们只有四种构造类型，给定两个类型，我们就可以根据上右图的递归方法来判定

#### 两个类型是否等价。

我们讲tiger选用的是name-equivalent，否则我们还要展开到下面。我们后面讲的这部  
分都是tiger中没有的东西，但是一般的编译语言要处理的。比如我们有int和float，又有  
一个加法，那么int+float怎么办？这件事情就是编译器帮我们做的事情。

#### 比如上面实数和整数相加，我们就要把I转化为实数，然后加法一定是浮点数加法。转

的方法第一种就是编译器帮我们去做，第二种就是我们在代码中I前添加(float)做强制类型  
转换。

在tiger中，只有int和string两种，所以tiger中有typechecking的动作，还是没有  
conversion的动作。

```
这种根据参数决定operator的具体含义的，这就是simpleoverloading。
```

有人提出过generaloverloading。在Ada中，它会根据environment来判断而不是只看  
局部的，把第一步计算 3 \* 5 也直接变成复数乘法。

#### 做法无非就是从表达式最上面看下来。

第一部分就是彻底结束了。高层次的语言->AST+SymbolTable，前端就结束了。后端就  
是AST+SymbolTable->IR-> 汇编。  
从AST可以看出源程序长什么样子，基本上可以退回去。再变一次以后，它就不像高级  
语言了。后端和前端最大的区别就是，前端可以大量地使用工具解决，而后端需要手写代码。  
我们要把AST变成一个汇编，我们要先讲activationrecord。

### ActivationRecord（Frame）..........................................................................................

```
Activationrecord（AR）其实就是frame。Frame是ICS中比较喜欢用的词。
```

#### 最早的计算机是没有程序的概念的，只有执行的概念。后来我们可以把程序作为数据存

到内存中，那么我们找一个地方就把代码放进去了。后来，我们慢慢发现有procedure，函  
数之间可以相互调用。Activation就是函数的一次调用。从函数被调用到返回，就是这个  
activation的lifetime。其中变量的lifetime也是类似的定义。

有了这件事情以后，变量会变的，一会儿有一会儿没有，Fortran会直接分配变量，但  
是这样不合理，我们发现可以使用一个栈来存放这些变量，这样符合函数P调用函数Q后，  
生成P的变量->生成Q的变量->收回Q的变量->收回P的变量的特点。

#### 在很多机器上，栈从高地址开始向着低地址增长。在一次函数调用中需要维护的数据叫

做activationrecord或者frame。  
如果函数F调用了G，会有一些参数的传递，F要向G传递一些实参，而G在执行的过  
程中是formalparameters（形参），早期在执行的过程中是一个东西。本来我们的参数都是  
从右向左依次压栈的，这就是同一个东西。F向其中压栈，而G从中读出来，那么它们的frame  
就会有overlap。

#### C这样的程序有一个特点：它是有函数指针的，并且可以作为返回类型，但是没有函数

嵌套。而在tiger中函数允许嵌套，但是函数指针不能作为返回值。

两次调用f返回了两个函数，我们再去执行就可以拿到两个value。这是既嵌套又  
返回的情况，编译中比较难处理这种情况，所以我们不处理。

在过程中，我们也会生成一些local的temporaryvariable。传参的时候就是自右向  
左压栈，有寄存器了以后那就是前 4 ~ 6 个参数放到寄存器里。在tiger中要支持函数嵌  
套，并且内函数可以引用外函数的变量。g需要访问f的activationrecord。但是f和g  
的activationrecord在栈上并不一定是相邻的。我们要让g能够找到f的frame，所以我  
们需要加一个staticlink，让g能够直接跑到f的frame中。

Lab 5 就是codegene，我们尽量希望把变量能放寄存器就放寄存器（假设是无限个），  
但是最后一个lab的寄存器是有限个的。

call-by-ref（call-by-addr）实际上就是传入actualparameter的地址传进去，也就是  
传入的是左值。

call-by-restore是一个混合的方法，它有很多别名。实际上就是我们在calling之前的传  
参的时候，我们把右值传给callee，同时如果有左值的话，我们把左值的值（右值）传递过  
去。Callee的时候都是拿r-value计算，而在return的时候，会把计算完的右值copy到左值  
里去。

```
我们用的宏就是call-by-name。
```

#### 使用寄存器存在调用别人的时候，还是需要把参数存到栈上，但是对于叶子函数（不

#### 调用别人的函数），就没有这种问题。如果寄存器传参的话，最终编译器要处理这些事

#### 情，在ICS里头我们举过一个例子。

P(x,y):  
{

returnQ(y)+Q(x);  
}  
这时候我们传参的时候  
%rdi<-x  
%rsi<-y  
我们在调用第一个Q的时候  
t 1 <-%rdi  
%rdi<-y  
callQ  
t 2 <-%rax  
%rdi<-t 1  
callQ  
add%t 2 %rax  
Ret  
这时候我们发现t 1 和t 2 ，必须能跨过Q。所以我们需要把t 1 和t 2 作为callee-saveregister

#### 可变长参数至少有一个是固定的，也就是参数数量必须是 1 ~任意多。这就是一本书上

的例子，我们要访问这个变参，就通过va\_list的一个宏。我们传入第一个参数到va\_start  
中，就可以定位到第一个参数。注意va\_arg(ap,)这个函数每调用一次就会往后走。  
大家可以看到va\_start,va\_arg有一个潜在的要求是formalparameter必须是连续放的，  
否则我们的宏不能处理。所以，我们希望formalparameter是从memory中连续拿的。

#### 但是前 6 个又是要放寄存器里的。一个比较好的参数是把栈上的前 6 个位置空出来，等

到callee需要的时候，把相应寄存器的值一个个写到内存中去。

### 2021 / 10 / 29

#### 15 号期中考试

考到typechecking，我们说过的，我们是两次考试，每次考试 20 分，我们的Project是  
60 分  
上节课讲到参数通过压栈/寄存器来传参，并且传参的时候会有什么问题。今天我们来  
讲的主要是localvariables。变量的话一种就是说放到寄存器里，因为寄存器比较快。但是有  
些情况下我们也不得不把变量放到内存中，大部分时间是放到栈上。Eg：callbyref，引用变  
量地址，nestedfunction（内函数需要用到的外函数的变量），结构、数组等寄存器中放不  
下的，又比如calleesavedregister，又比如spill（局部变量和临时变量太多了，寄存器放不  
下，多出来的都放到内存里去）。  
这里有很多种变量进内存的情况，其中前三种称为variableescape（前两种需要地址，  
第三种是嵌套函数引用，在tiger中主要是第三种情况）  
这些讲的都是局部变量，也就是函数体中定义的变量需要放到内存里。还有一种是全局  
变量，在C和C++中比较明显。一旦生成了以后，程序的任何地方都可以访问这个数据，所

#### 以不能放到栈上，因为栈会随着函数调用消失。

但是在tiger中，把引号中的字符串常量，最后都是放到StaticData里头。在C里面也  
是这样处理的。我们知道在ICS里，Read-OnlyData是和Code放在一起的。

第三种情况是堆，在C++里就是用new申请的空间。在Tiger中，是把record和array  
在内存中分配固定大小的空间。在Tiger处理中，是把record和array放到堆上去的。因为  
使用了堆，所以在函数中声明数组和record以后，会在堆上分配一块空间。当我们函数结  
束以后，这两个变量就消失了。但是在堆上的两个空间还在对应的地方，tiger没有显式地  
回收掉这两个东西。在第二部分里头，就有garbagecollection，在哪个地方我们需要用  
compiler把record和array在堆上的空间回收掉。在某些点会触发这件事情，让runtime来  
接手回收掉垃圾。

Code是可读的，staticdata是可能是可读的，也有可能读写的。栈和heap是随着程序  
运行的时候会变的。对于每个栈本身的一个frame，通常frame的大小是固定的。我们现在  
知道在这两个增长的中间，我们又插入了sharedlibrary。在考虑我们程序编译的时候，就要  
考虑到内存的布局，这都是在user态的东西，往上的kernel态我们也没去管。  
下面我们重点提到在tiger中的variableescape

```
这个部分main函数在最外面定义了tree这个类型。
```

我们关心的是，main里面定义了prettyprint，prettypring里又定义了write和show，show  
里面又定义了indent这个函数。我们把main称为第 1 层函数，以此类推，prettyprint第 2  
层，write和show第 3 层，indent第 4 层。

在每一层的函数中都可以声明一些变量。比如在prettyprint中声明了tree和output变  
量。第三层的函数write可以用到外层的output变量。C因为没有函数嵌套，所以只有global  
和local变量，而在tiger中是可以的。因为只有在prettyprint调用的时候才有可能调用write  
和show，所以show和write一定是可以用到外层的output变量的。  
同样的，第 4 层函数indent用到了第 3 层的变量n、第 2 层的变量output。

那么这个indent怎么去访问到n和output呢？我们需要传递一个framepointer进去。

要让内函数访问到外函数的变量，我们需要把framepointer当做参数传递进去。Indent如果  
能拿到prettyprint的framepointer，那么我们就可以访问到prettyprint中定义的output。但  
是传递进去没那么简单，因为在indent中用到了两个变量n和output。我们在这个时候，  
是传递show的framepointer还是prettyprint的，还是两个都传？

我们先看一个简单的情况，show会用到prettyprint中的output。我们令 0 和tree压栈，演  
示调用show的时候会传参。在tiger中，是把 0 当做第二个参数，tree是第 3 个参数，而第  
一个参数是staticlink，它是一定要在栈上的。

这样show+ 8 就可以拿到staticlink。Tiger假设生成的代码都是framepointer的，后面我们  
可以用一个宏把framepointer替换成stackpointer。这就是staticlink作为参数传递进去的情  
况。

在调用indent的时候，我们可以传递show的staticlink进去。要访问n的时候，可以直接  
通过show的staticlink进去直接访问n，要访问output的情况下，就需要走两次staticlink  
到prettyprint里去找到output。

我们的直觉似乎是相邻的上层传下层。那么show递归调用了怎么办呢？

我们发现两个show的staticlink还得是prittyprint的framepointer。因为是show调用第 2  
个show，所以它要负责把prittyprint的framepoint传递给第 2 个show。

#### 下面我们来讲算法，这本书里这部分写的太烂了，龙书上写的是比较好的。

有一个procedurep，每一个函数/过程都是有深度的 _np_ 。p想要访问一个非自己局部的

变量，也就是外函数的变量a，也就是a的层次一定是比p小的。那么我们p里要访问a，  
当前我们已经在p里了。p在栈的底部是有一个staticlink的。那么我们p里要访问a要走

_np_  _na_ 次staticlink，这都是我们在编译时可以确定的，生成出来的代码是可以确定的。在

第 7 章的时候，我们翻译到non-localvariable的时候会产生出一个非常深的数据结构。当然，  
a在对应深度的frame的offset的多少，编译器也是知道的。

#### 算出

第二个问题，是我们的staticlink怎么建立起来。这个问题更加复杂。这里的indent最  
后怎么访问到output，我们这里需要建立两次。

建立的过程如上图所示，在编译的时候，我们发现函数p调用了函数x。  
第一种情况，浅的调用深的。也就是把自己的framepointer传进去，在我们这个函数  
里，prettyprint也不能直接调用indent，所以要保证深度层次相差 1 。  
第二种情况，它可以调用外函数，比如第 4 层的indent可以直接调用第 3 层write。我  
们怎么样把prettyprint的staticlink传递给write。也就是indent和write需要找到最近共同  
祖先，传入最近共同祖先即可。找到了以后，我们看indent到prettyprint要走几下，算一下，  
我们就知道indent在执行的时候沿着staticlink需要走几下。然后把它作为参数传进去。

### Displays............................................................................................................................

#### 在中文书的 95 页， 6. 1. 6 静态链

下面我们来看看display是什么意思，实际上就是在运行的时候每个函数都有一个深度，  
排序完就是 1234.

#### 有一个指针，指过去到栈帧开始的地方。

show自己调用自己的情况，那么第三层有两个show，display中我们保留最近的一个  
show，因为第一个show除了退出，不会再调用了。当第 2 个show结束的时候，上图右边  
的display需要恢复成上图左边的情况，所以在第二个show中要保存前一个show的地址，  
这样第二个show退出的时候就可以把第 1 个show的位置填进去。

```
最后一个lambdalifting
```

```
当我们g调用f的时候，escapeanalysis需要的变量全部传递进去。
我们开始讲tiger中的数据结构。
```

在我们的书上就是大写的F\_作为前缀。在这个frame里，比较重要的就是遇到一个函  
数之后，我们需要new一个frame出来，也就是给一个新的函数分配一块frame。我们讲到  
newframe的第一步没什么太多的事情，

1. 把函数名字传递进去。但是这个时候的函数名就不是symbol了。把一个函数名放  
    在那里，其实就是一个label（在汇编中的函数入口），第二个参数实际上就是一个bool的  
    链表，其实就是{true,false,false}，代表着哪些参数应该放到内存里去，第一个参数是static  
    link，是一定要放到内存中去。

第 7 章，我们要做translation，AST在变过来的时候是没有staticlink的，但是在变完之  
后，就有staticlink了，然后我们就需要调用newframe。我们在设计的时候，frame对于高  
层来说是一个不可见的namespace。因为我们要生成代码，一定是要和某个体系结构相关的。  
Frame是每个体系结构单独写的，但是其他模块都是体系结构无关的。

我们回到这里，传入函数的label和一个bool链表，对应每个formalparameters要不要  
进栈。

### Access..............................................................................................................................

有了frame以后，变量无非就是分配在栈上或者寄存器里。所以我们要设计两个数据结  
构，一个是放在寄存器中的变量，一个是放在内存中的变量。我们用一个统一的封装接口  
Access。Access类就是用来描述函数的局部变量和形参（formals）是存放在寄存器上还是存  
放在栈上。  
/_mipsframe.h_/  
#include“frame.h”  
class **Access** {  
public:virtual tree::Exp \*ToExp(tree::Exp  
\*framePtr)const= 0 ;  
}  
//其中tree是中间表达treelanguage的数据  
结构

```
/*mipsframe.cc*/
#include“mipsframe.h”
class InRegAccess :publicAccess{
public:temp::Temp*reg;
explicit InRegAccess : (temp::Temp
*reg):reg(reg){}
tree::Exp *ToExp(tree::Exp *framePtr)
constoverride
{returnnewtree::TempExp(reg);}
};
```

class **InFrameAccess** :publicAccess{  
public:intoffset;  
explicit InFrameAccess : (int offset):  
offset(offset){}  
tree::Exp _ToExp(tree::Exp _framePtr)  
constoverride;  
};  
/_frame.h_/  
classFrame{  
public:  
...  
std::list<frame::Access_\>_formals\_;  
}

变量要么是在寄存器中（InRegAccess），里面分配了一个virtual的register。  
要么在栈上（InFrameAccess），核心问题就是offset，也就是在frame中，从framepointer  
开始是负几的位置上存了这个变量。  
所以在Frame类中，我们定义formals（函数的形参）是一个Access的链表，也就是形  
参要么在寄存器上要么在栈上，

这个是说formal是一个access的链表，也就是把formal的这些形参分配了寄存器或者  
是栈上的东西。讲到这个形参，上节课讲到参数用寄存器来传的时候，虽然速度很快，但是  
会引入比较大的麻烦。  
比如在ICS中  
P(x,y):  
{  
returnQ(y)+Q(x);  
}  
这时候我们传参的时候  
%rdi<-x

%rsi<-y  
我们在调用第一个Q的时候  
t 1 <-%rdi  
%rdi<-y  
callQ  
t 2 <-%rax  
%rdi<-t 1  
callQ  
add%t 2 %rax  
Ret  
这时候我们发现t 1 和t 2 ，必须能跨过Q。所以我们需要把t 1 和t 2 作为callee-saveregister

```
Callee-saved参数进寄存器会很讨厌。
```

像MIPS中，传入r 4 和r 5 ，进来以后需要把它们移走，移到两个临时寄存器里去。参数  
超过 6 个也要进栈，在这种情况下，我们都要把这些东西放到栈上。这个栈我们可以算出大  
小，那么上来第一条指令就可以调整栈指针分配K个空间。第二条指令是r 2 是第一个参数，  
r 4 、r 5 是第三第四个参数。R 2 是staticlink，不能分到寄存器里去，必须要进栈，所以它必  
须去栈底。后面的参数我们根据boollist中是否为true来判断是要放到栈上还是要放到寄存  
器里去。

```
我们在后端生成，在tree上翻译完了以后，头尾还要添加很多东西。
```

这个frame是一个隐藏的类型，这个frame要包含locationsofalltheformals，要么在寄  
存器里，要么在栈上；还需要包含viewshift相关的指令，不同的函数的指令会不一样，但  
是要生成在frame里，这是一开始。  
可能过段时间，我们还会发现代码有很多局部变量。以及函数是一个label，在汇编的  
时候我们是需要继续操作的。

#### 有了这些东西以后，我们刚才讲到了中间要处理局部变量。来一个局部变量我们是要分

配空间的，在frame上我们需要allocatelocal，在栈上我们就传递True，在寄存器里就传递  
False，等一下我们要讲escapeanalysis。并且可能有第二个变量用到的时候第一个变量的生  
命周期已经结束了，那么这种时候x和y就可以共享一个空间。  
第三个事情，我们的局部变量是可以嵌套的。在C里的话，  
P(x,y)  
{  
intv;  
{  
intv;  
}  
}  
当退出block的时候，v还在栈上，我们认为其中变量的lifetime是整个函数的生命周期，  
等到函数结束的时候才会被回收。

### EscapeAnalysis................................................................................................................

#### 如果一个函数体中定义的变量没有被嵌套的内函数访问过，那么这个变量就是没有逃逸

的（donotescape），在runtime的时候，可以分配在临时寄存器中；如果它在内函数中被  
访问过，那么在 **runtime** 的时候，这个变量一定要分配在栈上（frame中），这样调用内函  
数的时候，内函数就可以通过staticlink进行一次或多次跳转访问到这个变量，此时这个变  
量就叫做逃逸变量（escapevariable）。确定一棵AST中所有变量是否是逃逸的行为，称为  
逃逸分析（escapeanalysis）。  
具体操作方法其实就是遍历整棵AST，查看每个变量是否在内函数中被调用过。每当我  
们看到一个变量或形参的声明时，我们就在SymbolTable的一张专门用来做逃逸分析的表  
中，添加一项<key= 变量id,value={depth（静态嵌套深度）=d,escape\_ref= 变量的escape

域的地址}>；当我们看到一个变量在深度 _d_ 1 被访问时，我们就去这张表中查看是否 _d_ 1  _d_ ，

如果确实是这样，说明是在某个内函数中访问到的这个变量，那么我们就可以直接根据表中  
维护的escape的地址，设置对应的escape为True，也就是指明这个变量确实逃逸了，需要  
在运行时分配在栈上。

C++的escapeanalysis：（来自lab 5 源码）

escape.h  
classEscapeEntry{  
public:  
intdepth\_; //变量的静态嵌套深度  
bool_escape\_; //变量的escape在AST中的位置  
EscapeEntry(intdepth,bool_escape):depth\_(depth),escape\_(escape){}  
};

usingEscEnv=sym::Table<esc::EscapeEntry>;//逃逸分析表  
usingEscEnvPtr=sym::Table<esc::EscapeEntry>\*;

escape.cc  
voidAbsynTree::Traverse(esc::EscEnvPtrenv){  
/_TODO:Putyourlab 5 codehere_/  
}

voidSimpleVar::Traverse(esc::EscEnvPtrenv,intdepth){  
/_TODO:Putyourlab 5 codehere_/  
}  
我们可以看到其实就是一个递归向下遍历整棵AST的形式。

### 2021 / 11 / 02

我们把上次的frame的一点点剩下的讲完，然后开始讲中间表示，其实这已经是中间表  
示了，Frame的结构应该是什么样的。它应该表示一些函数的数据信息，包括函数转化为汇  
编以后有一个label来指定跳转的位置，也就是callbyname。我们上节课讲了shiftofview，  
比如我们callee 传参的时候，如果是x 86 - 64 ，参数在前面 6 个寄存器，在callee看的时候，  
它认为这些形参都不是在特殊寄存器，它认为都是在temporary里。在做escapeanalysis的  
时候，如果内函数并没有访问到这个形参的话，它认为这些参数都会在临时寄存器里；如果  
通过escapeanalysis发现某个变量是被内函数访问过的，那么这个变量就应该放在栈上，这  
些都是callee来做的事情。而caller总是认为前 6 个参数在固定的寄存器中，后面的参数在  
栈上。Callee认为参数都不在指定的寄存器中，因为如果在指定的寄存器中会有很多麻烦。  
上来我们就会写很多代码，比如：  
pushq%rdi#把参数放到栈上去  
movq%rsi,t 1  
这些都是我们需要补的代码，我们用另外的方法生成出来以后贴到函数的头上去。这是  
我们要在栈上做的事情。  
临时的寄存器叫做temporary，我们就在这里定义了这样的一个类:  
temp.h  
class **Temp** {  
friendclassTempFactory;  
public:\[\[nodiscard\]\]intInt()const;  
private:intnum\_;  
explicitTemp(intnum):num\_(num){}  
};  
class **TempFactory** {  
public:staticTemp\*NewTemp();  
private:inttemp\_id\_= 100 ;  
staticTempFactorytemp\_factory;

```
temp.cc
Temp*TempFactory:: NewTemp (){
Temp*p=newTemp(temp_factory.temp_id_++);
std::stringstreamstream;
stream<<'t'<<p->num_;
Map::Name()->Enter(p,newstd::string(stream.str()));
returnp;
}
```

#### };

#### 我们认为此时有无限的临时寄存器，有限寄存器的情况我们要等寄存器分配的时候再

#### 说。

还有一个就是在functioncall的时候，比如我们有一个函数f，汇编的时候一定会有一个  
对应的label，比如说f\_：.....。包括说jump、conditionalmove等都会有label，其实就是一  
个字符串。因此在代码实现中，我们也有label这样一个类：  
temp.h  
using **Label** =sym::Symbol;  
class **LabelFactory** {  
public:staticLabel\*NewLabel();  
static Label _NamedLabel(std::string\_view  
name);  
staticstd::stringLabelString(Label_s);  
private:intlabel\_id\_= 0 ;  
staticLabelFactorylabel\_factory;  
};

```
temp.cc
Label*LabelFactory:: NewLabel (){
charbuf[ 100 ];
sprintf(buf,"L%d",label_factory.label_id_++);
returnNamedLabel(std::string(buf));
}
```

```
Label*LabelFactory:: NamedLabel (std::string_views){
returnsym::Symbol::UniqueSymbol(s);
}
```

std::stringLabelFactory:: **LabelString** (Label\*s){return  
s->Name();}  
在这里我们就可以new这个label，其实就是把一个symbol和一个指针关联起来，这样  
在之后我们就可以用这个label了。我们现在已经有了Frame类来描述我们这个栈、Access  
类来描述我们的变量，这个变量可能在临时寄存器上也有可能在Frame上。临时寄存器我  
们就用Temp类来描述，最后还有一个label类就是来描述汇编中的Label的。  
下边我们来看一下Translation的过程。  
Type-checking是自底向上扫描AST，那么扫描树的时候我们也可以处理declaration，一  
边做一边environment就有了。对于declaration的处理是自左向右的，比如：  
Letdec 1 ;dec 2 ;dec 3 ;inexpseq  
它是自左向右处理declarations的，并且处理完右边的expseq就可以直接开始用这些  
declaration。

我们马上要讲到的事情是要把high-level的AST变成一个中间表示IR（intermediate  
representation），也就是第 7 章中的tree。它是机器语言的一种抽象，因为我们要支持不同  
的高级语言和不同的机器语言，支持不同的高级语言我们是用AST来做到的，也就是用AST  
来表示不同的高级语言；支持不同的机器语言就是通过我们这个中间表示treelanguage来  
做到的，所以接下来我们要做的事情就是把我们的AST变成我们的treelanguage。  
书上给的方法就是我们扫描整个AST一次，同时做type-checking和translation。  
type-checking还是semanticanalysis的过程，里面有一部分函数就是在做translation，一边  
扫描一边我们生成treelanguage。注意，我们生成的treelanguage是体系结构无关的，但是  
我们最终生成的汇编语言一定是和ISA（指令集架构）有关的，所以我们如下图所示做了两  
层抽象的封装：

这样.c在implement不同函数的时候，可以使用不同的体系结构的指令集，但是向上提  
供接口的时候，frame.h和temp.h就屏蔽掉了底层实现的细节。包括frame我们是不希望被  
semant看到，但是一定要给translation看到的，所以我们沿用这样的思路把底层实现以接  
口的形式暴露给上层。  
在translation.h中有一个tr命名空间，其中我们定义了一个Level类，其实就是translation  
里的frame，一个Level类包含了一个Frame，但是它还有别的东西，比如一个Parent，就是  
哪个函数定义我的。当然我们tiger语言最外面有一个outermost的frame，里面定义了main。  
所以除了outermost，每个函数都是可以找到自己的parent的。  
第二件事情就是我们把frame.h里的Access类，重新定义成了在translation.h里的Access  
类。这两个的区别就是Frame::Access是针对变量的，表明一个变量要么在寄存器中要么在  
栈上，而在translation中，增加了这个Access是在哪个frame（函数里）。我们多了一层封  
装，我们同时扫描的时候能看到的数据结构都是translation里的，frame里的结构我们是看  
不到的。  
translate.h  
class **Access** {  
public:  
Level_level\_;  
frame::Access_access\_;  
Access(Level_level,frame::Access_access):level\_(level),access\_(access){}  
staticAccess_AllocLocal(Level_level,boolescape);  
};

class **Level** {  
public:  
frame::Frame_frame\_;  
Level_parent\_;  
/_TODO:Putyourlab 5 codehere_/  
};  
在type-checking的时候，我们会构造symboltable，我们只关心变量的类型是什么。在  
translation的时候，我们遇到一个变量的时候，还要关系变量应该是放在寄存器中还是放在  
栈上，我们在做过escapeanalysis以后，要把access的信息也要填到function里去。这里填  
的就是function的local变量。  
env.h  
//蓝色表示是type-checking中需要关注的变量，而橙色表示是translation中需要关注的变量  
class **VarEntry** :publicEnvEntry{  
public:  
tr::Access_access\_;  
type::Ty_ty\_;

```
//Forlab 4 (semanticanalysis)only
explicitVarEntry(type::Ty*ty,boolreadonly=false)
:EnvEntry(readonly),ty_(ty),access_(nullptr){};
```

//Forlab 5 (translateIRtree)  
VarEntry(tr::Access_access,type::Ty_ty,boolreadonly=false)  
:EnvEntry(readonly),ty\_(ty),access\_(access){};  
};

class **FunEntry** :publicEnvEntry{  
public:  
tr::Level_level\_;  
temp::Label_label\_;  
type::TyList_formals\_;  
type::Ty_result\_;

```
//Forlab 4 (semanticanalysis)only
FunEntry(type::TyList*formals,type::Ty*result)
:formals_(formals),result_(result),level_(nullptr),label_(nullptr){}
```

//Forlab 5 (translateIRtree)  
FunEntry(tr::Level_level,temp::Label_label,type::TyList_formals,  
type::Ty_result)  
:formals\_(formals),result\_(result),level\_(level),label\_(label){}  
};

我们在遇到一个function的时候，我们要填入function的frame（也就是level），另外  
还要填入label。这个就是对我们原先的EnvEntry做了一个修改，增加了一些translation关  
注的变量。  
那么我们新增了这两个东西以后，一遍扫描（包含type-checking和translation）合起来  
就叫semant。  
我们在做translation的时候：  
·如果我们在translate的一个function，它会调用tr::Level::NewLevel这个函数，new出  
来以后，就会把这个level记录到FunEntry里去。  
·如果我们 translate 的是一个 variable declaration，那么它就会去调用  
tr::Access::AllocLocal(level,escape\_)。escape\_是在semant阶段的最开始，遍历整棵AST进行  
escapeanalysis得到的。Semant会在生成机器码的时候使用到这个Access.

第三个事情就是我们有staticlink，它不是一个程序中本身有的东西，而是我们为了让  
内函数访问外函数的变量增加出来的结构，当然如果不用staticlink的话，我们也可以使用  
display或者lifting，不过在我们的compiler中用的还是staticlink。在translate的时候，我  
们看到的如下：  
当我们在函数g中尝试调用f(x,y)的时候，我们其实就是在调用：

tr::Level::NewLevel( _level_ ( _g_ ),{false,false});

在这个函数内部，因为Level只是对frame::Frame的一层封装，它事实上会在形参的最  
前面添加上一个true，再调用NewFrame(label,formals);所以NewLevel传入的是两个参数而  
NewFrame传入的是三个参数。  
刚才我们讲的有个outermost，我们现在最外面的就当做main\_lavel\_，在ProgTr里。这  
就是最外的一层特殊函数。当然我们还有一个NewLevel函数，里面主要是parent,labelname  
以及一个List定义了escapeanalysis的信息。  
整个Tiger最外面的一层叫做mainTigerprogram，它里面包含一个main函数，并且和  
main函数并列的还有一些libraryfunction（print、scan、stringequal等）。  
这就是我们的第六章。下面我们开始讲第七章。  
我们要有一个更像机器的中间表示IR。实际上AST也算一种中间表示，属于HighIR。  
现在我们的treelanguage叫做MiddleIR，下面我们还有一个Assem叫做LowerIR。编译的  
过程就是不断的中间表示变换的过程。我们通过bison把highlevel的过程变成AST，把HIR  
变成IR的过程会复杂一点。  
IR要求非常简单，AST的一部分翻译成IR，IR的group就可以真正变成机器指令。现在  
我们就来介绍这个treelanguage

### TreeLanguage.................................................................................................................

### Expression.......................................................................................................................

Tree分成两部分，第一部分叫做Expression，第二部分是Statement。我们先来看  
expression。Expression分成如下：

1. Constant常数
2. Name（symbolicconstant）:比如goto.L这个.L就是name
3. Temporary(virtualregister)
4. Binaryoperation
5. Memoryaccess（访存）：比如说(%rax)就是一个expression，要访问某个内存地址  
    上的一个value。
6. Expressionsequence：前面的都比较像汇编，而这里的不像，就是(seq,exp)。比如  
    说exp是a+ 5 ，而seq就是a= 5 ，这就是一个side-effect，最终的结果就是 10.
7. Functioncall  
    这样我们就可以把expression定义成一个类，在tree的命名空间中。我们接下来就根据  
    这 7 种情况定义 7 个子类。

#### 注意到这里没有关系表达式。因为是二元运算，所以就有左右子树。

#### 我们就这样一个个去写。

#### 为了在后面讲解起来方便，我们定义一些缩写：

CONST(i)：整数常量i  
NAME(n)：符号常量（Label）n  
TEMP(t)：临时寄存器t

_Binary_ ( _o_ , _e_ 1 , _e_ 2 )：对表达式 _e_ 1 和 _e_ 2 进行对应o的二元运算

Mem(e)：从内存地址e开始，访问wordSize个Byte（int为 4 ）  
ESEQ(s,e)：也就是(seq,exp)  
Call(f,l)：也就是调用f，传入的参数是l

### Statement........................................................................................................................

在我们定义Tree中的expression的时候，已经和tiger没有关系了，我们更希望抽象出  
一种机器语言。  
第二类的Tree就是statement，分成如下：

1. MOVE
2. Expression：把刚才的expressionclass拿过来执行计算，但是我们不要结果。比如  
    说a++，我们并没有把a的oldvalue拿出来。

3. Jump：无条件跳转
4. ConditionalJump：有条件跳转
5. StatementSequence
6. Label：注意Label和Exprssion中的Name的区别。Name是使用这个symbol，比如  
    goto.L，而Label是定义这个symbol，即.L:

#### 同样地，我们会定义 6 个子类。

在ConditionalJump的时候，会有RelationalOperator，也就是：  
enumRelOp{  
EQ\_OP,NE\_OP,LT\_OP,GT\_OP,LE\_OP,GE\_OP,ULT\_OP,ULE\_OP,UGT\_OP,UGE\_OP  
};  
类似地，我们定义如下的一些缩写：  
MOVE：分为两类，一类是把表达式移动到寄存器中，一类是把表达式移动到内存中，即：

( , )

```
( ( 1 ), )
MOVETEMPt e
```

_MOVEMEM e e_

Exp：只求值不要结果  
Jump(e,labs)：跳转到e，这个e可能是一个label或者是一个地址的表达式（其值为labs）

_CJump_ ( _o_ , _e_ 1 , _e_ 2 , _t_ , _f_ )：conditionaljump写的比较复杂一点，必须是两个表达式做关系运算，

这和汇编里的条件跳转比较一致，比如JL,JNE等。和汇编中不一样的是，一般汇编中只有一  
个target，条件成立跳转，条件不成立就继续执行。但是在我们这里，如果条件成立就跳转  
到t，条件不成立就跳转到f。

_SEQ_ ( _s_ 1 , _s_ 2 )：就是两个statement合在一起

LABEL(n)：就是定义了n作为当前机器地址的label，要使用的时候就可以使用Name(n)  
这个是我们的tree，注意一遍扫描的时候，tree也是不让type-checking看到的。  
type-checking能看到的是translation出来的东西。  
现在我们有了一个Exp，这就是我们翻译出来的Tree。这个class有三个子类，本来我  
们讲AST表示了一个expression，那么我们翻译出来得到expression就可以了。翻译出来的  
只有三样东西，Ex、Nx和Cx。  
翻译出来的Ex就是expression；第二个Nx就是一个statement；第三个Cx比较复杂，  
是一个statement加两个patchlist，定义如下：  
/_translate.cc_/  
classCx{  
public:  
PatchListtrues;  
PatchListfalses;  
tree::Stm_stm;  
Cx(PatchList_trues,PatchList_falses,tree::Stm_stm)  
:trues(trues),falses(falses),stm(stm){}  
};  
Cx我们还看不太清楚是什么东西，前两者是比较清楚的，要计算表达式的值我们就选  
用Ex，如果不需要表达式的值，就选Nx。  
下面我们来看一下，原来在做type-checking的时候，同时做了translation，也就是一遍  
扫描的时候，返回的就是如下的一个ExpAndTy：  
classExpAndTy{  
public:tr::Exp_exp;  
Type::Ty_ty;  
ExpAndTy(tr::Exp_exp,type::Ty_ty):exp(exp),ty(ty){}  
};

ExpAndTy_absyn::Var::Translate(env::VEnvPtrvenv,env::TEnvPtrtenv);  
ExpAndTy_absyn::Exp::Translate(env::VEnvPtrvenv,env::TEnvPtrtenv);  
voidabsyn::Dec::Translate(env::VEnvPtrvenv,env::TEnvPtrtenv);  
type::Ty\*absyn::Ty::Translate(env::TEnvPtrtenv);

下面我们来看Cx到底是什么东西，为什么会变的这么复杂。简单来看，x< 5 就会被翻  
译成一个Cx：  
stm=CJUMP(LT,x,CONST( 5 ),NULL,NULL)  
Cjump后面应该要跟两个label，在Cx里，我们没有把true和false对应的label没有填  
进去，把这两个变成了两个PatchListtrues和falses。也就是把这两个NULL的位置，指针指  
到True的label的位置和False的label的位置。  
为什么要这样处理呢？在Tiger的AST中，是没有逻辑运算的，Tiger语言是有逻辑运算  
的，因为要支持short-cut。支持short-cut，也就是对于表达式 a>b|c<d，如果a>b成立  
的时候，就不要计算c<d了。我们在生成AST的时候，我们把&和|变成了ifexpression。  
也就是对于tiger语句：  
_if_ ( _a_  _b_ | _c_  _d_ ) _thene_ 1 _elsee_ 2

要处理嵌套if的short-cut，本书作者就认为他的这种方式比较好。  
a>b|c<d的翻译语句如下：

temp::Label::_z=temp::LabelFactory::NewLabel();  
tree::CJumpStm_s 1 =newtree::CjumpStm(tree::GT\_OP,a,b,NULL,z);  
tree::CJumpStm_s 2 =newtree::CjumpStm(tree::LT\_OP,c,d,NULL,NULL);  
tree::Stm_s 1 =tree::SeqStm(s 1 ,newtree::SeqStm(newtree::LabelStm(z),s 2 ));

tr::PatchListtrues=PatchList({&s 1 - >true\_label\_,&s 2 - >true\_label\_});  
tr::PatchListfalses=PatchList({&s 2 - >false\_label\_});

tr::Expe 1 =newTr::CxExp(trues,falses,s 1 );  
在上例中，对于s 1 来说，如果a>b的值为True，它暂时还不知道要跳转到哪里，但是  
值如果值为False，它知道要跳转到判定第二个条件，所以我们可以在s 1 和s 2 之间插入一  
个Labelz，使其False的时候跳转到z。而对于s 2 来说，它暂时都不知道要跳转到哪里去。  
但是我们知道对于s 1 和s 2 的True的情况，它们应该是跳转到一个相同的地方的。注意上  
例中，最后我们还是创建了一个CxExp，没有转换为 0 和 1 。这是因为我们的关系表达式可  
能非常长。  
但是如果我们真的需要关系表达式来求值怎么办呢？比如flag:=(a>b)|(c<d); 这时  
候就需要把Cx转化为Ex。  
classExp{  
public:  
\[\[nodiscard\]\]virtualtree::Exp_UnEx()const= 0 ;  
\[\[nodiscard\]\]virtualtree::Stm_UnNx()const= 0 ;  
\[\[nodiscard\]\]virtualCxUnCx(err::ErrorMsg_errormsg)const= 0 ;  
};  
所以在Exp中定义了三种强制类型转换的函数。分别把三样东西转换成Exp、Stm和Cx。  
我们先来看Nx和Ex怎么转化为Ex：  
tree::Exp_NxExp::UnEx()constoverride{  
returnnewtree::EseqExp(stm\_,newtree::ConstExp( 0 ));  
}  
tree::Exp_ExExp::UnEx()constoverride{  
returnexp\_;  
}  
要么就是在后面加一个 0 ，要么就是把自己返回。  
那么我们怎么把Cx转化为Ex呢？  
上例的Cx中，有三个位置和两个label，现在我们要做的事情就是把Cx的值求出来。  
接下来就是我们要把true跳转的地方设置一个寄存器值为 1 ，false要跳转到地方设置这个  
值为 0 ，这样Cx就变成了Ex。  
tree::Exp_CxExp::UnEx()constoverride{  
temp::Temp_r=temp::TempFactory::NewTemp();  
temp::Label_t=temp::TempFactory::NewLabel();  
temp::Label\*f=temp::TempFactory::NewLabel();  
tr::DoPatch(trues\_,t);tr::DoPatch(falses\_,f);//回填操作

```
returnnewtree::EseqExp(newtree::MoveStm(newtree::TempExp(r),newtree::ConstExp( 1 )),
newtree::EseqExp(cx.stm,
newtree::EseqExp(newtree::LabelStm(f),
newtree::EseqExp(newtree::MoveStm(newtree::TempExp(r),newtree::ConstExp( 0 )),
newtree::EseqExp(newtree::LabelStm(t),newtree::TempExp(r))))));
```

其中DoPatch就是把对应的PatchList都用第二个参数填入。其实很容易理解，我们初始  
化临时寄存器为 1 ，考察conditionaljump这个statement，如果为TRUE，直接跳转到t这个  
label，返回TempExp，也就是 1 。如果为FALSE，那么就跳转到f这个label，重新设置寄存  
器的值为 0 ，并且返回。  
第八章我们要把这个代码正规化，这样才能生成代码。  
注意Nx是不能转化为Cx的，因为它没有值，所以需要报错。  
我们还是一遍扫描做两件事情，要把两件事情分隔好，不要让一边可以看到对面的乱七  
八糟的太多。  
比如说我们可以在translate中添加SimpleVar接口，可以转化成一个tr::Exp，其实就是  
一个Ex。它要去翻译的时候，Access已经可以从表中有了，也知道在哪个level，我们传进  
去以后就可以处理SimpleVar了。在translation中我们是看不到tree中的东西，看到的都是  
tr。  
另外，我们在frame.h中，还有一个RegManager，因为我们有一些特殊的寄存器，比  
如framepointer，比如returnvalue的register称为rv，有些机器它的returnaddress也是一  
个特殊的寄存器。

下边我们来看，这边要定义一个ToExp函数。我们要把treenode产生出来。Access如  
果是在寄存器中的变量，那么它返回出来的就是寄存器，如果是在内存中的，那么就会使用  
这个framepoint来计算memory的地址，来拿到这个变量。AST中是一个variablenode，在  
Tree中就变成了一个ExpressionNode。

### 2021 / 11 / 5

上节课主要讲了Cx、Nx、Ex三个部分。Lab 5 大部分都是关于翻译，算法上没有什么难度，  
主要是工程上要考虑到各种各样的结构。

语义分析需要关系程序本身，而不需要关心运行时，栈帧都是通过Access结构之间传  
来传去的，但是对于Semant模块是不可见的。这里的问题是能不能拆成两个parse来做呢？  
Semantic结束的时候，imperativesymboltable就被完全销毁掉了。  
Tr::SimpleVar()也就是在translate的时候顺带做了语义分析。  
刚才说过了Semant不会碰tree::Exp这种事情，而关注的是把symbolvariable放进symbol  
table。Tr::Access是通过venv获取的，是变量的环境中获取的（变量symbol->变量type）。  
通过这个Access，里面有这个Scope的层次，frame里面的access（在栈上和在寄存器中）。  
寄存器我们要分配编号，而栈上的我们需要分配偏移量。

这里我们加了一个registermanager，抽象一下硬件上的寄存器，在不同的硬件上有不  
同的寄存器，所以我们专门定义了RegManager，我们可以继承这个Manager在不同的硬件  
上做实现。\*FP不一定要返回一个固定的寄存器，wordsize是根据硬件的情况来决定的。下  
面还定义了一些和Access相关的东西。Frame=k对应的是从栈帧到实际变量的偏移量，也  
就是位置(fp+k)上的值。

Semant和translate在同一个parse做完，在我们要translate的时候，我们调用  
tr::SimpleVar，最终它会调用到ToExp，翻译成一个memory的exp或者是一个寄存器的exp。  
因为我们的语言包括嵌套函数，这是tiger不同于C和C++的一点。它就需要用我们之  
前提到的staticlink来取memory的位置。Staticlink是通过一个固定的位置把栈帧连在一起  
的。因为它在栈上的位置是固定的，只要我们拿到FP，就可以通过FP+ 4 来拿到staticlink  
往上走，并且编译器会计算出来需要走几层，所以我们只需要往上走到对应的位置即可。

### 数组和Record的翻译...................................................................................................

因为它是定长比较简单，对于i的访问就是(i-l)_s+a,a是array的起始地址。在C语言  
里的情况，lowerbound= 0 ，那么要访问A\[i\]，那就是addr(A)+i_ 4 ( 4 是int数组的情况)。  
field就是基地址加上整个在里头的offset，比如ICS里的alignment和padding。下面主  
要是要讲一下offset和element还是比较好算的。我们主要的还是计算变量的地址。  
数组和record在不同语言中代表什么含义呢？

这就是a和b代表整个数组的内容，所以a:=b就是把b中的内容整个copy到a里。a  
出现在了赋值语句的左边，所以取的是这个表达式的lvalue（基本上指的是地址）。在C里  
的左值都称为一个scalar。

而在C里，数组的a代表是一个地址常量。因为a不能当做左值，所以前半部分a=b  
是不合法的。而后半部分是把常量赋值给一个变量，这是合法的。

在tiger和java中，array像一个指针一样，但它不是一个常量。在tiger中， 12 个整数  
的一个数组，就是在堆（heap）上找 48 个Byte，然后在栈上再分配一个 8 个Byte的地址空  
间，这里填的是数组的首地址，在tiger中数组名代表了一个指针变量，所以在tiger中虽然  
没有指针，但是array和record的行为和pointer是一样的。它们所指向的空间都是放在堆  
上的，所以不同的语言对于不同的东西是用不同的方式来处理的。

在tiger中，这样处理就是允许的。a赋值为b之后，a所指向的原先的 48 个Byte就变  
成garbage了，等我们讲完garbagecollection就会回收掉这块堆上的空间。

现在我们的memexpression只是给了一个地址，如果我们要支持structuredl-value，那  
么我们还需要加一个size。从framepointer加一个常数，然后再说要多少个。

我们在tiger中的tree就没有size了，只有首地址。在tiger中，数组也好，结构也好，  
是一个aggregateddatatype。

这就是a\[i\]用树结构怎么表示，我们怎么计算出memory的地址。a其实是栈上的一个  
地址或者是一个寄存器，我们其实是要把这里面的值拿出来作为地址，在堆上找这个地址  
Mem(e)+i\*w。然后继续对这个地址访存找到a\[i\]的值。到底是放在寄存器上还是放在栈上，  
这是做escapeanalysis的结果。

```
Filed是类似的，编译的时候我们可以根据field直接算出offset。
```

我们讲了array和record，record比较简单，引用field的时候一定declaration存在的，  
一定有个field是f。但是数组的话，i可能越界（负的、太大），如果i不在合法的范围内，  
访问数组就会导致程序出错。这是memory中的bug。在C中产生garbage的话，其实就是  
memoryleak，如果在循环/递归中一直做这件事情，就很快没有空间了。所以我们在编译的  
时候可以做一些检查，比如boundcheck。碰到i的话，我们要看一下这个i是不是在范围内。  
Java的interpreter就是这么做的，每次访问的时候都做一个boundchecking，但是现在我们  
要把下标和两个bound做checking，比较慢。但是Java确定i不会越界的时候，可以把bound

checking去掉。

到目前为止，我们讲了简单变量、array、record怎么从AST生成一个IRtree。下面我们  
来讲arithmetic（算术运算）怎么变成tree。

在tiger中比较简单，算数也不多。逻辑运算、关系运算都变成Cx了。等会儿我们看if  
的时候，一个要支持short-cut，一个是不想支持太多临时变量，当我们需要的时候才回填会  
去。还没翻译完的时候，它就留着。  
因为AST中也没有Unary、求补我们可以使用异或来代替。翻译就没有太多的事情。

这个翻译起来就有点事情，我们可以再次看到为什么在tiger中要选出特别不直观的CX  
来。Ex就是一个表达式，Nx就是一个tree，而Cx就是非常奇怪。  
其实Cx就是说relational 和logical的expression最常见就出现在e 1 这个位置上。而且  
出现的时候，我们还要做short-cut。我们在翻译e 1 的时候，它的两个target，true和false  
都是要跳转的。这样的表示出来的Cx就会和assembly不一样，因为assembly讲的是true  
要跳，而false就继续执行后面的。  
在现在来讲，他就要两跳。在翻译e 1 的时候，两跳的target就不给他确定下来。因为  
它希望在这个地方代码可以间接一点，否则我们还需要再来一遍。而到了后面就是把true  
的地方填入e 2 ，false的地方填入e 3 。  
因此，这里我们引入了寄存器r，它在true的时候赋值为e 2 表达式的值，在false的时  
候赋值为e 3 表达式的值，最终两个分支会有一个jointlabel就是r。  
事实上，e 1 不一定是Cx，所以我们引入了unCx，强制把e 1 变成一个Cjump。

e 1 和e 2 都是relational的东西。

If拿出来主要是展现一下，为什么要有Cx这个东西。在讲到relationaloperator的时候，  
有一个特殊的是比较两个string是否相等。它实际上是调用了一个库，runtimesystem，写  
出来的behavior像relational的operator。

```
Printf(“helloworld”);
```

helloworld是一个字符串的常量，放在汇编中的datasection中。加点的东西是伪汇编，  
这是一些宏，告诉汇编器最终生成的.o(relocatableobjectfile)这些东西该放到哪里去。len这  
里也可以当做参数直接用。  
在tiger中是函数嵌套，而没有全局变量，它依然会产生出datasection（C里是全局变  
量和字符串常量产生的），因为我们有stringconstant。

在C里，加一个\\ 0 作为字符串的结尾；在Pascal中是固定长度的字符串处理。而tiger  
支持 128 个ascii字符全部出现在字符串里，分成两个部分，一个是word（ 4 Byte，最长表示  
2 ^ 32 的一个字符串的长度），后面放的是字符串。这样我们就不需要找\\ 0 来计算字符串的  
长度了。  
我们要生成字符串代码的时候，label是肯定要的，第二个后头会跟两个pseudocode.  
然后往里放常数和字符串。这是tiger中的方式。

生成好了以后，label就能用了。要用字符串的时候，其实就是一个Nameexpression。  
它可能是一个字符串的首地址，拿了这个就可以访问我们的字符串。  
Fragment其实就是datasection中的东西。  
还有一个操作是字符串的拼接操作，拼出来的字符串是在运行过程中生成的，我们就要  
放到堆上，返回出来的首地址，我们就当label来用。

```
在声明array和record的时候，我们会对其赋初值。它们是都在堆上的。
```

声明了一个n个field的record，我们就去堆上要一个 4 nByte的空间，把空间地址放给  
temp寄存器r。我们有了首地址之后，可以对空间里的每一个field去赋值。

最左边有一个functioncall，mallocn个整数，我们把这个地址赋值到虚拟寄存器里去。  
然后往memory里放一个e 1 ，第二个位置我们就去放e 2 ，......以此类推。malloc是我们编  
译里提供的外部函数。

Array初始化每个是一样的，直接调用一个外部函数init\_array直接初始化即可。Tiger  
会用到一些外部函数，外部函数只有在编译器生成代码的时候才能用这些东西。要支持  
externalcall。

#### 第一个传入函数名，第二个要传入函数的参数。在汇编中生成出来的代码名字和源程序

#### 的名字可能不一样，我们要用真正汇编里生成出来的函数的名字。

```
在while里要支持break，到了translation里也要支持break，break其实就是跳出第一
```

层循环。这边就是要把done作为一个参数传给while，break的时候就直接jumpdone即可。

Dec的返回值返回了一个Tree的表达式。我们拿到了这些tree的返回值以后，最后我  
们要加一些move语句，在let结束的时候，马上要进in了，所以我们要把MOVE都做好，  
放到最前，这样执行in的时候，就有这些值作为初值了。

Body都翻译完了以后，还需要一些指令。

我们tiger的翻译，ret、一开始的两行都不是我们transtree产生出来的东西。从头上到  
incr的第二行，从ret往下也不是transversetree产生的东西，这就是prologue和epilogue。  
Body我们已经产生出来了。

### 2021 / 11 / 9

上节课我们讲到把AST翻译成我们的tree（middleIR），但是我们翻译出来的tree基本  
上是整个汇编语言的核心一块，但是每一段汇编上来会有一块声明函数的入口等基本操作，  
要放在.text这个section中，进入到函数之前从函数出去的时候可能都要做一些准备工作、  
收尾工作，包括还有一些没有初始化的静态变量的声明。  
因此，我们在一个function除了中间的body，其他还有两部分是prolugue和epilogue。  
这也是我们在生成代码的时候需要生成出来的东西。

Prologue：

1. 伪指令
2. 函数名label的定义
3. 调整stackpointer
4. 因为tiger有函数嵌套，内函数可以访问外函数所定义的变量，所以参数也可能被  
    内函数访问，所以这些访问都需要放在栈上，但是传参的时候参数都是在寄存器中的，所以  
    进入到了函数之后，我们要把这些参数放到栈上去，对于不需要放到栈上去的参数，我们也  
    需要把这些参数从固定的寄存器移动到temp虚寄存器中。比如  
    pushq%rdi  
    movq%rsi,t 1  
    以上其实是处理ICS中比较经典的例子，也就是  
    P(X,Y){

returnQ(Y)+Q(X);  
}  
这个并不是我们做到这里的时候才做，是一开始，我们就需要把X和Y移到其他的寄存  
器中，把用于传参的寄存器空出来。这些工作也是在body之前需要做的。

5. 还有就是一些callee-savedregister  
    也就是prologue是在之前translate没有的语义，需要我们额外的生成出来。同理，函  
    数结束的时候，也有一些epilogue代码所需要做的工作。

#### 1\. 恢复栈指针

2. 把callee-savedregister从栈上pop出来
3. Return的value要放到固定的寄存器中（比如x 86 中的%rax）。

```
这些工作也是要专门做的。
```

仔细分析一下，操作 3 和 9 需要用到栈指针。所以我们就把 1 ~ 3 、 9 ~ 11 ，我们用一个单  
独的函数去处理它。

为什么要用一个单独的函数？Compiler希望做到的事情是希望支持多种target，支持不  
同的体系结构。每一个不同的体系结构，prologue和epilogue是不同的。中间的 4 这个操作  
是shiftofview，传的参数两边看过来是不一样的，不同的机器这部分也是不一样的，所以  
我们尽量让有些代码可以重用，有些代码可以修改。只有当所有寄存器都分配完了，我们才  
能执行这个函数。

我们翻译完body以后，实际上是一个Expression，我们把expression的值move到  
ReturnValueregister，每个体系结构，这个register都是固定的。剩下的都是和viewshift有  
关的。

#### 这就是我们头尾的一些处理函数。

```
到目前为止，我们的一个函数就翻译完了，产生出了两个fragment（procedurefragment，
```

产生出来的汇编代码，最终要放到.text中）在翻译的过程中还会产生一些字符串常量，生  
成StringFrag，最终是要放到.data里去的。

ProcFrag是包含指令的tree，还包括了frame的信息，主要是变量等。最后我们一边翻  
译一边把fragment放到一个list里面去，有一个就插入一个。

在translation这一层我们做了封装，屏蔽掉了底下不同体系结构的细节。这里就只需要  
翻译好的body和函数的level，在translation的时候，我们主要就是要生成viewshift。所以  
我们还需要传入formals需要进栈的信息。  
我们拿到的是一个AST，我们在traverse这个AST的时候，我们一边做typechecking一  
边做translation。Typechecking某种程度还是前端的一部分，而translation是前端到后端的  
过渡，它碰到一个函数的时候，会先new 一个level，然后再根据AST调用一系列的函数。  
它一边翻译，一边把string，也就是字符串常量（datafragment）加到fragmentlist中去。  
整个翻译完了以后，我们再把头尾加上去，就会得到一个proceduredfragment。

```
所有fragment都会被记录到fragmentlist里去，我们翻译就到此为止了。
```

### 第八章：BasicBlocksandTraces...................................................................................

#### 第八章是这门课比较难的部分。我们先来看一下，我们现在做完了一系列步骤，得到了

#### 一个IR。但是IR还是和我们的AST比较接近，即使它已经有点像汇编了。它还是一个树状

#### 的结构，而我们的汇编是链状的结构，所以第八章我们主要处理这个问题，处理完了还是一

#### 个和具体机器无关的汇编表示。

#### 到第九章，我们就要把体系结构无关的汇编表示变成一个ISA（指令集），当然寄存器

还是虚的，假设无限个寄存器，最终到了寄存器分配讲完，才会变成真的memory。  
我们先来看一个例子：  
对于tiger语句  
if(b== 0 )a=b;  
我们假设变量a和变量b都放在栈上，那么我们可以通过MEM来对a和b取值。  
其AST和treelanguagestructure如下图所示：

#### 接下来我们再来考虑翻译一个比较通用的情况。

我们有语句T\[if(E)S\]=...  
tree语句为：  
SEQ(CJUMP(T\[E\],NAME(t),NAME(f)),SEQ(LABEL(t),SEQ(T\[S\],LABEL(f))));

#### 我们注意E的部分就翻译成CJUMP。从这个地方来看，CJUMP是一个树的表示，和代

码中的表示有一点点不一样。真正的汇编指令里，我们有conditionaljump，比如jl，它实际  
上是条件成立会跳转而条件不成立的情况下就执行自己的后一条指令。而在tree里无论成  
立还是不成立，都需要跳转。所以这个差异是在我们把treelanguage转变为assem的时候  
需要处理的一个问题。

```
第 2 个tree里的问题是，
```

如果计算s的时候有side-effect，那就会导致谁先做谁后做，生成出来的指令不一样，  
所以我们也要处理这个问题。  
第三个问题也是比较类似的，把s换成一个call，也会改变。

#### 我们需要把这些不一致的地方都消除掉。

```
我们先考虑后几种情况：表达式中嵌入了其他表达式，并且嵌入的表达式有side-effect。
```

### CanonicalForm................................................................................................................

我们要把statement全部移上去，每个statement最后就会和我们的汇编比较接近了。  
到这里我们的执行的顺序就定下来了。

```
第一步：线性化
主要把expressionsequence和call都处理掉。
```

它基本规则就是一些rewritingrule。比如在做e之前，要先做s 1 再做s 2 ，我们把statement  
合在一起，把表达式放到最后去。  
两个表达式做双目运算的情况下，也是我们先让s先做，然后再做e 1 和e 2 的运算。  
Memory也是，计算地址的时候也会不同，所以我们就把语句提出来，再去计算地址。  
CJUMP中也是，把s提出来再计算。但是如果s出现在两个地方了怎么办？Expression  
sequence出现在第二个怎么办？

我们先算e 1 ，再执行s，它会影响e 2 的计算。所以我们不能把s提到最前面去，否则  
e 1 就会受到影响。所以我们要先把原先的e 1 用一个额外的寄存器t存起来，然后我们再把  
s提出来即可。

如果e 1 本身是constantexpression或者s是 nop，这种情况下是显而易见没有相互影响  
的。

我们先判这个expression是不是const，statement是不是nop。我们根据下式可以来判  
定一个s和一个e是否是可交换的。

刚才我们提到了有一些规则，最终我们希望尽量把s往外提出去。我们在s提出去之前，  
我们需要把e 1 和e 2 的值算好放到寄存器中。然后再算s和e 3.

下边我们先来看这个例子，这是一个表达式的tree，我们的目标是把s提到最前面去。我们  
先来了一个expressionreferencelist，分别指向当前尝试正规化的两个儿子中的Expssion，在  
这个例子中就是指向tree的两个子节点。然后有了这个以后，我们从右向左调用canon函  
数，把它正规化，从右向左的过程就是reorder。

最终的结果就是分成了statement和expression。我们实际上是对treenode做标准化，  
建立一个list。我们在处理MEM的时候，我们又要建立一个expressionreferencelist，不过  
此时只有一个节点指向ESEQ节点。这样我们就可以递归地往下做。

我们再递归地做，就可以得到了(s, 1 )。然后我们就把这里面的s拿出来， 1 就被我们处  
理完成了。然后我们回到上一层递归的expressionreferencelist。如果CONST和s是可以交  
换的，那么s就直接提出去了，如果是不可交换的，那么s就要生成一个move语句，把现  
在s的地方Move(e 1 ,t 1 )。

```
因为这个例子中是可以交换的，所以我们直接把s往前移动。到最后expressionreference
```

```
list中就没有待处理的表达式了，最终只剩下了一个seq和一个exp的形式，这就是rewriting
rule。
```

我们现在有StmAndExp这个结构，statement的Canon返回的就是statement，expression  
的canon返回的就是一个StmAndExp结构。  
我们会产生多个statement，合成一个statement就成为了statementsequence。这个时  
候我们可以判定一下，如果存在nop的情况，我们扔掉即可。

我们可以看一下，BinopExp的Canon函数其实就是对其左exp和右exp构造一个  
expressionreferencelist，有了这个list以后，我们调用reorder。刚才的例子中就是一个binary  
operation。  
如果是memory的话，它就调用Mem自己的那个expression，如果是Temp寄存器，那  
就不需要，直接return即可。

如果是seq，就是左右各自canon一下，然后再合并。Jump主要是把jump后面跟的  
expression，reorder一下。Jump本身也是一个statement，所以这就是一个sequence。

### 2021 / 11 / 12

上节课我们做了线性化之后，把一些有expressionsequence有side-effect的事情，我们  
就调整了。包括functioncall出现在表达式当中，我们都把这些提出来了，结果就是变成了  
一串statement。  
第二个mismatch就是在assembly中，conditionaljump只有一个target，它的false是继  
续执行后面的指令，但是在我们的IR中，conditionaljump有truetarget和falsetarget。

要做这件事情就要提到basicblock。它是一个statementsequence，具有唯一的入口和  
出口，所以basicblock它们之间的顺序是可以随便放的，因为都是通过jump指令跳入跳出  
的。但是因为我们的汇编都是串行的，我们要把图状的basicblock变成一个线性的结构。这  
样就是一个trace（把basicblock一个个排下来）。我们尽量地把CJump(cond,lt,lf)和LABEL(lf)  
放在一起。有时候可能不一定完全一样，因为basicblock可能从多个地方跳进来，那么我们  
只能让一个跟到后面来。  
上节课我们已经提到了，linearize之后，我们有一串statement，s 1 ~sn。我们从头到尾  
扫描，看到一个Label，就是一个basicblock的开始，前面就是上一个basicblock的结束。  
如果我们扫描到一个Jump或者ConditionalJump，那么这个basicblock就结束了，下一个  
basicblock就开始了。最后我们就把线性表划分成了一个个basicblock。因为看到Label的时  
候是强行划分的，所以我们要把上一个的Basicblock末尾加一行JumpL；靠Jump划分开的，  
下面的basicblock就加一个label。  
并且，如果我们扫描到最后并且不是jump，我们需要加一个done：的label，因为后面  
还有epilogue需要添加。  
线性表的划分其实就是一个StmListList（每个basicblock是StmList，组成的就是

StmListList）

因为BasicBlock都是跳进跳出的，所以可以任意排序，我们先想做的就是把CJump和  
Labelfalse排序在一起。

我们遍历Q，拿出一个Q的第一个basicblockb  
我们要check一下是不是已经放进去trace过了，如果没有就mark一下加入到trace中。  
我们扫描b的后继，如果存在没有标记的后继c，那么用c代替b，继续走循环。一直到找  
不到的情况，这个trace结束，内层循环结束。  
最终我们就变成了一个个的trace，它是线性的东西。Trace谁先谁后也是无关的，我们再做  
一遍排序。Trace的好处就是jump的target永远是挨在一起的。  
有了trace之后，我们再来查一遍：

如果CJump和Lf正好挨在一起，那么任务就达到了；如果不是，那么可能是CJump和  
Lt挨在一起了，我们需要把ConditionalJump条件反一反，那么也完成了我们的任务。  
最糟糕的情况是一个孤零零的Cjump，两个target都被别人拿走了。这样是不能生成汇  
编的，此时我们就强行增加两行，把零跳改成一跳。

然后，我们还可以再做一点优化，有可能Jump和Target挨在一起了，那么我们可以直  
接消掉相邻的情况。  
Basicblock在上半本书里，主要的任务是调整CJump。它是串行执行的，分析代码就很  
好分析。Basicblock之间会构成一个图，我们称之为控制流图（cfg,controlflowgraph）。优  
化没有在这门课中作为重点。如果要做编译相关的工作，那么就要以cfg作为基础。

我们已经把AST（HIR）变成了IR（MIR）。接下来我们要把MIR变为LIR。大家看到tree  
language有点接近汇编，但是还不是汇编。我们接下来是要把tree变成伪汇编，因为伪汇  
编中的指令是真的，但是寄存器是假的，我们现在还是假设有无限多的寄存器。我们最后一  
步就是分配寄存器，变成LIR的时候基本上汇编的样子都出来了。  
我们先来举个例子，要把Tree变成汇编：

比如我们现在有一个赋值语句a\[i\]:=x，它本身是一个MOVEstatement，左边是x，右  
边是a\[i\]。在这里我们要做一些假设，我们做完escapeanalysis后就知道放到哪里了。我们  
现在假设i在寄存器中，a和x在memory中。这样我们的tree就出来了。

我们现在有两个指针FP和SP。x和FP有一个offset，也就是offset-x。这个是在第 7 章  
translation的时候，看到一个variabledeclaration，我们会从env找escapeanalysis的结果是  
应该在memory中与否。一旦到了memory里，我们从栈顶FP开始分配一个空间给这个变  
量，所以每个变量和FP的offset我们是清楚的。最终x的地址就是FP+offset-x。然后到内存  
当中去取x的值：MEM(+,FP,offset-x)。  
左边呢，数组在tiger中是一个pointer。我们先取MEM中a的值作为基地址，然后再  
根据取数组中的第几个值来计算偏移量。

### 第九章：InstructionSelection.......................................................................................

#### 下面我们就要生成指令了，一定要指定ISA是什么。

书上用的是教学用的Jouette指令集。这边我们并不限制有几个寄存器。ADDI、SUBI也  
就是可以加一个immediate。注意这里没有寄存器之间的MOVE，在Jouette有一个特殊的寄  
存器r 0 ，放了一个只读的 0 ，比如我们要rj移动到ri中，那么就是ADDrirj+r 0 。同样的一  
个常数如果要放到寄存器ri中，那么就是ADDIrir 0 +c.  
然后就是一个LOAD指令，它支持的baseregister加一个常量来寻址。STORE就是把一  
个寄存器的值放到Memory中。  
到目前为止，Jouette的指令集都是很RISC的，为了有点变化，它加了最后一条指令  
MOVEM，允许两个Memory互相传递值。

```
我们认为除了MOVEM，其他指令都是一个cycle能完成的。
我们接下来的目标就是把tree变成一串指令。
```

#### 实现一：

因为数组a是放到memory里的，我们先把数组a的首地址读出来放在r 1 中。因为数  
组的每个元素的偏移量为 4 ，我们先把常数 4 放在r 2 中。然后我们计算r 1 +r 2 就是我们要取  
的a\[i\]的内存地址。  
实现二：

我们现在只算了x的地址，但没有把值取出来，我们直接把x的值放到a\[i\]的内存地址  
中去。

这一章的题目叫做instructionselection。也就是一个tree可能对应多个不同的指令序列  
完成相应的功能。最后我们就要选一个指令序列。

```
一条指令可以看成一个tree上的pattern。
```

#### PLUS下面不是两个寄存器怎么办呢？因为除了MOVEM之外，其他指令的执行结果都

是放到寄存器中的。所以一条指令，在tree中是一个tile，或者叫做tree的一个pattern。  
ADDI因为加法有交换律，所以有两种情况，再加上一个r 0 +c的情况。  
LOAD的话，可以是一个单独的寄存器访存，也可以是常量访存，也有可能是常量加寄  
存器的访存。  
我们在计算中间结果的时候，会引入很多中间寄存器。  
所以指令选择的过程，实际上是把tree做tiling的过程，也就是拿一个个tile来覆盖我  
们的tree。注意覆盖的过程中，两个tile不能存在overlap。  
所有地方都覆盖好了以后，我们自底向上把指令写出来，那么我们的tree就转变为了  
一串的指令。有不同的tiling的时候，生成出来的指令是不一样的。我们的目标是明确的，  
我们希望生成的指令执行时间快一点。我们在做选择的时候，如果对于RISC这种指令，如  
果一条指令执行时间（timecost）是一样的，我们选择指令数最少的。但是在Jouette中有  
一条指令cost为 2 ，所以不能使用这个方法。  
方法 1 ：全局最优，因为我们要做tiling，每个tile都是有权重的。

上图中的cost= 1 \* 5 + 1 \* 2 = 7 上图中的cost= 1 \* 6 = 6  
方法 2 ：局部最优，我们看相邻的两个能不能合成，如果合成出来代价更小，那么就选  
择。其实就是一个局部的贪心。对于RISC指令集，局部最优基本上是全局最优。大家要做  
lab就是一个局部最优的maximalmunch。

### MaximalMunch（局部最优）......................................................................................

我们从根开始做，根可能有好几种tile可以去cover的方法，我们要选择最大的那个tile  
去cover，cover完以后，tree就变成两棵子树了，我们接下来可以继续递归地去做这件事情。

右边是const的情况：

我们来以MoveStm看一下。接下来我只需要把根是MOVE的之前表格中的pattern一个  
个情况去写即可。  
生成出来的指令就是；STOREM\[r 1 +c\],r 2 。在此之前已经计算出了r 1 <-...,r 2 <-...

左边是const的情况：

#### 两个子树都是MEM的情况：

### 2021 / 11 / 16

我们上节课在讲instructionselection，讲了一个maximalmunch，每一个指令就变成了tree  
上的一个个tile，然后拿tile去覆盖我们的tree。覆盖好以后，剩下的就是有一些子树，我  
们递归地去覆盖，结束之后，我们自底向上地来生成我们的指令。后来我们看了代码，当我  
们看的MOVE的时候，实际上会根据MOVE的左子树和右子树的地方来做tiling。实际上，  
在我们tree的表达里，因为tree是一个statement，还会有如下图所示：

#### 那么我们要生成指令是：

r<-e 1  
addr 1 <-r 0 +r

针对statement的munch，我们就来判各种substatement，我们分门别类地一个个写出  
来可能的statement。但是lab 5 的第二部分，因为我们对x 86 - 64 做instructionselection，所  
以tiling的方式完全不一样，并且改成了c++了以后，这段代码也不是非常好的风格。

这边我们有一个参数instructionlist，实际上munch和emit这样的结果我们都会生成一  
条指令，最后我们就变成了一个指令的序列，每生成一个都append到list最后。

接下来我们来看expression的maximalmunch，当然我们也会产生几条指令放到最后，  
区别在于expression要返回一个寄存器，而statement的maximalmunch返回的是void。

比如上例中，e的结果会放在返回的寄存器中。  
expression的maximalmunch的例子：

注意我们先tileCONST+e，如果不匹配再tilei，这才满足maximalmunch。

这就是局部最优的maximalmunch，如果我们要做全局最优。在判断一个root节点，我  
们对任何子树都要得到最优情况，这样我们就可以继续判断当前的的情况。在这边，我们用  
到的是动态规划的想法。因为我们讲的是先对subtree做tiling，做好以后，把subtree的cost  
（生成需要几条指令，加权以后得到cost），我们把cost记录在每个subtree的根节点上。  
我们来看一个例子：

我们现在对每个subtree都来计算cost

要tile单纯的一个const，需要一条addi指令。如上表所示，后两个tiling方式的cost更少。  
最后还有一个memory的情况。

这种方式实现起来比较复杂，所以我们lab使用的是maximalmunch，再下来，如果到  
了cisc这种style。它有一些特征，当然有些特征和instructionselection没什么关系。

#### 关系比较大的是：每次寻完址就自动地加 4 加 8 。有影响是前面几个特点：寄存器少也

不影响instructionselection，到时候分配寄存器的时候可能一点麻烦。  
2 , 3 , 4 , 5 可能对我们有点影响。比如我们要支持整数除法，它用到了IDIV

这条指令它用到了%rax和%rdx，虽然只有一条指令，但是用到了两个额外的寄存器。  
注意cqto是把 64 位变成 128 位（%rdx是高位，%rax是低位，根据%rax的最高位填入全 0  
或全 1 ）。除来的结果商是放到%rax里，余数是放到%rdx里。这样一个tree就变成了 4 条  
指令，在寄存器分配的时候，我们就必须知道这 4 条指令都用到了%rax和%rdx。  
第二点是，在x 86 - 64 里算术逻辑运算只有两个操作数，它的destination和source是合  
而为一的。所以t 1 <-t 2 +t 3 需要用两条指令去实现它。  
我们还有更多的addressingmode，在访问数组的时候，我们就可以用更复杂的  
addressingmode去支持数组的访问。这就是针对一些特殊的情况我们来做优化，如果我们  
只是类似于jouette的方法来做的话，我们只有简单的addressingmode。

在我们的x 86 - 64 中，还支持( _ra_ , _rb_ , _s_ )。所以我们tiger的数组访问可以通过这样的二重

寻址方式来访问。我们可以去做优化。  
如下的算术运算，在x 86 - 64 中只需要生成右边的一条指令即可。

最后我们来看代码。我们的目的是要把treelanguage（MIR）变成一个assem（LIR）。  
这个已经基本上是汇编指令了，除了寄存器还是虚的（无限多的）。

```
大部分的指令都是operationinstruction，还有一个是labelinstruction
```

因为它只有一个标号。为什么要把moveinstruction单独从operationinstruction拿出来  
呢？因为它在寄存器分配中比较特殊，比如我们要做shift-of-view，我们可能上来就要做在  
callee中把真实register中的参数放到虚的register中去（callee-savedregister）：  
t 1 <-%rdi  
t 2 <-%rsi  
t 3 <-%rdx  
只是这种情况，我们需要把%rdi移走，但是大部分情况是不需要移走的。所以在  
registerallocation的时候，是要做move的coerce的。我们在生成汇编的时候单独作为一  
个类拿出来比较好。  
所有的instruction第一部分都是一个字符串。下面是jouette的instruction。

#### ‘这个符号不会在汇编中出现，但是标识着在指令中对应寄存器的位置。

在我们生成lowerIR的时候，第一部分就是把这条指令写出来。但是它和真的assembly  
还有区别，因为两个寄存器还没定下来。虚的寄存器就是一个TempList，分为destination（结  
果寄存器）和source（操作数寄存器）。比如add的话就会有两个sourceregister。  
第三个参数就是Target\*jumps，如果我们的jump指令，那么jump的label就会出现在  
target这里。  
现在上例中，是对fp寄存器加 8 ，也就是取staticlink。因为取出来结果要放到寄存器

里，所以我们new一个新的寄存器。

```
在寄存器分配的时候，我们必须把t 1 放进去
我们现在要做的是controlflow
```

Move是我们在做寄存器分配的时候要对寄存器做特殊处理，做collace。  
这样我们就把lowerIR变成了instruction的形式。在我们instruction这个class里，要支  
持我们最后的输出，也要支持我们的调试。我们希望能输出这样的格式。这样我们还要提供  
给一个Print函数，给了一个instruction后，我们能够打印出来具体的寄存器是通过map来  
定的。

这个table和environment一样是会一级级叠起来的。这个table实际上就是把register  
和string做一个mapping。对于一些特殊的预先有的寄存器，我们也需要添加到map中。另  
外我们的map还要负责registerallocation，把虚的寄存器变成我们实的寄存器。有了这些东  
西之后，我们来看前面的maximalmunch函数怎么来写：

我们就是对一个个subclass去写。在做MEM(e 1 +i)的时候，会先做e 1 的maximalmunch，  
会return一个register，作为MEM指令的source。MEM对应的是一个LOAD指令，结果放  
到d 0 ，其中的d 0 和d 1 会从map中拿了以后填入。

```
按照我们IR的格式生成的代码。前面这些是会生成operationinstruction。
```

```
对于labelstatement，生成的是labelinstruction。
```

```
在这个过程中，我们会生成instructionlist，我们用标准模板来生成instructionlist
```

### 2021 / 11 / 23

到现在为止，我们产生tiger都使用了framepointer，framepointer和stackpointer差了  
一个framesize。framesize一般来讲是一个整数，  
f(intn):  
{  
intA\[n\];  
}  
如果在上例中出现了变长的数组，那么我们一定要使用framepointer。在tiger中是先  
用了framepointer，到最后我们可以去掉它。

对于register的命名，我们有一个registermanager，它映射了一个map，把int映射到  
string。有一些确定的寄存器，比如stackpointer，returnaddressregister，zeroregister。在  
registermanager里，我们还要生成 4 个list。

1. 特殊用途的寄存器，returnvalue、stackpointer，etc。
2. 传参寄存器，在x 86 - 64 中有 6 个
3. callee-savedregister
4. Caller-savedregister  
    在产生call的时候，call写过的寄存器都是caller-savedregister。我们做完instruction  
    selection，就有一个instructionlist。然后我们再做了一个entryexit 2

### ProcEntryExit

Returnsink其实就是callee-savedregister，returnvalue，stackpointer，也就是在function  
结束之后还需要用到的值。EntryExit 2 其实就是在body添加了一条空指令，提醒到了这里还  
有这些寄存器是要被用到的。

### ProcEntryExit

这个函数其实就是产生一个头和产生一个尾，比如我们function是有一个label，我们  
就添加在这里。具体我们要根据汇编来生成这样的一个代码。

下边我们进入到最后一个部分：寄存器分配  
在做livenessAnalysis的时候，我们要做全局的流分析。我们再补充一个globalflow  
analysis和constantpropagation。

### GlobalOptimization........................................................................................................

其实我们在做寄存器分配的时候，我们只需要知道livenessanalysis，但是在优化的时候，  
我们需要做常数传播(constantpropagation)和死码删除(Deadcodeelimination)。

#### 3 为什么可以传过来并且删掉？

我们的一个basicblock实际上是一些statement和指令，特征就是单入口和单出口。所  
以在controlflowgraph中的节点就是一个个basicblock，指向的边就是basicblock可以跳转  
到的地方。

#### 3 没有被用到，可以删除 3 在高亮处被用到了

我们做livenessanalysis、常数传播、死码删除都是需要在这个控制流图上分析的。上图  
中的X:= 3 是一个死码，因为 3 无论走哪条路到 4 都没有被用到，那么我们就可以删掉它。  
所以我们做这件事情先要保证其正确性。

#### 也就是我们要判断X的值在某条语句中是否还是活跃的（之后是否还会被用到。）

### 变量活跃的条件.............................................................................................................

变量x在语句s中活跃的条件是：存在一个语句s’用到了x，要有一条路径从s到s’，  
并且在这条路上没有对x的赋值语句。

### 死码删除.........................................................................................................................

如果x在语句x:=...后立马就不活跃了(dead)，我们就认为这条赋值语句是死码（dead  
code）。死码就可以从程序中删除，所以在做死码删除的时候我们必须先做活跃性分析  
（livenessanalysis）。  
Example 1 :

#### 这种情况下X:= 3 处就是不活跃的，因为中间两条语句没有用过X。

#### 在做活跃分析的时候，不活跃就等于所有路上这个性质都不成立。似乎也不复杂，在我

#### 们做全局分析的时候，麻烦的事情是可能我们存在循环，导致某些路会反复走。这样我们就

#### 需要遍历整个控制流图来做分析。

#### 我们活跃分析的目标，比如说死码删除。编译器在优化的时候采取了比较保守的策略，

#### 当我们不确定某个是死码的时候，编译器为了正确性是不会删掉它的。

#### 活跃分析

我们先讲针对一个变量x的活跃分析，在程序的所有点，这个变量的活跃性的分析。也  
就是每个点我们需要知道x在这里是true（活跃）还是false（不活跃），最后我们把所有信  
息分析出来以后，对于一个赋值x:=...我们就可以来看这点上x是活跃的还是不活跃的，如  
果不活跃就可以删掉（死码删除）。

```
目标：对于变量 x ，计算其所有点上的活跃性。
要做这件事情，我们实际上用了一些规则in和out。
```

```
Lin(x,s)的含义：在in这一点，对于x是否活跃。
对于多个statement，我们有一个转移函数。
```

_Lout_ ( _x_ , _p_ ){ _Lin_ ( _x_ , _s_ )| _sisa_ }  
控制流图中一个节点可能跳转到多个地方去，每个后继节点上都会有X的liveness  
information，true代表X在这一点是活跃的，只要有一个点是活跃，那么当前的父节点肯定  
也是活跃的。

#### 根据这四个规则，我们就可以来计算活跃性分析了。

初始化时，每一个点都是false。

在 4 条规则里，false可以变true，但是true不能变为false，对于n个点的程序，存在  
2 n个L，每次循环我们至少会让一个点的值发生变化。所以这个算法是可终止的。

我们可以计算某个点上活跃变量的集合，我们在这里定义了use\[s\],def\[s\],in\[s\],out\[s\]。  
use是说这个statement用到了哪些变量（赋值号右边的变量）；def是赋值号左边的变量。

### LivenessAnalysis：数据流方程.....................................................................................

#### 活跃分析就是在控制流图上求解控制流方程。

在程序结束的地方，我们已经知道哪些变量活跃了EntryExit( 2 )。  
这样我们就计算了每个点上哪些点是活跃的，因为每个点上集合的大小总是越来越大  
的，并且存在点个数的上限，是有限可终止的。

### 常数传播.........................................................................................................................

定义：在满足某个条件的情况下，将使用到x的地方用一个常数k来代替。  
条件：在使用到x的每条路径上，最终的assignment是x:=k。  
为了仔细描述这个问题，我们定义如下的三种x的情况在每个程序点上（atevery  
programpoint）。  
value interpretation

# Thisstatementisnotreachable

c x=constantc

- Don’tknowifxisaconstant  
    x在每个点都有三个值之一#（还没开始），c（确定这一点是常数）、\*（这个点一定  
    不是常数）

```
对于每条语句s，我们可以如下定义x在某条语句前后的值。
Cin ( x , s )：在s语句前x的值。 Cout ( x , s )：在s语句后x的值。
```

### 常数传播的八条规则.....................................................................................................

规则 1 - 4 是根据s的前驱的 _Cout_ 来更新s的 _Cin_ ，是沿着CFG的边前向传播。而rule 5 - 8

是根据语句s的 _Cin_ 来更新语句s的 _Cout_ 。

### 常数传播算法.................................................................................................................

1. 对于程序中的每个入口s，我们令 _Cin_ ( _x_ , _s_ )\*（这个点一定不是常数），其他所

有语句 _Cin_ ( _x_ , _s_ ) _Cout_ ( _x_ , _s_ )#（还没开始）

2. 接下来不断根据规则 1 ~ 8 来更新相应的 _Cin_ 和 _Cout_

### 常数传播算法的中止性.................................................................................................

```
因为一条语句的绑定的值只有可能从#->c->*，所以也一定会终止。
```

### 2021 / 11 / 26

我们的lab 5 第二部分是要生成Assem，在lowerIR中和真正汇编的区别就是里面用到的  
寄存器还是虚的。  
在寄存器分配的时候，就是要把汇编指令中虚的寄存器替换成为真正的物理寄存器。因  
为通常来说temporary比真正的register要多，这时候的原则如下：  
我们之前做了livenessanalysis，当两个变量同时活跃的时候，只能在两个寄存器中。因  
为这两个值在后面都是被需要的，所以我们不能分到同一个物理寄存器中。在这里，我们这  
种就称之为两个variableinterfere。  
我们接下来看一个例子：

### InterferenceGraph..........................................................................................................

#### 在任意一个点，我们都有一个活跃信息，如果同时活跃就不能分到同一个寄存器。因为

#### 我们想让相干的变量不能分到同一个寄存器，我们就根据相干性来构造一个图。

#### 节点是变量，如果两个变量同时活跃就画一条边。这样我们就画出来了相干图，这样我

#### 们就把问题转化为了图上的着色问题。以上图为例，如果我们有 2 个寄存器，那么我们就去

#### 看这个图是不是 2 - 可着色的问题，显然是的。

如果某个相干图不是k-可着色的，那么显然寄存器是不够的，那么有些变量就要放到内  
存中去。FindingaK-coloringinallsituationsisanNP-CompleteProblem；求解一张图是几可着  
色是NPHard问题。所以求解就不太方便，我们只能使用一些启发式算法。  
具体地，相干图的构造方法为：对于一条指令i，它define了变量a，并且有一个live-out

集合： _Lout_ { _b_ 1 ,, _bj_ }，如果指令i并不是一个move指令，那么在相干图上连上边

#  a , b 1 ,, a , bj ；如果指令i是一条move指令，记作 a  c ，那么我们对满足 bi  c 的边

## 连上 a , bi ，此时的a和c可以视为虚线连接（move-related），我们是希望在coalesce操

#### 作中把这两个节点尽可能合并的。

### Kempe’sAlgorithm..........................................................................................................

这个启发式算法就是在图中找一些节点，要求节点的度数小于k，拿掉这些节点不影响  
图的可着色性。如果图是k-可着色的，因为拿掉的节点放进去边小于k，所以一定有一个颜

#### 色是可以分配给这个被拿掉的节点。我们用一个栈来记住这个节点被拿掉的顺序。

我们按照ceabd的顺序压栈，然后一个个从栈中pop（顺序为dbaec）出来分配颜色。如果  
simplify能把整张图拿掉，那么一定是可以分配出一组颜色的。

此时我们就说可能有一个值要放到内存里去。我们先选出b拿掉，也进栈，剩下这个图就可  
以继续simplify了，所以我们可以继续拿掉全部压栈。  
我们现在一边退栈一边着色，

b我们刚才说是有问题的，b放回来的时候不能保证一定能着色，但是当前这种情况，b放  
回来正好两个邻居着了相同的颜色，所以我们可以继续做下去。这种情况就是一种optimistic  
coloring的情况。

不成功的情况：

跟刚才的图拿走节点顺序是一样的dbace。给b着色的时候，我们发现b没有颜色可以选，  
这时候b肯定是要被spill（寄存器溢出）的。这种就叫做actualspill。

### ActualSpill（寄存器溢出）...........................................................................................

#### 在选取的时候，我们倾向于选择度数比较大的节点。我们希望这样的计算不在内循环中。

#### 如果在最内层循环放到了内存中，那么会有反复的读取内存操作。但是在汇编这个层次找到

#### 谁是最内层循环就比较困难了。

我们总归到最后会选择出一个temporaryb来进内存。每一次要用它的时候，我们就要  
把它从内存中取出来，每次用完了就把计算出来的值存回去。加了这段东西以后，相干图还  
是在的，但是b的liveness的range就变短了，它和别的节点同时活跃就少了。那么相干图  
的边就变少了，更容易去着色了。

#### 实际上，寄存器分配没那么简单。我们来看如下的这个例子：

我们按照顺序拿ghkfjdebcm

#### 我们代回去就得到了这个汇编，注意红色部分是有两种选择的时候随便选了一种颜色值。我

#### 们想做的事情是把它们俩赋值给同一个寄存器。分配两个物理寄存器本身没那么错，但是我

们想做的是r 4 :=r 4 ,r 2 :=r 2 ，这样这两条语句就不要了  
因为我们会做view-shift，把物理寄存器赋值给一个虚的寄存器。

_t rsi_

```
t rdi
%
```

```
%
2
```

```
1

```



ReturnQ(Y)+Q(X)  
实际上，我们发现用到了 2 个callee-savedregister，因为我们要把%rsi写到%rdi中，所以我  
们call完了第一个Q，我们需要把临时存的x释放到%rdi中，并且要把第一个Q返回的%rax  
存到t 3 中，否则会被第二个Q的返回值%rax覆盖掉。  
此时t 1 和t 3 就被变成必须的了。  
因为我们用的是procedureEntry 1 ~ 3 ， 2 我们是在每个procedure后贴了一个live信息， 1 是  
贴view-shift信息。我们会发现上面的t 2 的这个view-shift是没用的，所以我们最好在register

allocation的时候把t 2 分配给rsi，这样 _t_ 2 % _rsi_ 这一句就没用了可以删掉。

对于定义变量a的指令，在后面live-out的地方，我们有变量b 1 ~bj，我们在加interference  
的时候我们就加进去。我们在assem的时候把instruction分成了三类move，op。我们这时  
候就要判定b 1 到bj有没有一个c，如果有c的话，我们就不把这条边加进去。

#### 但是我们这条边少了以后，我们试图把这条边所连着的两个节点合在一起。但是合完以

后会有一个问题，图上的有些节点的度数会变大。这样本来那张图的度数是小于k的，但是  
我们合完以后度数大于k就不可着色了。所以这种情况我们需要避免，也就是我们在判定两  
个节点是否可以合并的时候，我们要先看是不是影响我们图的继续着色。

```
我们现在有两个启发式算法
```

### Briggs算法......................................................................................................................

a和b合并完的节点{a,b}，我们看看它的neighbour，分为两类，一类是度数小于k，另  
一类是度数大于等于k（称为significant），我们要求significant节点的个数要小于k个。此  
时我们可以先把<k的非significantneighbour拿掉，这是肯定可以拿掉了。这样{a,b}的度数  
一定小于k，所以我们可以把{a,b}拿掉，剩下的图就是原来的子图了。所以这样原来的子图  
可以做k着色，那就可以，否则就不行，所以a和b节点的着色没有影响到原来图的可着色  
性质的判定。

### George算法....................................................................................................................

我们想把节点a和节点b合起来的时候，我们说a有一些neighbour，a的每个neighbour  
也分两类，度数小于k和度数大于等于k。度数小于k的我们不管它，如果大于等于k，要  
求已经和b之间有一条边了。现在我们合并a和b即可。这样合并完b的节点的significant  
neighbour并没有增加。  
我们令S是a里的度数小于k的neighbour集合。在没有合并的时候，我们可以把S先  
simplify掉。剩下的neighbour都是b的了。所以a和b合并还是不合并都对图的可着色性  
没有影响了。

因为我们要合并a和b，所以这种节点不能simplify掉，所以我们simplify是simplify掉  
非move-related的节点。Simplify结束以后，剩下了a和b和significantnode，我们就来看a  
和b是不是能合并，合并完以后就变成了non-move-related了，我们就继续做simplify。

```
如果要分配到两个不同的寄存器中，我们就放弃合并，变成non-moverelatednode。
```

```
我们基本上就是这么一个反复迭代的流程。先做simplify，能做就做，但是只能simplify
```

non-move-relatednode。这时候我们尝试合并a和b，如果可以的话，那么合完以后{a,b}就  
变成了non-move-relatednode，继续回去simplify，如果没有东西可以coalesce，那么我们就  
去freeze，不合并这两个节点了。再上去做simplify。如果图上还有东西，所以所有的节点  
都是significantnode，这时候我们就要spill了，此时是potentialspill，标记为可能回内存，  
继续回去simplify，做到最后图就为空了，stack就满了。接下来我们就做select（退栈着色  
过程），如果标记为了potentialspill，到了某个节点可能没有办法着色了，此时我们就真的  
去做actualspill当前的这个node，重新写这个node的load和store信息。此时liveness的  
信息就会发生变化，所以我们要重新构造RIG图。然后再回来做一遍这件事情，直到最终停  
下来。肯定会停，大不了所有变量都进内存。  
这两年的考题最后一题都是registerallocation，基本上都会重新画几遍RIG的。

这样我们就把dc和jb分到了同一个寄存器里去。在simplify的时候要留下j和b还有d  
和c。新算法的流程如下

```
，我们先选d和c看看是否可以合并。它们的
```

neighbourb和j都不是significantnode，所以d和c可以合并成{c,d}。

此时cd就变成了non-move-relatednode，可以被拿走了，然后合并jb即可。

```
其实我们做的事情就是暂缓了dc和jb的simplify操作。
```

### ConstrainedMove（受限的Move操作）...................................................................

所以我们为了减少一个register之间的move，我们现在多了很多事情出来把寄存器分  
配这件事情变得比较复杂。

实际上我们在做view-shift的时候， _t_ 1 % _rdi_ 。在interferencegraph里，节点上肯定

有真的寄存器。这是参数导致的真的寄存器出现在interferencegraph中，还有一些情况，比  
如我们的长整数乘除法，它天生会用到%rdx和%rax。

如果我们机器有k个寄存器，我们就有k个precolorednode，这是一个k个节点的完全  
图。在simplify的时候，不能把precolorednodesimplify掉，我们也不能把precolorednodespill  
掉。

接下来我们要处理functioncall。Callee-savedregister的行为如上图右侧所示，我们希望上来  
把callee-savedregister都存到，出去前再给它恢复。Prologue和epilogue在其中有一部分就  
是要做的事情。

caller-savedregister

我们为什么要coalesce，就是为了处理callee，caller和view-shift。Call这条指令是一条  
opinstruction，后面跟了两个dest和source还有一个label。在destination里，就是把  
caller-savedregister全部放进去。在functioncall的时候，我们假设其一定被写过，除非我们  
做interprocedureanalysis。所以我们就在那个里把define放到这里。

我们看到r 1 和r 2 是传参的，r 3 是一个callee-savedregister。r 1 又作为返回值的寄存器  
来使用。

第二部分就是codegeneration我们要做的事情。第一部分做完以后就是一个trace。有  
了frametiling完就是一个instructionlist。

我们把trace里的一个个statement来做tiling，然后我们合到一起来做ProcEntryExit 2 。  
生成shift-of-view、生成头尾， 2 是做registerallocation来用的。

### 2021 / 11 / 30

#### 上节课基本上讲了寄存器分配的原理，我们以下面这个例子为例。

R 1 和R 2 是传参的寄存器，R 3 是callee-savedregister

在结束的时候r 1 和r 3 是活跃的，这就是procedureentryexit 2 干的事情。大家在生成instruction  
selection最后一步会加一条liveout的register。我们从最后开始一点点往上走，做liveness  
analysis从而构造interferencegraph。如果两个变量同时活跃，那么在interferencegraph就  
有一条边。  
R 1 ,r 2 ,r 3 是precoloredregister，构成了一个完全图。在goto后面c和d就同时活跃了。  
如果我们的死码没有做死码删除，那么f<- 1 是要放一个寄存器去存的，所以f和后面的变量  
也会有interferencegraph。

3 条虚线对应r 3 和c（有一条赋值），r 2 和b，r 1 和d。所以dbe是在内循环中出现的，

#### 变量进内存，出现的次数越多，那么访存次数也会越多，我们优先考虑内循环出现的尽量不

要spill掉。外循环我们就要看出现的次数。我们对内循环的次数 \* 10 来放大这个因素。这  
样spillpriority的时候，我们就优先拿掉。大家在做lab的时候就随机选一个就行了。  
所以我们先拿掉c，标记为potentialspilled的点。

现在剩余的几个点都是move-related，不能去做simplify了。我们只能去做coalesce。  
Briggs可以用来作为非temporaryregister。它合并完以后，significantnode会小于k。

Ae合并完以后，只有r 2 是significantnode。下面再要合并的时候都是temporary和  
precoloredregister，此时我们使用的是George方法，我们得出结论r 2 和b可以合并，要把  
b合并进r 2 里，ae也可以合入r 1 .但是d和r 1 不能合，因为ae的degree= 3 ，所以不是r 1  
的neighbour，合入以后r 1 会多一个neighbour。

此时d和r 1 ae就叫做constraintmove，我们就可以去掉这条边，也就是freeze掉。接  
下来我们就可以拿掉，然后把d拿掉。

我们发现c和r 1 ，r 2 ，r 3 都有neighbour，此时c就必须真的spill掉。因为r 3 是一个  
callee-savedregister一旦我们中间用到r 3 的话，必然要push-pop一次。

再要用c的时候，就去从memory里拿出来，这样c 1 和c 2 的liverange就特别短。新  
增的 2 个节点，度数为 2 和 1 很低。通过spill方法，这个图更加容易着色了。

我们在spill的时候，每spill一个变量，我们就在内存中增加一个空间去放这个变量。  
如果a和e都被spill了，在上例中就会导致memory中来回copy。所以coalesce也可以对  
于spillednode来做。这样减少memory之间的move。如果有比较多的temporary都被spill  
了之后，来回的内存move是很昂贵的，在x 86 中，必须先load到register，再move到对  
应的内存里去，所以会浪费寄存器。因此，我们希望尽量地去coalesce，尽量把a和e放到  
同一个memory里去。

所以，我们要对于spillednode再去做一次interferencegraph，如果是赋值就是一条虚  
线。Simplify比较容易，因为memory是无限的，不需要关心是k-可着色的。

```
真的要产生spillinstruction的时候，在生成指令之前，我们需要给这些变量分配空间。
```

### 在Tiger中寄存器分配的实现......................................................................................

```
前面是lab 6 的原理，后面是lab 6 的实现。
```

首先，我们有graph这个class。Controlflowgraph是有向图，而interferencegraph是无  
向图。给定一个图G的时候，我们可以在图上增加一个节点。节点会和一些信息关联起来，  
代表了basic-block、code、temporary、precoloredregister。在构造节点的时候，信息就会attach  
到节点上。

在controlflowgraph中，节点代表了一些指令，每个节点之后，我们还需要liveout  
information，这种我们该怎么样在图上画呢？可以直接绑定到节点上，节点维护一个指针，  
此外还可以用table来维护。

```
这个Instr类里对每条instruction构造一个def和use，实际上就是destination和source。
```

```
有了图的基本结构后，我们就来构造CFG和RIG
```

### ControlFlowGraph.........................................................................................................

map就是用来记录关联信息的。

InterferenceGraph

在每个节点退出的地方有一个livenessinformation。MOVE之间会有一条虚线。

bitmap就是一个n\*n的矩阵，如果有 1 就代表有一条边。在我们书上实现的时候，邻  
接表只有temporary，而bitmap既有temporary，又有register。节点上会关联到一个  
move\_count 如果其不为 0 ，那它就是一个move-relatednode。还需要记录下每个节点的  
degree。

**procedure** Main():  
LivenessAnalysis()  
Build()  
MakeWorkList()  
**repeat  
if** simplifyWorklist!={} **then** Simplify()  
**elseif** worklistMoves!={} **then** Coalesce()  
**elseif** freezeWorklist!={} **then** Freeze()  
**elseif** spillWorklist!={} **then** SelectSpill()  
**until** simlifyWorklist={}&&worklistMove={}&&freezeWorklist={}&&spillWorklist={}  
AssignColor()  
**if** spilledNodes!={} **then**  
RewritePrograms(spilledNodes)  
Main()  
其中

simplifyWorklist：度数 _k_ 的非move-related节点列表。

worklistMoves：可以做coalesce的move指令集合。

freezeWorklist：度数 _k_ 的move-related节点列表。

spillWorklist：度数 _k_ 的节点列表。

spillNodes：被spill的节点列表。  
这就是一个总体的伪代码。小于k个节点，要么是可以simplify的，要么是可以做coalesce  
的，剩下的就是>=K的degree的节点，就放到spillworklist。

Basic\_block中的指令逆序来看，拿到一条指令先看看是不是move指令，如果是move  
那么就有一个use和有一个def。所以每个变量要和live中的每一个节点画一条边。

#### 我们先要判定这两个节点不一样，并且这条边不存在。

```
我们根据图中的节点的度数以及是否move-related来构建这几个list。
```

处理过的move-related我们就要去掉。

#### 节点的度数减一之后，性质可能发生变化，可能就变成一个好节点了。

### 2021 / 12 / 03

我们上节课开始讲了Coloring的实现，数据结构之前提过了，主要是一个图，图的话是  
使用邻接表来做，这里面还用了一个bitmap，在实现registerallocation的时候，里面使用了  
大量的列表，主要是list和set。List第一个就是把节点给分类了，这个节点分类呢，是按照

我们度数的大小来分，分成了significantnode（度数 _K_ ）和non-significantnode

（度数 _K_ ），度数 _K_ 的节点又分成两类。

SpilledWorkList：里面放置了度数 _k_ 的节点，也就代表这些节点不能简单地从图上拿

走。因为我们的temporaryallocation算法说的是，如果节点的度数 _K_ ，那么可以简单地

从interferencegraph（相干图）上拿掉，拿掉以后不影响我们最终着色的结果。

度数 _K_ 的节点又要分成可以直接从图上拿掉的节点和move-relatednode。对于

move-relatednode来说，就是一条moveinstruction把两个节点联系在一起，比如说 _x_  _y_ ，  
此时x和y都不能从图上拿掉。那么什么时候可以拿掉呢？如果x和y可以合并（coalesce），  
那么我们可以把x和y合并成一个节点后，再从图上拿掉；还有一种情况是，它们不能合并，  
那么我们要把move-related的虚线重新加回实线，让x和y变成相干的，这个就是freeze操  
作。

所以我们就把度数 _K_ 且non-move-related的节点放入SimplifyWorkList中，而

度数 _K_ 的move-related的节点放入FreezeWorkList中。那我们整个寄存器分配，上来先

做活跃分析，然后构造interferencegraph。在构造interferencegraph的时候，一个是根据变  
量的活跃信息来构造边，不过这里有一点变化，就是moveinstruction导致的相干性我们要  
通过虚线来连接。  
**procedure** Main():  
LivenessAnalysis()  
Build()  
MakeWorkList()  
**repeat  
if** simplifyWorklist!={} **then** Simplify()  
**elseif** worklistMoves!={} **then** Coalesce()  
**elseif** freezeWorklist!={} **then** Freeze()  
**elseif** spillWorklist!={} **then** SelectSpill()  
**until** simlifyWorklist={}&&worklistMove={}&&freezeWorklist={}&&spillWorklist={}  
AssignColor()  
**if** spilledNodes!={} **then**  
RewritePrograms(spilledNodes)  
Main()  
其中

simplifyWorklist：度数 _K_ 的非move-related节点列表。

worklistMoves：可以做coalesce的move指令集合。

freezeWorklist：度数 _K_ 的move-related节点列表。

spillWorklist：度数 _K_ 的节点列表。

spillNodes：被spill的节点列表。

我们重温一下构造相干图的方法：对于instructioni，我们的livenessanalysis是backward  
analysis（从程序结束的时候的变量活跃信息来倒退前面的每一条instruction的live-in和  
live-outinformation）。i这个instruction有def集合和livenessout集合。

### 我们要做的就是对{ def }{ out }{ use }这个笛卡尔积在相干图中连上边。如上就是

build操作做的事情。  
接下来的makeworklist其实就是，我们已经得到相干图了，接下来按照节点的度数以及  
是否是move-relatednode去分类。

**procedure** Build()  
**forall** b  blocksinprogram  
**let** live=liveOut(b)  
**forall** I instruction(b)inreverseorder  
**if** isMoveInstruction(I) **then**  
live  live\\use(I)  
**forall** _n_  _def_ ( _I_ ) _use_ ( _I_ )

_moveList_ \[ _n_ \] _moveList_ \[ _n_ \]{ _I_ }

_workListMoves_  _workListMoves_ { _I_ }

_live_  _live_  _def_ ( _I_ )

**forall** _d_  _def_ ( _I_ )

```
forall l  live
AddEdge(l,d)
```

_live_  _use_ ( _I_ )( _live_ \\ _def_ ( _I_ ))

Build函数中，在处理move指令时，我们需要特殊处理一下，比如说存在如下的两条  
move指令：

_I x y_

```
K x z

```

```

:
```

:

那么我们从后向前遍历的时候，就要把指令I和指令K加入到moveList(x)中，表明这是  
和变量x相关的move指令。并且要把move指令加入到workListMoves里去，表明这些move  
指令可以准备做coalesce的。如果做完coalesce，在freezeWorklist还存在节点，那么我们就  
做freeze，也就是把虚线变成实线。

到目前为止我们的准备工作已经做好了（把节点和指令都分类完毕了），接下来我们进  
循环正式开始着色流程，注意到每次循环我们只处理一个节点，按照Simplify,Coalesce,Freeze,  
SelectSpill的优先级去做。注意到这里的SelectSpill的结果是potentialspill，也就是当我们退  
栈放回来的时候，是有可能能够着上色的。

**procedure** AddEdge(u,v)

**if** (( _u_ , _v_ ) _adjSet_ )( _u_  _v_ ) **then**

_adjSet_  _adjSet_ {( _u_ , _v_ ),( _v_ , _u_ )}

**if** _u_  _precolored_ **then**

_adjList_ \[ _u_ \] _adjList_ \[ _u_ \]{ _v_ }

degree\[ _u_ \] 1

**if** _v_  _precolored_ **then**

_adjList_ \[ _v_ \] _adjList_ \[ _v_ \]{ _u_ }

degree\[ _v_ \] 1

其中adjSet是一个元素取值为 0 或 1 的矩阵，如果 _adjSet_ ( _i_ , _j_ ) 1 ，那么就说明在相干

图上i和j有一条边。而adjList其实就是邻接表，也就是每个节点都有一个head，如果有一  
条新的边连出去，就加载head对应的list的末尾。并且，因为我们在adjList中不加入machine  
register，只加入temporaryregister，所以我们在加入adjList的时候，需要判定一下u和v  
是否是precolored（也就是machineregister）。注意到machine(hard)register的颜色是固定  
的，是不能从图上被拿掉的。所以我们把precolorednode都当做significantnode来看待。

#### 其实就是对节点分类。

**function** Adjacent(n)  
adjList\[n\]( _selectStack_  _coalescedNodes_ )  
Adjacent这个函数说的是，我们希望找到n在图上的邻居是谁，因为我们在一次过程中  
不再会删除图上的内容，所以我们对于已经进栈的元素要手动剔除掉。还有一个需要考虑的  
就是合并的元素，比如说 _x_  _y_ 这条move指令，最终我们把x和y合并成一个节点了，我  
们不会说在图上把x和y删除，然后新增一个{x,y}节点，因为这会让我们重新构建bitmap  
和adjacentlist。所以我们使用x来代表y，而y就加入到coalescedNodes中，在所有操作中  
被手动剔除即可。

**function** NodeMoves(n)

_moveList_ \[ _n_ \]( _activeMoves_  _worklistMoves_ )

这个函数就是询问节点n，是否还有move相关的指令。因为我们过程中会做一些freeze，  
做了freeze之后，某些move指令就会被拿掉。activeMoves就是那些还没有准备好做coalesce  
的move指令。

**function** MoveRelated(n)

_NodeMoves_ ( _n_ ){}

如果某个节点没有move相关的指令了，那么它就是一个可以simplify的节点，不能再  
放在freezeWorklist中了。

因为simplifyWorkList中都是non-move-related的度数 _K_ 的节点，我们可以从中拿出

来进栈然后减掉对应的度数。

度数减一可能会引发一系列的事情，因为如果度数减一之前是度数 _K_ 的节点，那么

度数减一之后就会变成一个好节点。然后我们根据其是否是move-related，把spillWorkList  
中元素放进freezeWorkList或者simplifyWorkList，注意到成为一个nonsignificantnode之后，  
此节点及其邻居如果存在move-related关系，可能可以再次做coalesce，因为无论是Briggs

算法还是George算法都是会根据邻居的节点度数 _K_ 类似的条件来判断的，所以我们要

把这些节点从activeMoves移动回workListMoves。  
**procedure** Coalesce()

**let** _m_ ( _x_ , _y_ ) _workListMoves_

_x_  _GetAlias_ ( _x_ )

_y_  _GetAlias_ ( _y_ )

```
if y  precolored then// 保证第一个元素是 precoloredregister （如果有的话）
let (u,v)=(y,x)
else
let (u,v)=(x,y)
workListMoves  workListMoves \{ m }
```

```
if (u=v) then //u 和 v 已经被合并到一个寄存器里的情况
coalescedMoves  coalescedMoves \{ m }
AddWorkList(u)
elseif v  precolored ( u , v ) adjSet then//u 和 v 有一条边（实线）又有虚线
```

的情况，我们就 **freeze** ，保留实线，如果 **v** 是 **precolored** ，根据前面的， **u** 也是 **precolored** ，  
显然相干；或者就是 **u** ， **v** 因为某种意义存在了实线的情况

```
constrainedMoves  constrainedMoves { m }
AddWorkList(u)
AddWorkList(v)
```

```
elseif
( ( ) ( ))
```

```
( ( ), (, ))
u precolored Conservative Adjacent v Adjacentu
```

```
u precolored t Adjacentv OK tu
  
```

```
   
then
```

**//** 第一种情况： **u** 是 **precolored** ，使用 **George** 算法，对于 **v** 的度数 _K_ 的邻居，

**George** 条件要求必须也是 **u** 的邻居。  
**//** 第二种情况： **u** 不是 **precolored** ，使用 **Briggs** 算法，我们考察合并完的节点的  
度数 _K_ 的邻居的个数是不是小于 **K** ，如果确实小于 **K** ，那么就满足 **Briggs** 条件。

```
coalescedMoves  coalescedMoves { m }
Combine(u,v)
AddWorkList(u)
else
activeMoves  activeMoves { m }
```

constrainedMoves：src和dst相干的move指令。  
coalescedMoves：被合并的move指令  
我们从workListMoves中拿出一条指令，它一定是 _x_  _y_ 的形式，但是x和y此时可能  
已经被合并了，那么我们需要找到代表x和代表y的节点，就是通过如下的这个GetAlias函  
数：  
**function** GetAlias(n)  
**if** _n_  _coalescedNodes_ **then**

GetAlias(alias\[n\])  
**else** n  
我们是要递归地从alias中得到某个被合并节点的代表节点的编号。当move(u,v)被合并  
的时候，我们就令alias\[v\]=u。  
到最后，如果既不满足Briggs条件也不满足George条件，我们就把这条指令放进  
activeMoves（当前setting已经被考虑过不能做coalesce的情况）。只有当我们合并的节点

以及其邻居的状态发生了变化的时候（如：度数 _K_ 变为了度数 _K_ ），那么我们再把

对应的指令从activeMoves移动回workListMoves，再考虑新的setting能不能做coalesce。只  
有这样，我们的算法才能够终止，如果我们没有activeMoves这个集合的逻辑，那么我们循  
环每次都是coalesce失败，并且导致算法陷入死循环。

**procedure** addWorkList(u)

**if** _u_  _precolored_ !(MoveRelated( _u_ ))degree\[ _u_ \] _K_ **then**

_freezeWorkList_  _freezeWorkList_ { _u_ }

_simplifyWorkList_  _simplifyWorkList_ { _u_ }

在合并时，u还是在freezeWorkList中的，如果它是precolored，那么我们不去管它；如  
果它还存在move-related关系，那么它还是在freezeWorkList中；如果它既不是precolored，

也没有move-related关系，并且度数 _K_ ，那么合并完的这个节点就是一个普通节点，加

入到simplifyWorkList即可。

**function** OK(t,r)

**return** degree\[ _t_ \] _K_  _t_  _precolored_ ( _t_ , _r_ ) _adjSet_

Geoge算法的辅助函数：也就是合并r和v的时候，对v的邻居t考察，要么其度数 _K_ ，

要么度数 _K_ 且同时也是r的邻居。当然t如果是物理寄存器，那么r在我们的算法中也

是物理寄存器，它俩显然也是有一条边的。

**function** Conservertive(nodes)  
**let** k= 0  
**forall** _n_  _nodes_  
**if** degree\[ _n_ \] _K_ **then**

```
k  k  1
return (k<K)
Briggs条件判断，也就是合并完的节点的邻居集合中，度数 K 的邻居的个数是否小
```

于K。

**procedure** Combine(u,v)

**if** _v_  _freezeWorkList_ **then**

```
freezeWorkList  freezeWorkList \{ v }
else
spillWorkList  spillWorkList \{ v }
```

_coalescedNodes_  _coalescedNodes_ { _v_ }

_alias_ \[ _v_ \] _u_

我们要把v合并到u里去，显然v只有可能存在于freezeWorkList或者spillWorkList中，  
我们从中把v去掉加到coalescedNodes集合中去。因为使用u来代表v，我们需要设置  
alias\[v\]=u，并且u的moveList需要继承v的moveList。因为此时v的状态发生了变化，之前  
不能做的move指令的coalesce可能可以做了，所以我们还需要EnableMoves(v)。最后，我  
们需要把v的邻居全部连到u上，并且把u根据其度数放到对应的集合中去。

**procedure** Freeze()

**let** _u_  _freezeWorkList_

_freezeWorkList_  _freezeWorkList_ { _u_ }

```
simplifyWorkList  simplifyWorkList { u }
FreezeMoves(u)
当simplify和coalesce 都不能做了以后，那么我们就要把 move-related的
freezeWorkList中的节点真的freeze掉。
```

**procedure** FreezeMoves(u)

```
forall m ( x , y ) NodeMoves ( u )
if GetAlias(y)=GetAlias(u) then
v  GetAlias ( x )
else
v  GetAlias ( y )
```

_activeMoves_  _activeMoves_ { _m_ }

_frozenMoves_  _frozenMoves_ { _m_ }

**if** _NodeMoves_ ( _v_ ){}degree\[ _v_ \] _K_ **then**

_freezeWorkList_  _freezeWorkList_ { _v_ }

_simplifyWorkList_  _simplifyWorkList_ { _v_ }

```
如果都干不了了，我们只能强行选一个放到simplifyWorkList中，并且去掉
move-related关系。
```

最终我们一个个退栈。当前退栈退出n，我们就来看n的邻居的颜色。我们把对应的颜  
色从okColor中去掉，如果不剩颜色了，那么这个n就不能被着色；否则就随便选一个颜色  
着色。

真的要被spill的，我们就重新写代码，把对应的位置做loadandstore，当然这里也可  
以重新做coalesce。

### 在Tree上做寄存器分配................................................................................................

```
下面呢，我们的书上还提了一点，就是我们能不能直接在tree上做registerallocation。
```

在tree上不太好做spill，但是它可以计算某一棵子树需要几个寄存器。这时候我们就有  
一个全局变量n，初始化为 0.

我们从根这个地方开始做tiling，就会分出一些子节点。每个子节点我们递归地算一下需要  
几个寄存器。因为在根节点计算的时候，子树的寄存器的值不会被别人改变，所以我们可以  
复用这个寄存器。

所以我们先去做一个label，先扫描一遍看看每个子树要多少个寄存器。然后我们真的  
分寄存器的时候，我们看看左右要多少个寄存器。

### 2021 / 12 / 07

#### 到寄存器分配基本上就是一个完整的编译器了。

虽然我们经常认为垃圾回收是在java这种比较安全的语言中去做的，但是在C和C++  
中也有实现垃圾回收的项目。总的来说，垃圾回收的前提是我们有一个堆，在tiger中用到  
堆的情况就是我们的数组分配还有我们的record分配。所谓的dynamicallocation，栈上的分  
配我们认为是比较static的，因为栈上分配的生命周期通常是和我们的frame的生命周期一  
样的。而堆上分配的变量的生命周期是相对独立于执行流的，frame的退出可能会导致堆上  
的变量的一些引用没有了，堆上的不再被引用的变量（notreachable）其实就是垃圾。  
假设一个c的代码只做malloc不做free，我们不断push和pop新的frame，这样很多  
对堆上的引用就没有了。在c和c++里面，我们认为这是一个memoryleak，因为这块内存  
就不能再被使用到了，导致程序最终outofmemory。在有运行时的一些语言，比如  
java/Go/C#，提供了垃圾回收机制，其实就是找到垃圾对象然后把堆的情况释放出来。  
对控制流的静态分析是可以规约到停机问题的，我们不能很清楚地知道每个对象的life  
cycle，所以对垃圾对象的判断是通过reachable来判断的。

比如我们栈上有一个a，引用了堆上的b。比如说我们用完a之后再也不使用a了，此  
时b其实已经是个垃圾了。但是在静态分析的时候限制比较多，比如说有一些分支用到了b  
而有些分支没有用到b。这样子就不太好判断。所以垃圾回收机制主要还是使用可达性，也  
就是只要有引用指向b，我们就认为是活着的。如果此时a被另一个指向堆上的变量d的c  
覆盖了，那么根据可达性我们就知道没有人再指向b了。

#### 这里有一个例子。注意我们暂时认为垃圾回收的点是一些程序中的定点，我们先不考虑

怎么触发垃圾回收机制。这个时候x和y已经没有用了。在这里活跃的变量只有pqr三个变  
量，而红色标注出来的其实就是我们的x和y，此时已经没有指针指向他们了。

#### 后面我们来讲一些具体的垃圾回收算法。

### MarkandSweep..............................................................................................................

通常我们会建模成为graph，这个图里的节点要么是程序变量，要么是堆上的record，  
而边就是引用关系。Markandsweap分为两步。Mark就是图遍历的过程，把从root（栈上  
的程序变量）开始遍历做可达性分析。而sweap就是把堆扫描一遍，因为我们已经标记过  
对象了，我们认为没有被标记的对象就是垃圾对象，我们回收掉这些对象，并且被标记过的  
对象回重新取消标记，以便下一次mark操作。  
我们还有一个freelist作为空闲列表，我们每次要分配一个新的record的时候就会从空  
闲列表中分为空间，如果空闲列表为空，就会触发垃圾回收。  
**function** DFS(x)  
**if** xisapointerandpointstorecordy:  
**if** recordyisnotmarked:  
marky  
**foreach** field _fi_ ofrecordy:

DFS( _y_. _fi_ )

Mark阶段：  
foreachrootv:  
DFS(v)

Sweep阶段：  
plastaddressinheap  
whilep<lastaddressinheap:

```
Ifrecordpismarked:
unmarkp
else:
let fi bethefirstfiledinp
```

_p_. _f_ 1 freelist

freelist _p_

_p_  _p_ ( _sizeof record p_ )  
就是一个DFS的图遍历。在sweep的时候，如果一个recordp已经是垃圾了，我们可以  
把freelist的指针放在p的第一个field中。这样我们就不用专门生成一个freelist来存储信息  
了。

### MarkAndSweep的开销................................................................................................

首先，mark的执行时间和活着的record的数量相关。而sweap是全堆扫描，所以sweap  
时间是和堆的大小有关的。

GC的效果就是我们把freelist重新填满了，可以填充的数量是H-R的大小。如果R和H  
差不多大，那么就是堆上活跃的record基本上快填满堆了，所以我们的总的cost很大但是  
并没有回收掉很多内容。此时可能我们不应该做垃圾回收，而是扩展这个堆，或者抛一些  
out-of-memory的异常。  
如果R/H大于 0. 5 ，其实垃圾回收的效用就比较差了，也是建议让回收器去增加堆的大  
小。

### ExplicitStack....................................................................................................................

#### 面临的问题： DFS 会创建太多的栈帧。

#### 我们先讲DFS的问题，它是通过递归函数实现的，每多一层的访问都会创建一个新的

stackframe，这样开销是比较高的。举个极端的例子来说，我们有一个长度为一百万的链表，  
我们就要一直DFS下去，这样我们生成的frame就会有很多。当我们做图遍历的时候，如果  
我们结构整体是一条链，那么我们的节点的遍历深度就会很深。

解决的办法就是不要使用原先的栈帧，而是使用自己实现的vector替代原先的栈。函  
数逻辑如下：  
**function** DFS(x)  
**if** xisapointertorecordywhichisnotmarked  
marky  
_t_  1  
_stack_ \[ _t_ \] _y_ //把深搜的起点加入  
**while** t> 0 :  
_y_  _stack_ \[ _t_ \]; _t_  _t_  1 //取出栈顶元素

**foreach** field _fi_ ofrecordy

```
if y. fi isapointertorecordzwhichisnotmarked:
//指向了一个没有标记过的record
markz
t  t  1 ; y  stack [ t ] //加入栈中
```

因为我们并不知道栈的深度可能是多少。我们把栈顶的field拿出来遍历一遍。这个和  
原先的算法没有什么差别，但是使用了explicit的栈来代替了c++系统的栈帧。现在我们每  
一个record只需要一个entry来保存它的port，就可以达到节省内存的目的。还有，我们给  
栈分配的内存不会很多，通常只是MB级别的。而当我们使用vector的时候，就没有大小的  
限制了。

注意到这部分并不是什么编译原理限定的内容，这在OI/ACM的一些特定场景下，是一  
个很常见的优化方式。

### PointerReversal..............................................................................................................

后面还有一个pointerreversal的优化。这个方法的本质就是说，对于每个对象来说，一  
旦访问了这个field并且把这个field放到了栈上，后面是通过栈来访问这个reference的。

比如原本是x指向y，接下来我们会把x的指针放到栈上，接下来我们就直接通过栈上  
的引用来访问y的值。这样子x就可以用来存放一系列别的东西。

结论：在pointerreversal之后，我们就没有栈了，使用了一系列record的指针来把栈的  
信息嵌入在里面。这个有点像书上介绍symboltable的一些反向指针。

done\[y\]是表示y有没有做完，也可以作为mark过程来看。它的作用就是来判断y里面  
的三个field有没有处理完。当我们处理完了以后done\[y\]= 3.

#### 这个方法可以节省内存开销，本来我们还需要在内存中额外一个栈去存，现在我们只需

要把指针都存在field里面就可以了。现在的垃圾回收算法通常不会使用field来存，比较麻  
烦，并且可能多线程不好处理，并且栈的占用可能并不是很大，没必要这样去做。

**Freelist**

方法就是类似malloc，把list分成好几种，比如小于 128 B，小于 512 B，小于 4 K等，分  
几个类，当我们想malloc 1 K的时候，就可以从 512 ~ 4 K去找，我们的目标就是减少freelist  
的时间，避免扫描全部的freelist。

```
总结：算法由mark和sweep组成，mark时间和活着的record的数量相关。而sweap
```

是全堆扫描，所以sweap时间是和堆的大小有关的。值得注意的是用DFS完成的，后续有  
一些算法会使用BFS。

### ReferenceCount..............................................................................................................

#### 第二个算法是一个理论很完美，但是操作起来很多问题的算法。思路就是对每个

reference记录一个引用，比如在文件系统中多个进程引用了一个文件。我们可以通过  
referencecounting记录到底有几个进程引用了这个文件，直到其为 0 就说明没有人引用了，  
我们就可以删掉了。还有一个例子就是virtualmemory引用了物理页的情况，当引用没了以  
后就可以释放这个物理页了。所以在垃圾回收中可以使用类似的方法，我们给每一个record  
加一个field叫做counter，也就是有多少个引用了我。

上左图为原先的情况，右图为 _X_. _f_ 1  _Y_ 的情况，引用从Z改变为Y了以后，原引用- 1 ，

新引用+ 1 。如果引用的counter为 0 了，那么我们就加到freelist中，所以在上例中，对象Z  
需要被回收放到freelist中。

### Deferreducingthereferencecount................................................................................

在上例中，Z被加入到freelist以后，我们暂时不修改它的field引用：A和B的reference  
count，而是当Z被freelist拿出来赋值为新的G的时候，我们才去修改并检测A和B是否需  
要回收。  
为什么要做这个defer的实现呢？因为在我们之前做mark和swap的时候，我们会把全  
堆做扫描，而referencecount只需要看对象身上的元数据就知道它的死活。所以这个算法可  
以比较好的实现对时延要求比较高的垃圾回收算法。如果是一个很复杂的树对象死了，根节  
点一死可能所有节点都变成了 0 了，如果不defer的话，可能回收要占据很长时间。所以defer  
的优化，每次只回收一层，把过程拆分的很细，这样对于应用的影响比较小，分配和回收都  
很快地完成。

算法的优点：这个算法设计简单、实现简单、可以很快回收。  
算法的缺点：我们不会把事实上已经死的对象很快地回收掉，这被称为浮动垃圾，可能会造  
成内存的占用量高一些。

### RC的性能开销高...........................................................................................................

#### 算法问题 1 ：性能开销高，每次我们对引用的写操作就要多写很多指令。如果是多线程

#### 去做的话，+ 1 和- 1 还需要用原子指令保护起来。

比如我们想赋值 _x_. _fi_  _p_

_z_  _x_. _fi  
c_  _z_. _count  
c_  _c_  1  
_z_. _count_  _c_  
**if** c== 0 :  
callputOnFreelist  
_x_. _fi_  _p  
c_  _p_. _count  
c_  _c_  1  
_p_. _count_  _c_

场景 2 ：Swift语言用的是referencecount作为垃圾回收，这个开销可能在极端情况下有  
40 %~ 50 %的应用占用。

### RC不能解决相互引用的问题.......................................................................................

第二个问题就是解决cycle问题，这是referencecount的死穴。也是因为这个原因导致  
不能应用在大型系统中。  
最极端的例子就是两个对象相互引用的情况，如下图所示：

```
referencecount算法那就不能回收这种对象。
```

解决方法分为两种:  
解决方法 1 ：Swift认为这个需要靠程序员去打破这种cycle，可以通过weakreference的机制  
或者通过软件工程的模块化去避免相互引用。  
提供了weakreference：也就是在内存压力大的时候，我们可以忽略一些引用（弱引用）。  
也就是在内存压力大的时候，弱引用的虚线就无效了，也就是x的referencecount会变  
成 0 ，然后x被回收，然后y的referencecount也变成 0 ，这样x和y都可以被回收了。

这个比较适合用在read-onlycache里面，因为cache拿到以后是为了加速我们本地的访  
问，如果能hit就用本地的，如果不能hit，我们就从网上拉这个数据，所以内存压力大的时  
候可以回收内存中的cache，无非是再从网上拉一份这个数据。

解决方法 2 ：一段时间内如果referencecount回收的不够多，再调用markandsweap算法作  
为backup。

### Copy算法........................................................................................................................

copy算法和marksweep有点相似，它也是基于标记的，从root出发它也会找到 3 个活着的

#### 对象。

它一定有一个space是空的用来接收我们的对象，from-space和to-space是可以相互转  
化的。copy以后我们对象就更加紧凑了。  
这个算法的核心好处就是分配快，所有的数据都被copy到顶端去了，后面的都是  
freespace，所以我们只需要一个next指针就划分出了已经使用的区域和free的区域。

#### 所以分配的事情如果大家考虑的比较多，就可以考虑使用这个算法。

### Cheney’sAlgorithm.........................................................................................................

这边给了一个Cheney’sAlgorithm，它提出了一个基于BFS的copy算法，核心就是这个  
forward算法。  
**function** Forward(p)  
**if** pisapointertofrom-space **then  
if** _p_. _f_ 1 pointstoto-space **then**  
//如果已经被别人copy走了，我们不需要对同一个对象再copy一次  
**return** _p_. _f_ 1  
**else**

**foreach** field _fi_ of(\*p)

_next_. _fi_  _p_. _fi_ //注意此时next.fi里的指针还是指向from-space的

_p_. _f_ 1  _next_ //from的第一个field指向to-space

_next_  _next_  _sizeof record p_

```
return p. fi
else
return p
```

**function** Main()

```
scan  next  beginningof to  space
foreach rootr
r  Forward ( r )
while scan<next
foreach field fi atscan
```

_scan_. _fi_  _Forward_ ( _scan_. _fi_ )

_scan_  _scan_  _sizeof recordatscan_

在这个算法中每个record的第一个field就是垃圾回收专用的，一定会指向copy后的位  
置，它保证了不会把一个对象copy到两个地方的地方。

因为Forward只是把根直接连接的一些record放到了To-Space中，而引用的field的指  
针还是From-space中的指针，所以Scan就是把剩余的引用到的所有对象放到To-space中。  
当scan=next之后，算法就停止了，因为我们把所有可达的对象全部复制到了To-space中。

所以我们其实是一层层fieldcopy的，所以是按照广度优先搜索的思路去做的。广搜的  
好处就是把to-space天然地用成了队列。

```
坏处就是局部性比较差，比如一棵树的record，会破坏子树的局部性导致性能下降。
```

### 2021 / 12 / 10

我们继续讲Cheney算法，它是一个基于BFS的copy算法，对象进来了以后，它是一层  
一层copy的。如果我们有一棵树，它是按照树的层次遍历顺序copy的，这会导致子树的  
locality并不好，所以BFS会导致局部性下降。  
所以就有人提出可以优化这个算法。  
**function** Forward(p)  
**if** ppointstofrom-space **then  
if** _p_. _f_ 1 pointstoto-space **then**

```
return p. f 1
else
chase(p)
return p. f 1
else
return p
```

**function** Chase(p)  
**while** (p!=nil)  
_r_  _nil_  
**foreach** field _fi_ ofrecordp

_next_. _fi_  _p_. _fi_

**if** _next_. _fi_ pointstofrom-spaceand _next_. _fi_. _f_ 1 doesnotpointstoto-space **then**

_r_  _next_. _fi_

```
p. f 1  next
p  r
```

_next_  _next_  _sizeof record p_

所以就有一个半深搜算法，没有改变本质，但是加了一个Chase函数。把pcopy完以  
后，我们不马上返回，我们去看p的record。

我们发现r没有一个forwardingpointer指向to-space，也就是r还没有被copy。此时我  
们把r记录下来。所以r记录的就是record里最后一个没有被copy的reference。

所以半深搜会把record中的一个field一路最终下去copy，局部性会比原先的BFS好一  
点。

### CopyCollection的开销..................................................................................................

#### 、

因为我们copy只copy活对象，所以总开销和活着的recordsize相关。书上认为c 3 = 10 。  
在我们使用的时候，我们永远只能使用一半的空间（另一半的空间要作为copy的目的地），  
所以一半的空间被浪费掉了。进一步降低cost需要分代GC。

### GenerationalGarbageCollection....................................................................................

#### 即大多数新创建的数据是很快会死的，比如面向对象语言中会在函数中分配很多对象，

#### 然后在函数结束就立马消亡的，而存活很久的对象，如网站的一些全局配置对象，有时候应

#### 用就会查询全局配置，这些就是一直存活的对象。

#### 所以对象和对象之间的寿命是不一样的，所以这个算法本身就是把这些对象分配，它比

较关心年轻的对象。回到之前的copyGC中，如果我们对那些长寿的对象反复地在from-space  
和to-space来回copy，就非常浪费性能。  
所以算法分代的意思就是把堆进行分区，一个比较general的想法就是把堆分成很多代，

年龄从小到大依次是 _G_ 0 , _G_ 1 , _G_ 2 ,...。主流实现就是年轻代 _G_ 0 和老年代 _G_ 1 。分代GC大部分

时间只回收G 0 ，也就是最年轻的代，它也会负责对象的分配。

```
这里有一个问题就是，我们考察如下一个场景：
```

倘若我们只通过Root的引用来判断 _G_ 0 ，那么我们会错误地把 _G_ 1 引用到的变量回收掉，

导致 _G_ 1 中的对象的指针非法。所以当我们回收的时候，我们的出发点是 _Root_ , _G_ 1 , _G_ 2 ,...中

的所有record。

分代GC只是一个架构，并不限定具体使用什么算法，我们也可以在 _G_ 0 内部分成

from-space和to-space，只是说过一段时间我们可以把年龄足够大的copy到 _G_ 1 中。

#### 不过根据统计来说，从老年代往年轻代的引用这种情况下相对是比较小的，因为在创建

对象的时候，正常情况下它的field会指向更老的情况。而在对象创建后使用一个年轻代的  
对象更新field的情况相对比较少。

为了避免对老年代做变量扫描，我们需要记录下来老年代指向 _G_ 0 的reference，所以编

译器会要记录下来这种情况。

1 .RememberedList

最早的方法就是使用一个列表来记录，每次我们来更新一个引用的时候，如 _b_. _f_  _a_ ，

并且b是老年代的，而a是年轻代的，那么我们就把b记录进一个列表里。但是这种实现的  
问题可能就是b会被重复加到列表中。

2. RememberedSet  
    为了避免重复的情况，我们可以在对象中放一个bit来记录它是否在List中。

3. CardMarking  
    思路是把内存分成很多个逻辑上的card，每一个card包含 512 Byte

一个card对应很多对象，一旦置为 1 ，我们在card中遍历一遍，是折中的方法。

可以很容易地对应成页表。一旦更新过了，page就是dirty的。我们可以主动地把页标志成  
read-only的，这个syscall是mprotect。如果有人去写它就会发现pagefault，然后用户可以  
自己注册一个pagefaulthandler来记录page的dirtyness。这个就是转换成了硬件的实现。

GenerationalCollection的整体的workflow：我们开始的时候只要知道哪些对象拥有G 0 的指  
针。因为引用可以改变，所以只是可能拥有reference。越往上，越老的代，回收的频率越  
低。

#### 当一个对象经历了多次回收还存活以后，我们就让它成为更老的一代，具体的值取决于应用。

假设大部分刚创建的对象都很快消亡了，那么相应的开销是c 3 / 9 ，而刚才CopyCollection的  
开销是c 3 。

所以分代就是分开管理不同生命周期的对象，降低了存活对象的比例，也降低了开销。

我们之前提到的回收方法都是停顿式回收，以copycollection为例，也就是当我们要  
allocate一个record的时候，我们发现from-space满了，那么应用程序就要阻塞在那里等待  
我们回收算法执行完毕释放出空间来。  
停顿式垃圾回收算法的好处就是，在回收的时候我们占据了所有计算资源，所以性能更  
高，并且应用程序阻塞在那里，我们不需要考虑和应用程序的同步，所以正确性比较容易保  
证。  
但是垃圾回收的占据时间可能比较长，比如 10 +G的堆可能就要几秒十几秒，这对于交  
互式应用是很不友好的。

### IncrementalCollection（增量回收）............................................................................

#### 可以想到，增量回收是每次回收一点，和应用交叉执行的，所以我们定义两个角色：

#### 1\. 回收器：负责垃圾回收

2. 修改者（mutator，其实就是我们的应用）：我们认为应用的事情就是不断在修改  
    数据的referencegraph。

在这个基础上我们提出incrementalcollector和concurrentcollector。  
增量垃圾回收就是应用需要的时候触发；而并行垃圾回收可能就是堆到一定程度了以后  
会和应用并行执行，此时应用可能在任何状态。

```
三色模型就是把record的状态分为三种，分别是黑白灰。
白色：对象还没有被GC访问过。
灰色：对象被GC访问过，但是它的儿子还没有被访问过。
黑色：对象和它的儿子节点都被GC访问过了。
```

思路就是把之前的标记算法（mark&sweep、copy）做进一步的抽象，通过三色的方式  
表达。

#### 三色算法保持正确性需要保证两个特质：

#### 1\. 不能有黑色对象指向白色对象，我们只会出现黑->灰、黑->黑、灰->白的情况。

2. 所有的灰色对象都应该在collector的管辖范围内，我们可以通过栈、队列等记录下来。

#### GC过程保证不让这两个性质被违反。因为应用此时也在修改数据，就有可能出现让一

#### 个黑色块引用白色块的情况。要解决这个问题，我们就要对所有写操作插桩，也就是当我们

要让一个黑色对象的field为白色对象的时候，我们把白色对象染灰。

#### 我们可以发现垃圾回收中的一个普遍思路就是通过虚拟页来管理，因为垃圾回收关注的

#### 事情无非就是某一块有没有写、有没有读，所以这和虚拟页的想法是一致的。这个方法就是

以页为单位来管辖，一旦发生一个pagefault，我们把这个page中的所有对象全部重新标记  
为灰色进到队列中重新处理，所以这个开销就比较高。

#### 我们写的时候运行黑指向白的情况，它认为只有应用观察到的时候才会有问题，所以当应用

读到这个对象的时候才把b染色成灰色，保证了应用永远不会从黑色对象中拿到一个对白色  
对象的引用。

#### 变成了虚拟内存的思路，所以我们要把页标记成不可读。

### Baker’sAlgorithm............................................................................................................

当我们进入allocation时，我们也要进入回收，当allocation完毕的时候，我们回收也结  
束。有些时候分配没有失败的时候，我们也要回收，这就是和之前的停顿式回收算法不同的  
地方。

首先Baker也延续了Cheney的设计，也是分成了From-space和To-space。From-space  
接收分配的对象，而To-space接收拷贝的对象。  
当From-space满的时候，这个算法开始。  
第一步就是filpping，把两个区的角色对调，这一步Cheney是在垃圾回收结束后改变的。

因为是allocation的时候触发，所以我们还是要分配出来空间给应用的，它想出来的办  
法就是从尾部开始分配。而前面的空间就用来垃圾回收。这样就不会把活对象和新对象混在  
一起，有一个局部性的好处。我们可以认为刚创建的没有任何引用的对象可以直接认为是黑  
色的。

如果我们allocateN个byte，那么我们至少就要scanN个byte，让回收能够追上分配的  
速度。

此时这一步的回收基本上完成了，下一步我们就是要让mutator去执行，交还给应用去  
执行，应用就会加载一些reference进来。我们的最终目标是在GC之后，所有对象都在

From-space，让To-space完成下一轮的GC，所以此时加载的reference，我们不能指向To-space。  
我们要检查所有的引用，这个方法就是插桩read操作来完成。也就是对于加载的执行  
To-space的reference，我们立马做forwarding，把它copy到From-space。

当scan和next重合的时候，GC就结束了，此时所有对象都copy完了。当活着的对象  
比较少的时候，就可以使用这个算法。

每次垃圾回收我们都可以很快完成，我们每次只需要copy一部分就返回给应用了，对  
于实时性较高的应用是比较好的。缺点就是overhead比较高，我们要对每个读操作插桩，  
比较当前对象的forwardingpointer是否指向自己（有没有copy），包含了内存访问和分支  
操作。

```
最后稍微讲一下并行回收，算法基本上思路一样
```

#### 麻烦的地方是同步指令的加入，因为这是两个线程，应用和回收器可能在任何时候修改和

copy对象。可能回收器刚刚完成扫描，把当前对象标黑了，此时应用立马把一个引用修改  
到了白色对象上。因为很多行为不是原子的，很容易出现这种情况。  
解决方法也很多，最简单的操作就是加锁/原子指令/虚拟内存的pagefault。

还有一些硬件支持的feature，比如硬件事务内存等。总之就要考虑更多同步方面的事  
情。

### 2021 / 12 / 14

### GC的实现.......................................................................................................................

#### 我们需要让编译器产生一些GC相关的信息，然后让GC去处理。

首先是allocation的生成，需要从堆上分配。GC需要知道每个record对应的field是不  
是指针；第三个就是Root是怎么判断出来的，我们需要从根对象出发找到存活的对象，最  
后一个就是barrier，也就是上节课讲到的并行/增量GC中对读和写可能需要一些插桩，来  
维持并行/增量GC的不变量。

Allocation为什么重要呢？教材上做了一个分析：对于内存密集型应用（图相关算法、  
机器学习型算法），我们会访问很多内存节点，还有函数式语言（不太鼓励更新）。  
在这种场景下，分配是比较多的，假如我们每 7 条指令就有 1 条memorystore的话，  
每一次memorystore都会对应一个allocation，相当于把七分之一的时间都放在了allocation  
上。

```
我们看一下copyallocation的步骤。
```

#### 1 和 6 就是分配+返回。

我们来看一下怎么优化，对于 1 和 6 我们可以inline一下。

所以overhead不会很高，通常为 4 个instruction。我们在做后端优化的时候，如果发现  
在一个basic\_block中既有allocateA也有allocateB，我们可以简单地合并成allocateA+B。

### DataLayoutDescription..................................................................................................

第二部分就是怎么描述datalayout。因为我们的GC需要record的size的大小，并且在  
Forward函数中，我们的GC需要判断一个record的field是否是一个pointer。所以这些都需  
要我们的datalayoutdescriptor来描述。

一个简单的方法就是给每个record都添加一个descriptor，这个在面向对象中也是很常  
见的。比如说C++中的虚表来查询最终函数对应到的是哪个对象的成员函数。这个我们就可  
以认为是descriptor的一种实现。  
所以对于面向对象语言，它总是要生成这些东西的，所以没有什么额外的开销。  
而对于staticallytypedlanguage，就需要一个word的额外开销。因为在编译的时候，我  
们是可以通过padding等需求计算出我们的malloc的大小的，而GC是在运行时操作的，已  
经丢失了编译时的信息，所以我们需要这个field来额外维护这个信息。

首先原本的alloc\_record就是传入一个int进去，因为我们现在的tiger都是一些 64 位的数据  
结构。我们现在参数传一个string进去，string的长度就是record的长度，而每个byte就表  
示是否是一个pointer。（如P表示pointer，而N表示非pointer，或 1 表示是pointer而 0  
表示是非pointer）

注意这个string放到堆上会很麻烦，因为这个信息我们是在type-checking之后我们就知  
道的，所以我们可以把这个string放进.data区域。

对于array的情况，比如长度为 100 ，array元素为record的情况，我们可以用 100 个 1  
来描述，也可以自己设计一套解码机制来压缩长度。

怎么去描述根对象？在traceGC中，都是从根对象出发去trace这些活着的对象。在运  
行时，栈上会不断生成指向堆的指针，除了栈以外还有寄存器可能包含root。我们知道往哪  
里找，但是我们不知道哪些是指向堆的。

早期的时候，我们就把栈和寄存器全部扫一遍，全部试试看能不能指向堆。比如 0 x 0  
不在堆的范围中， 0 x 1233 没有对齐肯定不是， 0 x 1200 符合条件，可能是指向堆的指针，那  
我们可以进去看一下是不是一个record。这样做的时候，当我们猜到在这里面以后，我们该  
怎么找到对应的record头。  
这种基于猜测的方法就叫做approximateGC。  
它的缺点是：运行时的一些integer可能被错误地认为是pointer，导致死的record被标  
记为活的record继续存活。

### ExactRootDescription....................................................................................................

怎么建立exactrootdescription呢？方法就是建立一个pointermap，在编译期间生成一  
些和指针相关的description，因为编译器在编译期间，type-checking后，我们知道所有变量  
及其类型是什么。

它的内容包含栈上的内容和callee-savedregister。我们在调用alloc\_record的时候插入一个  
pointermap的生成。

```
为了处理嵌套调用的情况，我们对于每一个函数调用都插入一个pointermap。
```

```
在寄存器分配的时候，那些溢出的变量我们也可以知道它是否是一个pointer。
```

那么怎么存呢？因为pointermap是编译器决定的，所以我们每个callsite只会生成一个  
pointermap。既然是静态的生成，我们就可以把它放到.data段。我们可以看到每个pointer  
map的元素如上右图组织，首先第一个值是指向上一个label的位置，也就是链表的形式把  
整个pointermap连起来，第二个指向的是call后的returnaddress的label，唯一标识了这个  
call。后面就可以放一系列的寄存器的pointer信息和栈上的pointer信息。

在运行时的时候，我们有一个call，拿到其返回地址以后，我们就在.data端从链表头开  
始搜索，每次找的时候比对第二个元素是否相同。所以我们用.global来标识链表头在哪。

那么我们栈上的内容怎么存值呢？我们只需要存栈的偏移量即可。我们通过%rsp加上  
这个offset来找到这个偏移量。

寄存器的存放的一个简单的方法就是我们把callee-savedregister全部push到栈上，然  
后复用之前的这个偏移量。

此时我们就不能单纯考虑自己了，因为caller中的rbx可能在callee中被spill到了栈上，在  
这种情况下我们就必须维护住rbx是个指针的信息。所以caller的信息要传递给callee，callee  
拿到这些信息要生成对应的calleemap。  
在这样的结构下做GC是没有意义的，因为callermap中的 1 并不代表它在寄存器中，  
我们需要通过信息的传递不断地去寻找。

#### 简单函数的话直接把 0 和 1 往后传即可。

这样传总得有一个尽头，到达uppermostfunction的时候，我们重新调用naive算法来  
把对应的寄存器push到栈上。

我们的栈是多个frame组成的，所以GC不得不去递归地扫描这些frame，因为每个frame  
都有自己的pointer。  
我们可以把frame\_size也放到pointermap里，这样我们就可以不断对%rsp+frame\_size  
从而得到上一个frame在哪。

这里有一个比较特殊的情况，在guess算法中发现了一个指向record中间的情况。这种  
情况下就是pointer指向数组的中间或者record的中间的一个field。此时我们是没有它的信  
息的，我们不能盲目地往后继续扫描。这种就叫做derivedpointer（派生指针）。在这种情  
况下，单单从root开始找是不够的。

此时栈上已经没有a的指针了，但我们做GC的时候不能认为a死了。我们要认为数组  
的生命周期和其中每个field的生命周期是一样的，我们持有数组a的derivedpointer的时候，

不能认为a死了。  
这在编译期间也是比较容易的，我们可以判断出派生指针，然后记录下来它的base  
pointer。

#### 这里就讲完了除了GC本身要做的事情。GC的实现麻烦在元数据生成的过程中，也就

是把AST中的变量类型往后传到最后寄存器分配。而在GC阶段，触发就是在allocation的  
时候，扫描栈就是通过%rsp不断加上frame\_size得到，然后我们在.data中的pointermap中  
找到对应的frame的pointermap，把对应位置上的栈或寄存器标记为root，最后有了root  
marking以后就是做垃圾回收了。

GC的时候就通过GLOBAL\_ROOTS来扫描整个pointermap的列表。key对应的就是callsite  
处的returnaddress。注意这里助教的实现是一个循环的链表。

### ModernGCinJava..........................................................................................................

最后我们介绍java中的现代GC，这个算法是一个停顿算法，所以主要覆盖的是分代算  
法和copy算法。

parallelscavenge是java 8 之前的默认GC算法，近几年java比较重视GC，出了很多个  
新的。  
这个算法是一个分代算法，回收过程分为年轻代回收（from-tocopy）和年老代回收（全  
堆回收、就地copy）

年轻代专门留出来一块分配的区域，from-to存的是相对年纪大的对象，而Eden区大部  
分年龄都是 0 。

所以minorGC在现代的垃圾回收中，就需要使用多核GC来实现。遇到的挑战分为三部  
分：  
1 .rootassignmenttoGCthreads  
2 .Copyrace  
3 .work-stealing

这个header包含了很多OO中的信息。对于两个worker都copy了一个对象到to-space  
的情况，我们把设置From-space中的forwardingpointer认为是一个原子的操作，worker 2  
想置这一个field的时候发现worker 1 已经置上了，那么它就把自己的指针指向worker 1 的  
copy位置，并且把自己copy出来的对象删除掉。

workstealing

很有可能出现任务分配不平衡的情况，当我们发现worker 1 的任务太多的时候，我们worker 2  
就可以从worker 1 的末尾去偷任务，也就是实现为一个双向队列。

在全堆GC的时候，内存比较紧张，不能做from-tocopy，我们只能做in-placecopy。其  
实就是在自己的区域中做copy，相对来说效率没那么高。在summary的时候我们可以准确  
地算出所有存活对象的新地址，算出来以后GC就变成了一个确定的算法，这样多核处理就  
没有什么压力了。

两个bitmap表示对象的开始和结尾。我们规定destination一定在另一个区域去接收这  
些对象。我们只需要依次找到，copy进来就可以了。  
但是我们的compaction的区域是非常不充足的。

这样就出现了依赖问题，第二块需要等待先全部copy走以后，source 3 才可以copy到  
destination 2 中。

### 2021 / 12 / 17

#### 函数式语言教材里会将两个基础的概念：

1. 函数本身不再像是面向过程中使用的function。  
    这个function还是有很大差距的。我们在接触计算机前就知道了y=f(x)，数学上的函数  
    就是两个集合之前的映射。在计算机中对这类函数的叫法叫做equationalreasoning，也就是  
    不管在什么时候传入相同的参数x，那么f(x)永远是相等的。  
    我们回想一下imperativeprogramming，很容易不是这个结果。比如引入一个全局变量。  
    比如f(a)=a+b。

varb:= 10 ;  
letf(a)={  
b=b+ 1 ;  
returna+b;  
}  
每次进入函数的时候，全局变量b的值会改变，导致每次传入相同的a但是返回值变了。这  
个改动的全局状态就导致我们函数的返回值不相同，这就叫做side-effect。  
所以我们如果要追求函数式的话，它会要求你不修改全局状态（如：堆里的状态）。要  
设计纯正的functionalprogramminglanguage限制是比较多的。  
还有一个重要的特性就是高阶函数（把函数作为参数传入），通常函数式语言应当支持  
这一点。应当可以支持传入参数作为参数/返回一个函数作为返回值。我们可以认为普通的  
函数是一阶的，而把函数作为参数传入是二阶的。  
它会带来一些复杂的东西，比如内部函数会使用外部的变量，通常来说高阶函数都会有  
这个特点。那问题就来了：到底哪个才是函数式语言的本质呢？

所以high-orderfunction通常是我们写程序的时候碰到的东西，没有这个特性我们就感  
觉不到我们在用函数式。Equationalreasoning我们不一定感受得到，但是一定要尊崇这个定  
义才算做函数式。  
所以我们在这里介绍 3 种不同的函数式语言。  
Fun-Tiger:Tiger+higher-orderfunctions，但是C/C++也有函数指针，我们通常认为C是  
一个imperative的语言，还不算做函数式。  
PureFun-Tiger:Fun-Tiger+no-side-effect，在Fun-Tiger的基础上保证了 equational  
reasoning的部分。  
Lazy-Tiger:Fun-Tiger+lazyevaluation，传入的函数的好处是不用立即返回值，最后我们  
讲延迟计算的语言。

### Fun-tiger..........................................................................................................................

我们先讲Fun-Tiger，我们需要加入一些grammarrules，让它支持函数式。首先要加入  
箭头（marker）。  
复习一下在语法翻译中，有翻译方式。  
ty->ty->ty（左边的箭头就是parsing的箭头，而右边的箭头代表返回值是一个ty）

- > (ty,{,ty})->ty （多参数的ty，返回一个ty）
  
- > ()->ty（没有参数的ty）
  

```
除了我们要加入类型相关的内容以外，我们还需要加入callexpression相关的东西。
```

我们引入了高阶函数后，会有一些比如说。比如说varx=g(y);此时x的类型是一个函  
数；又比如拿函数返回值直接调用一个函数。现在任意的返回值都有可能是一个函数，所以  
现在要把call的返回值从原先的ID调整为一个expression。但是现在把这个条件放太宽了，  
语法这里是可以通过的，具体检查下放到语义分析。

下面有一个例子：变量的名字就是它的意义。  
let  
typeintfun=int->int //参数是int，返回值int的函数类型。  
functionadd(n:int):intfun=//函数作为返回值类型  
letfunctionh(m:int):int=n+m  
inh //返回了h这个函数本身  
end  
varaddFive:intfun:=add( 5 ) //定义了一些intfun的实例  
varaddSeven:intfun:=add( 7 )  
vartwenty:=addFive( 15 ) //使用函数实例真正获得int值，这里是 20  
vartwentyTwo:=addSeven( 15 ) //使用函数实例真正获得int值， 22  
functiontwice(f:intfun):intfun=  
letfunctiong(x:int):int=f(f(x)) //把传入的intfunf调用 2 遍  
ing  
end  
varaddTen:intfun:=twice(addFive) //f(x)=x+ 5 ,f(f(x))=x+ 10  
varseventeen:=twice(add( 5 ))( 7 ) //f(f( 7 ))= 17  
varaddTwentyFor:=twice(twice(add( 6 ))) // f(x)=x+ 6 ,f(f(x))=x+ 12 ,f(f(f(f(x))))=x+ 24  
inaddTwentyFour(seventeen)  
end  
这似乎是把计算之间的中间过程做了一个snapshot存了下来。这个就把之前我们函数  
的表达能力拓宽了。  
这里就讲完了函数基础。

### 闭包（Closure）.............................................................................................................

#### C语言是没有函数嵌套的，不支持这种语法。C语言的好处就是接近底层的东西不需要

有太多的feature，函数指针具体到x 86 上就是一个间接的调用。虽然它有high-orderfunction，  
但是处理起来很简单。但是nestedfunction就比较复杂，childfunction可以在调用完存活，  
所以里面的状态是不能删除掉的。  
比如之前的varaddFive:intfun:=add( 5 )，我们不考虑寄存器传值，把staticlink和 5 都  
放在栈上。然后add做完返回h存到main变量的addFive中。因为调用的时候会直接调用  
函数变量的地址的代码。

关键问题是add退出了，它的栈帧就不复存在了。所以在这个地方有一个问题，h是有  
一个储值 5 的，但是我们现在只有h的代码，这是不足以我们去调用的，因为 5 原本是存在  
add里的，而不是存在h里的。所以 5 不能在add退出时就删掉， 5 应该和h的lifecycle是  
一致的。  
所以我们要引入一个新的机制来存储 5 ，也就是closure。

Closure的定义就包含了functioncode 的pointer以及如何访问non-localvariable（or  
environment）。Closure是一个复杂结构，因为又有code和data。因为data并不在运行时  
栈上。  
它的实现方法有很多种，比如我们在编译的时候有一个全局变量m，在构造的时候把类  
传进去。但在tiger中大家比较熟悉staticlink，所以这里我们还是使用staticlink来做。

首先一个修改是activationrecord我们是放在堆上了。所以Add退出以后，其frame不  
会再被销毁掉。这里有一个问题就是说，栈上的frame通过push和pop就自动回收了，但  
是堆上的frame不会自动回收，我们需要GC去回收它们。  
在上例中heapframe和h的lifecycle一致的。  
如果我们只有一个指针的话，就可以用简单的referencecount，但是如果heapframe中  
还有一些复杂的连接，可能就不太方便。

堆分配frame的缺点就是frame可能比较大，对于一个复杂函数可能要把整个栈帧都放  
到堆上去会导致内存占用变多。我们希望只存放一些necessaryinformation，也就是我们只  
需要存放逃逸变量就可以了。  
为什么是逃逸变量呢？因为下次我们使用函数实例（addFive）的时候，其实我们看h  
本身之外的逃逸变量，所以其实就是staticlink和n。所以我们只需要escapevariable放到堆  
上的frame里去。所以我们栈帧现在分成了两份，一个是原来正常的栈帧，所有的escape  
和staticlink就全部放到堆上去了。我们使用escapepointer（EP）来指向堆上的frame。

在这样一个架构下，Add退出的时候不会影响堆上的结构。因为在调用Add的时候也会  
创建堆上的对应逃逸变量的帧，这个是不会随着add的退出而回收的。

所以看到这就是closure很明显的展示，既指向了代码，也指向了escaperecord。所以  
我们看twice的时候，传入的f本身是escape的变量，我们必须把f保存起来，而f传入的  
是addFive，所以f要执行刚才生成的Closure。这样的话，通过escapepointer和staticlink  
的配合，就可以实现closure方法。当然这部分就不需要大家实现了，但是不排除期末会考  
这样的题目。

```
这个其实就是在staticlink上划分成两部分去做。
```

EP应该是需要一个固定的slot，现在所有和staticlink相关的东西都需要通过EP指向的  
地方去找。EP本身是不escape的，否则会导致死循环。如果EP是固定位置的话，也可以  
通过对EP加减offset来得到栈上的位置。  
这就讲完了closure，它的核心就是code和data，有时候光有代码是不足以执行的，我  
们把数据和代码放在一起变成一个更大的抽象就是closure。  
这就讲完了Fun-Tiger，它是一个非常minimize的函数式语言。

### PureFun-Tiger..................................................................................................................

如果我们想实现equationalreasoning，Fun-Tiger是不够的。因为如果在Fun-Tiger的高  
阶函数中修改了escape变量，那么就可能导致side-effect。  
所以纯函数语言要求在可观测的范围内，我们不能修改函数的状态。这种状态就做不可  
变形。  
Scala是基于JVM的函数式语言，第一节课讲的就是不可变型。

### ImmutableVariables（不可变形）...............................................................................

要实现纯函数语言，除初始化以外不能给变量赋值；不能给堆分配的record赋值。  
最后一个问题是比较tricky的问题，externalfunction不能有可见的影响，比如print,flush,  
getchar,exit等。函数式希望的是getchar()不管被怎么调用都是一样的值，但是getchar()每次  
返回的都是用户输入的新的值，所以函数式也要解决externalfunction的side-effect。  
其实就是返回值会变的情况，我们返回void即可，来避免可见的side-effect。  
不能对新的变量赋值，我们只能使用copy-on-write。  
例子：二叉搜索树

在函数式中，我们一个enter修改了 4 个节点，开销还是比较高的。

### Continuation-basedI/O..................................................................................................

所以对于变量和堆上的record的不能赋值的限制，我们可以通过重构来做，那么对外  
部函数的调用怎么办呢？  
尤其是IO相关的外部函数去做函数式是比较麻烦的。解决方法就是：continuation-based  
I/O.  
continuation就是把一个程序的控制流（controlstate）用一个抽象的方式封装起来了。  
它有点像进程、线程中的上下文的概念。有人把它比喻成时空穿越的一个点，我们在某一个  
时空的状态下把状态保存下来，之后我们可以切换回去继续执行。

比如我们原本在这个状态执行，我们把这个状态用一个cont记录下来，继续执行下去，  
之后我们可以通过一个方法（如协程中的yield）跳转回去再执行一次。在functional中，限  
制比较多，回去的状态还是原来的状态。  
在我们这里continuation怎么用呢？其实我们就是生成一个固定的return，我们之前可  
能用的是void，但是void不是一个很好的returnvalue，我们这里就用了answer。它也没有  
什么特定的意义，就是用来做特定返回值的类型。这样我们的函数就永远返回一个值了，这  
样我们就把side-effect去掉了。因为我们返回的可见的值永远就是相同的值了。  
那对我们Pure-Functiger呢，我们需要加一个answer类型，我们就可以理解为之前的  
void，没什么特殊的含义。

#### 它只是表示了程序的返回值，无论什么时候调用这些函数，返回值都是一样的。

除了answer还有一个很重要的consumer类型，它是来消费input的。所以consumer  
它是一个函数，传入参数类型是string，返回类型为answer，把处理input的逻辑包到这个  
函数里，然后传递给getchar去处理。  
所以现在的getchar就像一个工具人一样，它受命去调用这个函数，调用完返回answer  
就可以了，至于参数怎么存、怎么传都是stringConsumer自己决定的。因为我们规定是函数  
没有状态，而不是传入的参数没有状态，所以它把函数里可能有的东西都丢给了参数去做，  
这样函数保证了自己是无状态的，可以通过让参数去做这些事情。  
所以当我们发现有些逻辑不能实现完全的函数式的话，我们就把它包成参数传进来，作  
为函数外部的一部分来处理。  
当然还有一个是continuation类型，也就是我们调用一下返回一个answer。它就是来生  
成returnvalue的。  
print现在也是会输出一个string，输出完以后调用一下cont类型返回一个answer。exit  
其实最简单，我们不做什么事情直接返回answer就行了。

#### 这里我们就来讲一个比较复杂的例子：

首先我们传入的是int，所以有一个intConsumer传入int返回answer。然后有两个IO  
相关的函数getInt和putInt。  
首先是getInt，它里面声明了nextDigit是拿下一个digit。而nextDigit声明了eatChar，  
里面调用了getchar。eatChar就是声明了一个digit，返回要么是nextDigit，要么是done。done  
就代表读到了非数字的字符，我们就进到loop中去执行。

在loop中，如果i超过了 12 ，那么就会调用exit()退出，否则就会调用putInt。而putInt  
是接受next这个continuation。nextcontinuation会不断地往里传。首先putInt的任务是输  
出这个传入的integer，如果i= 0 ，它就会调用contination，它就去继续做左边的getInt去了，

否则它就要去print这个字符。它继续把i分解成更小的数字，然后用doDigit作为continuation  
继续往下递归去putInt。

```
我们假设最开始的传入是putInt( 24 ,getInt(loop))的情况：
```

```
图 1 输入i= 24 的控制流
```

这个程序不断地getint和putint，原因它用continuation把print给串了起来。通过  
continuation的连续调用直接输出了。所以我们可以认为continuation是把控制流保存起来  
了。可以看到这个已经像是函数调用的一个关系了。这样一个continuation表示的东西就是  
先要调用print输出 2 ，再调用print输出 4 ，最后调用getInt。并且这个continuation还可以  
不执行，等到我们调用的时候再一个个执行。其实就是生成一个函数调用链再执行这个函数  
调用链的过程。  
对于putInt这个函数本身来说，它不产生什么side-effect，每次调用以后都只返回一个  
answer。

### 2021 / 12 / 21

前面讲完copy-on-write和continuation以后，我们就基本上知道了Pure-FunTiger是怎  
么实现的。如果Tiger要实现这个要改什么东西，比如我们要添加上节课提到的answer、  
consumer、continuation类型，包括说我们的一个过程现在返回的是answer。  
最后是assignment、for、while、compoundstatement（seqEXP）要删除。  
assignment比较好理解，它原先是对变量赋值，现在我们只允许对变量的初始化，我们  
就只需要保留let就可以了，forloop是因为我们不能做i++了；而while循环是因为我们在  
循环条件中往往是判断i 是否等于某个值，当我们i不能修改的时候，这个条件只有可能永  
真或永假。要实现循环，我们需要通过递归的形式去实现。而在compoundstatement中，

#### 我们说前面是一个赋值语句，后面可以加分号。这个也可以被删掉。

从语言上来说，pure-funtiger相对于tiger修改的不是特别多。因为高阶函数对tiger修  
改是比较多的，而equationalreasoning更多的影响是内部的，而不是外部的。所以整体语言  
变化不是很大，很多优化方法，比如寄存器分配算法，还是可以正常使用的。  
当我们写pure-fun的时候，控制流会复杂很多，原先只传变量，现在我们可以传function  
call进来。  
引入函数变量了以后，我们就很难知道函数的信息，可能就只能做一些保守的优化了。

#### 好处的话扩大了常数传播的范围，因为这些值都是常数。

### inlineexpansion..............................................................................................................

```
我们就主要讲一下，怎么去优化pure-funtiger。我们直接看如下的一个例子：
```

这个函数就是对于一个list，对于其中的每个元素，我们都输出元素和元素 \* 2 。如果  
我们用imperativestyle来写，我们只需要一个for循环就可以了。但是函数式里面没有循环，

所以我们用的都是递归的方式来做了，比如我们的doList。导致控制流比较混乱，功能也被  
分散到了各个函数去做。

我们先讲内联的思路先做一层优化。不知道大家有没有听说过这个词，也就是把函数体  
直接嵌入到我们调用的地方。

比如说函数f调用函数g的时候，我们直接把g的body里的内容放到f调用g的位置，  
这样就没有call这个动作了。比如说c和c++中可以添加inline关键字，让编译器帮我们优  
化。  
好处就是call被去掉了，省掉了一次call-return的开销。通过这个优化我们就可以接近  
imperative的性能。  
这里要注意的一点就是variable的capture。也就是可能出现外面函数变量和里面函数  
变量名字一样的问题。

#### 在做内联的时候，其实我们不会再回去检查这件事情了，所以这就会出现不同命名体系

#### 的冲突。一种方法就是重新命名冲突的参数，还有一种方法更旁边一些，我们可以在IR翻

#### 译的时候给每个变量翻译成不同的名字。

所以我们其实就把functionbody中的变量替换掉即可。如果实参是一套expression的话，  
我们也可以定义出一套常数，每个值为expression算出来的结果替换掉它们。  
rewrite的坏处就是我们最好在AST层去做。我们就要先加一个parse把变量名字去掉。

我们只需要在函数体里把j+j换成i+i就行了。

如果我们函数有副作用，可能就会使结果不一样。所以在imperative中不一定能做这样  
的优化，但是在functional中是可以这样做的。

一旦inline这个函数了，没有人在使用它了，我们就可以把它删掉，从而减少我们汇编  
的长度。

#### 递归函数可能就复杂一点。

简单来说就是展开一层，把doList的逻辑全部放到printTable中来。但是我们没有办法  
做functionelimination。这样doRest就被重复地声明了，所以这里的内联只减少了一次调用。  
后面的doRest的调用还是走的原本的doList函数，所以我们希望可以内联的更多。  
这里也提供了一个办法，就是把函数做了一个简单的转换。

```
简单来说就是把这个函数分成nested的两个函数。
```

变换之后的doListX其实就是变化之前的doList。

这样以后我们再去inline就容易了。这样我们就把整个doList全都inline进来了。

我们还发现doListX一直在调用printDouble，一直在doListX里传递这个f。

我们是否能让printDouble也不要传来传去，因为传递参数也是有开销的。参数如果放  
栈上就更麻烦了，要压栈。这就是loop-invariantargument。

在ICS中，我们有提到过for(inti= 0 ;i<strlen(s);i++)，这个strlen会成为一个性能瓶颈，  
我们需要提取到外面来。这里的话，编译器也是可以做这种优化的，我们知道每次调用都是  
一样的结果，我们就可以把它往外移。因为在函数式中我们没有循环了，所以这里的循环不  
变量其实就是递归不变量。

所以就有hoisting操作，也就是可以把内部参数往外拉，这样f’就少一个参数。

#### 这样我们的内联就可以更近一步。在我们内联之后就不用传递重复的信息了。

每次inline之后，我们可能会找到更多的优化机会。之前的情况里，doListX里调用的是  
f，我们没办法做进一步的优化。现在我们有了loop-invarienthoisting了以后，我们发现中间  
永远调用的是printDouble。我们就可以进一步内联展开。

```
putInt也可以继续inline，随着这个inline，函数体会越来越大，但是call的次数会少了。
```

### UnnestingLet..................................................................................................................

```
最后一个优化点是let。在我们不断优化过后，可能有一系列嵌套的let。
```

#### 我们简单做一个优化。

```
好处就是把scope减少了，现在我们可以把它们放到一个scope里去。
```

最后再介绍一下inlineexpansion的tradeoff，它的核心目的是优化性能，第二个目的是  
减少编译出来的代码大小。如果我们无休止地进行内联的话，我们的代码量可能迅速增长。  
那么怎么去控制这件事情呢？这边提供了几种方法。

哪些频繁执行，哪些就内联。静态分析有可能也能分析frequency，也就是数一数一个  
函数被多少函数调用，但是这个可能不太精准。  
第二种主要就是静态的，比如getter/setter这种简单函数就很容易被优化掉。

#### 如果一个函数只被调用一次，那么我们就可以把它消除掉，可以让我们的程序更加简洁。

### ClosureConversion..........................................................................................................

```
之后就是讲closureconversion。
```

```
高阶函数就需要closure提供环境信息使用。closure就会比一般的函数要复杂。
```

#### 原则就是我们尽量不想要有堆上的变量访问，而是把它们作为参数的访问。

所以rewritingrule如上图所示，首先non-escaping的变量不需要变，我们去定义一个record，  
成员包含了SL和其余的逃离变量。在定义了这个之后再去调用原本的body。之后我们所有  
对于escape的调用就不需要从堆上找了，我们直接访问这个record即可。当我们想要找更  
早嵌套层次中所定义的变量的时候，我们就可以从a 0 中去访问。

如果参数里有函数呢？这些函数可能也是closure，我们不需要太担心，因为rewrite是  
对所有函数做rewrite，所以函数都有escaperecord。

```
这些函数因为有escape变量，我们都要做成closure，就会复杂很多。
```

因为c是一个continuation类型，是一个函数，所以我们要拆分成cFunc和cSL，把它的  
escapevariable都放到cSL里去。下一个我们就可以注意staticlink，每一个函数进来的时候，  
第一个参数就是存了staticlink的record。

```
最后我们来讲一下type，它是根据rewrite的结果来定的。cSL这里为什么是一个问号
```

呢？因为staticlink不能用常规的typechecking来考虑了。

```
因为exit里我们知道没有什么内容，它可能对应的就是没什么内容的一个类型。
```

这样closureconversion就讲完了，更多的就是我们不希望用堆上分配，而是函数内空间  
的内容来处理，这样便于我们优化。

### EfficientTailConversion..................................................................................................

#### 接下来我们讲尾调用消除。

一个函数f(x)在g(y)return之前做的最后一件事情，那么f就是g的tailcall。而C 1 和C 2  
都不是，最后一件事情是把它们加起来。

tailcall的特性和别的call不太一样。也就是尾递归返回的时候会有多次returnvalue的  
返回，我们希望少做几次return，把尾递归使用jump一样执行。inline就是把函数体合在一  
起，没有call和没有jump，直接换成新的函数的第一条指令去执行。  
而这里保证了函数的完整性，可以减少一些内存操作。那么怎么实现tailcall呢？它主  
要有两个任务

1. call的时候把控制流给callee
2. 当callee执行完之后，还需要把控制流返回给caller。

#### 如果我们用递归的话，我们就可以这样去做。对于简单函数，也不需要去做

callee-saveregister，只需要jump过去就可以了。

所以即使我们做了内联，还是有很多小函数，其中有很多是tailcall。

我们把它们全部换成jump。

这里给出了一个imperative的实现。

翻译到这一步，我们的性能和imperative的性能就基本上一致了。无非就是我们的record  
是在堆上分配的，会导致性能稍微差一点。

这边就讲完了我们的pure-funtiger。作者花了很多功夫讲纯函数的性能未必不如  
imperative。

### LazyTiger.........................................................................................................................

我们之前追求equationalreasoning，我们是否达到了这个目标呢？我们对IO也做了  
continuation，没有side-effect。但是我们没有完全成功，这里提供了一个场景。

#### 左边导致死循环，但是它们函数体不一样，而右边不会导致死循环。这里的问题就是，

#### 左边因为我们的函数调用值总是在进去之前就算出来了，右边因为我们展开了，我们是先执

行了f，而是再执行了loop。

#### 我们要引入延迟计算：如果没有人使用这个值的话，我们就不去计算它。满足这样这个

条件的就是lazylanguage。我们在做deeplearning的时候也会很常用这种方法，比如矩阵的  
一系列算子丢给编译器分析一下，它就会输出一个执行顺序。

首先我们平时用的strictlanguage，通常使用call-by-value来传递参数。也就是在计算  
f(g(x))时，哪怕f没有使用这个参数，也会先计算g(x)。

而在函数式中，通常是使用call-by-name的，它就是把变量变成一个thunk。thunk没有  
什么实际的值，其实就是一个名字摆在这里。如果对int声明thunk的话，那么我们得到的  
就是()->int。这样我们就可以把原先的变量定义成一个函数。这样就不是一个直接计算了，  
而是到后面调用a()的时候才变成了一个lazy的东西。  
假设我们要在二叉树上做call-by-name，

通过这样一个转换以后确实可以lazy化，可以包含一些没有展开的treenode来减少计  
算。但是一个node可能会被展开很多次。

优化方法就是call-by-need，在用call-by-need的时候，每个thunk只需要被evaluate一  
次，这是一个记忆性的方法，evaluate一次以后就会有一个slot存储结果。

### 2021 / 12 / 24

```
我们还是从call-by-name开始，我们知道之前的是call-by-value。调用一个函数，肯定
```

是先算里面再算invocation。其实我们的所有变量都可以定义为一个函数，返回值为原来的  
类型。

#### 其实在正常语言里也可以理解，

#### 比如说

Let...  
Ina  
End  
我们也可以理解为这是一个没有参数的函数。这里就是把这个东西显式化了，我们这里  
把变量都变成了函数。要显式invoke它才能返回的东西。变成函数之后，它就不再对应内  
存中的一个值了，而是一段代码。所以当我们变成call-by-name，这些变量就多了一层tricky  
的含义。  
之前我们有二叉树的一个key和binding结构，现在我们改成所有的访问都变成了  
call-by-name式的访问。

typekey=string  
typebinding=int  
typetree={key:key,  
binding:binding,  
left:tree,  
right:tree}  
functionlook(t:tree,k:key):binding=  
ifk<t.key  
thenlook(t.left,k)  
elseifk>t.key  
thenlook(t.right,k)  
elset.binding

```
typekey=string
typebinding=int
typetree={key:()->key,
binding:()->binding,
left:()->tree,
right:()->tree}
functionlook(t:()->tree,k:()->key):binding=
ifk()<t().key()
thenlook(t().left,k)
elseifk()>t().key()
thenlook(t().right,k)
elset().binding
```

//call-by-value //call-by-name

所以当我们要做后面的二叉树的查找操作时，我们真的要做比较的时候，比如有些地方  
是不调用的，就是继续把k这个函数传进去了。  
比如t().left这个也是一个lazy的结构，在我们调用它之前是不用展开的。什么时候我  
们真正需要拿到它的值呢？比如我们上述的小于号的地方，我们必须拿到值才可以比大小。  
这时候我们就要调用k()和t().key()。

```
所以我们有 一个call-by-need，也就是只有要被算的时候才会被计算出来。
```

### Call-by-need....................................................................................................................

我们把thunk扩展一下变成memoslot。有ep我们就可以拿到所有的escapeparameter  
和staticlink。因为我们把所有东西都保存再堆上了，并且函数和ep具有相同的生命周期了。  
状态就从unevaluated变成evaluated。每次算完就调用以后就不会再去计算了。  
let  
typeintfun=int->int  
functionadd(n:int):intfun=  
letfunctionh(m:int):int=n+m  
inh  
end  
varaddFive:intFun:=add( 5 )  
vartwenty:=addFive( 15 )  
in...  
end

```
let
typeintfun=int->int
functionadd(n:int):intfun=
letfunctionh(m:int):int=n+m
inh
end
varaddFive:intFun:=add( 5 )
var twenty := intThunk{func=twentyFunc,
memo=EP}
in...
end
```

#### 原先的形式，这个函数我们正常就是

pure-funtiger。这个in里面可能要用到这  
个twenty，比如print或者小于号，这样  
就是通过观察的方法促使它去计算。

```
如果我们要换成lazy-tiger的话，就要把twenty
换成intThunk，它的function就是twentyFunc，
其实就是addFive( 15 )，而emeo是EP。其实
lazy-func的话，这个结构会更复杂，这里简单回
顾一下我们会用到的函数。addFive的EP要包含
```

#### 这个 5 。

#### 改出来的结果就是这样，会比较复杂。

typeintThunk={func:?->int,memo:?}  
typeintfunc={func:(?,intThunk)->int,SL:?} SL/EP  
typeintfuncThunk={func:?->intfunc,memo:?} //这里的类型是比较自由的，所以这里都标  
了问号，比如staticlink可以放一个结构体，里面包含各种各样的逃逸的东西。memo是EP，  
也是可以各种类型。  
//所以我们在做生成的时候不太关心类型检查的事情  
functionevaluatedFunc(th:intThunk):int=th.memo  
functiontwentyFunc(mythunk:intThunk):int=//这个对应的是没有evaluated的，所以要做一  
系列计算。传入的是mythusk，invoke就是传入自己去做invoke。  
letvarEP:=mythunk.memo  
varadd 5 thunk:intfuncThunk:=EP.addFive//通过memo去拿addFive这个函数。因为这  
个函数在里面没有体现，所以它会被放到escaperecord里去。  
varadd 5 :intfunc:=add 5 thunk.func(add 5 thunk) //传入的参数就是自己，都是以  
t.func(t)的形式。  
varfifteenThunk:=intThunk{func=evaluatedFunc,memo= 15 }  
varresult:int:=add 5 .func(add 5 .SL,fifteenThunk)//这里就是真的做了 5 + 15 的计算。  
inmythunk.memo:=result;  
mythunk.func:=evaluatedFunc;  
result  
end  
...  
vartwenty:=intThunk{func=twentyFunc,memo=EP}

我们在做这里面的时候，fifteen\_thunk肯定也是去调用evaluation来得到值。这里就不  
再是一个纯函数的语言了。

所以这里展现的是允许过程中的一个结果，修改了memo和thunk的值来达到记忆化的  
实现。  
一方面我们要引入lazy的东西，让所有东西变得复杂，value不再是value，而下面的实  
现就要不断修改thunk里面的成员，好处就是可以lazy地做这些事情，让我们算过一次以后  
就不用再算了。

我们继续回到可能死循环的例子，因为我们使用了lazy的方法，现在这个loop(y)因为  
没有人观察它（我们永远会走else这条分支），这个loopfunc没有人用，就不会计算它。  
这个地方y因为是有大于号，所以y是必须计算的，因为这个会影响控制流。

### Lazy函数式程序的优化.................................................................................................

我们来看看lazy对优化的影响。  
虽然lazy这个东西被我们弄得很复杂，但是在strictfunctionalprogram（严格函数式程  
序）和imperativeprogram（命令式程序）中使用到的大多数优化方法还是可以使用的，比  
如Loop-based,CSE。  
我们之前得到的结果是pure-fun的优化的最终性能是和imperative差不多的。  
但是lazy-compiler可以做更多的优化，主要是靠equationalreasoning。我们可以简单介  
绍一些这一些优化。（invarianthoisting,dead-coderemoval,deforestation）

这个和我们之前循环的hoisting区别不大。以后g这个函数就不需要再去算h(i)了，这  
里就非常严格地依赖于equationalreasoning。因为我们改变了执行顺序，在strictlanguage  
中可能就hang住了。

#### 另一种方式是证明这个函数是幂等的。

有了equationalreasoning以后，这些就可以很轻易地被消除，因为我们没有调用函数。

它把一个program拆成了很多module，这个例子要做的事情就是生成一个 1 ~ 100 的链  
表，求平方再加起来。square就是对每个元素拿出来调用乘法。  
去森林化的效果就是变成了一个比较紧凑的函数。

#### 总的来说，我们就把之前的函数合在一起了，我们可以认为这是某种程度的内联，但是

#### 合成的能力比我们之前的内联强很多。

#### 现在是乘一下加一下，它本质没有减少计算，但是它把函数的执行顺序改变了。

#### 我们介绍了函数式优化的方法和实现的方法，而面向对象开始就大家更加熟悉一点。原

先的面向过程的tiger要变成面向对象的tiger的差别还是挺大的。

也就是我们需要支持class，private/public，namespace等。当然method本身可能也分  
private和public。我们来看一个object-tiger的例子，其实在面向对象中一个比较重要的例子  
如下：

在tiger没有支持分开编译的事情，比如java中就需要指定包名。这里讲的是一个交通  
工具的例子，交通工具有一个position和move函数。下面我们就定义了子类Car和Truck，  
而Car还有passenger和await。我们接下来就可以通过new关键字来做。我们也可以定义  
向父类的转换。而Object是一个predefined的类型，是所有面向对象类型的父类，也称为  
Top，在别的语言中一个Bottom的概念，它是所有类型的子类，也就是Exception的情况。  
OO-tiger中没有构造函数，我们认为执行的所有函数就是它的构造器。注意这里的石油  
东西都是public的，所有东西都可以直接拿来使用。

上面稍微介绍了一下很像java的语法，其实description加了是比较多的。类型的定义，  
我们需要全部改掉，现在的所有的类型都必须以类型的方式来定义。类型必须是class  
description。

在expression中，我们现在的左值是一个对象，我们就可以增加new一个变量。相对  
于函数式，面向对象这里要修改的会比较多一点。  
self不在AST里去做，也不会识别一个keyword，只会识别为一个正常的token，它被处  
理为一个隐式的参数，在运行时自动地绑定到对象上去。如果我们处理的是一个对象，它对  
应一个temporary，那么self会自动和它绑定在一起。这更多地是一个runtime时候的事情。

```
认为就是传入的时候标志了一个self进来。编译的时候会被转化为move(c, 60 );
不同语言里的设计会不太一样c和c++还有java就是作为一个hiddenparameter来传的，
```

因为我们在调用的时候并不会传入self。

比如chainedcall，在做比较复杂的赋值的时候就会做这种复杂的调用。\*this就能够直  
接返回这个对象。  
在python里，这个self对象就不再是隐式的了。

```
我们一定是要定义函数的时候第一个参数设置为self对象。
```

#### 前面是语法介绍，我们来讲一下OO中比较重要的继承。

### 单一继承.........................................................................................................................

单一继承就是每个对象有一个父类。Java和c#，还有Swift等，这些语言都是单一继承  
的。我们继承的效果，一方面是field，一方面是method。

#### 直接从父类获取字段，子类还会有新的字段，那么怎么排序呢？我们只需要往后放就行

了。在GC中，我们需要判断record里哪些存放的指针。Descriptor中包含了类型信息、字  
段有哪些、方法有哪些。这是我们面向对象的结构。继承来的field会被放到最前面，按照  
辈分顺序来放置field。

我们只需要沿着这个继承顺序来走，就可以得到field的顺序了。  
方法也类似，但是方法有一个不一样的地方是方法可以override。如果名字一样，  
参数传入一样，那就直接override。

在c++中如果field中重复定义了，就会被定义为两个字段，而方法这里就需要被重载。  
在c++中descriptor是通过虚表来做的。

我们就以继承关系来看。B继承了A，而它自己声明了一个B\_g，而C继承了B，重载  
了新的g，所以用C\_g来覆盖B\_g。这里基本思路就是有新的我们就继续往下扩展，如果有  
重载我们就在原地重载。来做相同位置的函数替换。这样就可以使我们的虚表的扩展比较简  
单。  
其实大家的位置是一样的，所以动态的methodlookup不会很复杂。比如我们要callC.f()，  
我们从C的object拿到这个C对应的descriptor，然后我们要拿到A\_f的pointer，那么就从  
offset= 0 这个地方去拿。  
这个tablelookup也没有很费时间，总共也就 2 次额外的访问内存操作。

#### 这是单一继承，比较容易。

### 多重继承.........................................................................................................................

C++，Purl，Python等支持多重继承。复杂就复杂在A继承于B和C的话，刚才我们是  
线性的顺序，那到底把B和C的field哪个放在前面呢，这就需要讨论了。

### 2021 / 12 / 28

#### 我们今天继续讲面向对象的语言。先复习一下上节课讲的单一继承。

单一继承都是线性往下扩增的，一定是可以排出一个顺序的。我们通过一个固定的offset  
就可以拿到这个函数和field。  
而这节课讲到的多重继承就会复杂一点，因为这种线性序就不成立。没有多重继承的语  
言也有对应的feature来实现类似的功能。多重继承会导致layout不能在进行简单的排列。

我们可以强行让D的field按照某个顺序排列，但是我们会发现：  
Cc=newD()  
c.d  
当我们想把D强制转化为C去访问的时候，C.d和D.d的offset是不相同的。而我们在  
静态的时候又判断不了这个类型，就对我们编译产生了麻烦。

### GlobalGraphColoring.....................................................................................................

为了解决这个问题，就提出了图染色问题。如果不同field在同一个类型里出现了，那  
么它们就不能染成同一个颜色。也就是不同的field不能放在同一个位置。  
所以这个图染色问题的顶点是不同的类型名，而边是两个field共存在同一个类中了。  
我们举个例子：

classAextendsObject{vara:= 0 }  
classBextendsObject{varb:= 0 ;varc:= 0 }  
classCextendsA{vard:= 0 }  
classDextendsA,B,C{vare:= 0 }

#### 最终我们发现构成了一个完全图，我们就可以直接对它做染色并编号。

我们得到的这个layout符合我们对于单一继承的假设。比如说C、D类型的d一定在第  
四个位置。但是后果就是我们会有一些空的offset在这个地方，会造成一些浪费，可能造成  
比较大的内存压力。对于更加复杂的类型继承，可能会更麻烦。

我们通过类型的固定位置拿到d，然后再去对象中拿紧凑表达的序号。为什么要这样做  
呢？因为类型的数量通常是认为小于对象的数量的。所以我们在类型里面浪费一些内存影响  
没有这么大。

这里的问题就是说，本来的对象可以直接lookup，但是现在我们每次都要做一次间接的  
访问到classdescriptor才可以访问到field。

步骤：  
·从field的offset= 0 处拿到类型的descriptor。  
·从类型descriptor中，找到我们想访问的field的offset。

·再拿着这个offset去访问对象。

对于对象中的方法，我们也是放到图中去做染色，不过方法会放到类型里面，所以也不  
需要在对象里去存方法的信息。

我们拿到方法信息以后不用再去data中去会查了，我们可以直接拿到代码的位置直接  
去执行了。

#### 之前考虑的都是静态方法和字段的情况。我们有一个链接器，把这些都连接起来。比如

c++的话就用g++编译起来然后用一个linker自动链接起来。我们的要求是，类型信息在编译  
的时候都知道，因为如果我们不知道类型消息，我们是不能做这个图的染色的。所以都是编  
译器和链接器去完成的，没有什么动态的东西，运行的时候就直接用这样的偏移量就可以了。  
通常现在的OO语言都会有运行时，支持动态加载的。以java为例，比如我们从网上下  
载一个jar包，运行的时候可以加载一些jar包进来。因为我们可能有一个超大的jar包，这  
样我们就可以不需要一开始就全部把类型加载进来。坏处就是我们不能用之前的静态方法  
了，因为很多类型信息是此时我们不知道的。

#### 这样我们就用了一个哈希的表达方法，不再遵循之前的规律。我们给每个类型放一个哈

希表，分为key-table（放field的名字）和field-table（放field的offset）。这种情况下，不  
管单一继承和多重继承都是适用的，来了以后我们无非就是哈希查表即可。

#### 我们进来以后无脑查表即可。

#### 这四条指令的粒度是非常粗的，里面可能有一些非常耗时的指令，比如哈希计算。所以

这肯定不是几个cycle能结束的事情。判断string是否相等又是一个O(N)判断，更不用说hash  
的entry可能有冲突，又要做冲突处理。所以哈希这个数据结构可能比较简单，几十行就能  
实现，但是会有很多问题。

1. bucket分布不均匀，有的链可能很长，这就不能控制访问时间。
2. 闭哈希不够的情况下，我们可能就要resize。哈希表使用的slot的数量并没有到 100 %  
    但是不能继续插入了。

多重继承可能会有二义性，如上图所示。B和C把f方法重载掉，那么D直接调用f的  
话，应该调用谁的实现呢？多重继承本身并不提供解决方案。

interface就是一个抽象类，认为里面不应该有具体的component，通常情况下我们只定  
义一些方法类。  
Comparable就是一个很常见的interface，它里面可能就定义了boolcmp(Comparableb);

如果interface中出现了多重继承的话，B和C中只有两个对方法的定义，所以不会有冲  
突的问题。interface就解决了diamondproblem。

#### 多重继承给语言更多的灵活性，但是也在正常的字段访问和方法访问中加了更多的复杂

#### 性和额外开销。

### MembershipTesting........................................................................................................

类型检查，也包括了子类检查。这比我们之前的一对一的typecheck要复杂一些。因为  
有subtype的话，我们要做更多的一些比较。

我们先来讲一下类型转换的事情。在C里面很常见的事情就是和void\*之间的相互类型  
转换。首先我们要讲转换成一个supertype是永远安全的。但是子类就不一定安全了，因为  
父类的定义可能是不全的，一些新方法和新字段父类可能没有。所以我们希望upcast是可  
以做的，并且避免不正确的downcast。

很多语言会加上typetesting来帮助程序员判断对象的类型。很多OO语言支持这个  
feature。  
一个简单的方法就是我们拿到对象的classdescriptor。如果不相等，我们在拿对象的超  
类去判断。

#### 如果是多重继承，那就是一个带递归/广度优先搜索的向上遍历问题。这里的问题就是

#### 递归式的比较久。

```
一个简化的方法是通过display来实现的。
```

利用的思路就是说D的display一定是长这样的。如果是D的子类，一定是在D下面的。  
通过类型系统的这个排列，我们通过正向的去找就可以加速了。

这个其实就是把我们熟悉的语法扩展，扩展到可以接收任意的expression，然后根据类  
型判断来分别处理。

module可能是隔离编译的，这样就不容易去做。并且继承的时候是分成两个关系的，  
不同类id不同，但是父类应该是可以和子类匹配上的。所以typecase并不容易用jumptable  
实现。其实typecase就是一个语法糖，就是把一些if-else编制在一起。

scala就集成了caseclass。判断一下是不是Student类型，如果是的话就把id拿出来。  
然后scala里定义class的方式其实和数据库中的表的方式是差不多的，所以就有人把scala  
语言应用到数据库里。

c++有一些要兼容C的考量，和一些feature的考量。比如static\_cast就是类型直接转换，  
编译器假设我们是知道我们在做什么的。也就是我们认为void\*是所有类的超类。

```
dynamic_cast就会帮助我们判断类型，通过检查以后我们非常确定就是这个类型。
```

#### 还支持一些强制转换的函数。

```
真实的数据我们可以通过private隐藏起来，对外暴露一些函数。
```

不同语言对于private的含义是有分歧的。比如认为只有自己这个类能访问，子类能不  
能访问引入了protected。还有可能是同一个module都可以访问到这个变量。  
java可以通过一个紧密的方式把数据放在一起，这样就会比很多间接引用的访问比较  
快。

#### 每个对象想定义什么语言就定义什么语言，所以它就是动态类型的。

#### 每个对象隐含了类型信息，我们把它叫做“伪类”。如果我们想复用一些函数，我们可

以对对象copy完以后继续添加新的方法。

要进一步发展要解决软件工程问题，老是动态做的话很容易出bug。所以现在有  
typescript，让类型往静态方向调整。

### 2021 / 12 / 31

上节课我们提到了TypeScript。可以看到它的官网的卖点就是Scale和Safety。它给的例  
子里面，第一个也是检查出来错误的一个情况。所以这个语言本身就是给大家一个更加安全  
的js的状态，这也反映出来的了动态类型的一些问题。加了这些类型以后，我们就可以把  
很多错误暴露在编译器，对于整个开发流程有好处。  
compiler怎么编译classless呢？这个过程和我们之前讲的动态链接和多重继承的哈希表  
比较像。因为我们的类型信息都是动态生成的，我们可以动态扩展一个类的成员和方法。编  
译器很难判断有什么类型，最好就是弄一个哈希表各管各的，尽可能少地考虑继承的问题。  
当然一些全局的优化也是可以做的。  
我们知道js是runtime的语言，和Java有点相似的地方，比如说它们都有一个runtime，  
js这里用的是v 8 引擎，也有垃圾回收和动态编译，所以说全局的分析和优化也可以用在js

#### 的编译优化上。

### De-virtualizing.................................................................................................................

```
这边我们简单讲一下面向对象的优化，一个比较重要的优化就是De-vitualizing
```

#### 这是之前我们讲单一继承、多重继承、动态链接的情况都会有虚函数的，这是面向对象

#### 带来的。有了多态之后，虚函数就很普遍了。有了超类以后，我们重载虚函数去实现。所以

去虚函数就是优化中很重要的一点，我们找一个virtualfunction是相对费时间的，就算是单  
一继承，我们也需要找虚表找到对应的方法，需要 2 次memory的访存。坏处就是我们不能  
提前预测要往哪里跳。  
常规的jump是直接把地址写在后面的，如jump 0 x 123456 。这是非常好的，因为我们  
在跳转之前就可以把这个地址prefetch到我们的cache中里。但是对于我们现在这个情况，  
我们是jump到一个memory对应的地方，比如%rax，我们就不能做预测。我们知道在我们  
的y 86 上没有这种情况，因为我们在jump的时候清楚地知道我们的label在哪里，但是对于  
indirectjump的话，我们知道流水线是先判断再访存。现在访存都不知道在哪，我们怎么jump  
呢？  
所以这件事情对于流水线不太友好，对于多重继承和classless就更复杂了。我们讲了几  
种方法。一种方法是图染色，我们先往下去找，得到offset，拿到offset之后再去拿。哈希  
表更复杂一些，因为哈希的查找开销会更高，所以我们还是希望没有虚函数找虚表的这个过  
程。

怎么做de-virtualize呢？我们假设方法调用都是知道的，我们可以做一个程序的全局分  
析，把代码扫一遍。在做全局分析的过程中，我们会知道每一个调用虚函数的地方，都会分  
析它类型的hierarchy。

#### 举个例子来说，如下的C++代码：

Aa();  
a.method();  
我们肯定知道a是一个A类型，那么这里的method一定是A类中的method。如果A  
类没有自己定义，那么就是父类B里的method。这种是最简单的情况。

```
第一个rule：全局只有一个这个方法的实现，那么我们可以直接invoke来做de-virtualize。
```

第二个rule：就是newC的话，调用的c.method一定是C类的方法。我们就可以把 jump  
\*rax替换为一个jumplabel。

第三种就是有trade-off的方法，也就是继承的时候把的方法都copy一份。这样调用的  
时候，每个类都可以走自己的位置。

最后一个是有假设的优化，可能可以用在更加动态的语言中。因为dynamic的环境中，  
我们可以动态加载一些类型进来。我们的优化是基于已经加载的类来做的，我们可以做一些  
投机的优化，后面如果出现invariant不一样了，后面再做去优化的过程。也就是我们现在  
创建了原先的slowpath和基于某个假设做的fastpath的优化，当我们加载新的类进来导致  
我们优化所假设的条件不成立了以后，我们再从fastpath降级到slowpath去做。这种在动  
态语言里比较常见，比如java、python、js的解释器就可以认为是保守的slowpath。  
比如我们有一个类C，有一个方法f。D没有对Coverride，而E对f做了override，但  
是我们从来没有定义过和E相关的变量。此时我们整个f只有一个C的定义，在这样的一个  
类型系统下，我们可以对f做de-virtualize，因为满足rule 1 ，可以认为是没有overriden的  
情况，这样就可以直接调用f，不做look-up。  
但是我们一旦加载了E，会对我们整个结构产生影响，因为E会外挂一个自己对f的定  
义，此时我们对f的rule 1 假设就不符合了，我们就要回到原先的loop-up的情况。

在Java中，它同时存在两套代码，分别通过解释器和即时编译执行。而我们的runtime  
code中会有一个switch机制，一旦假设不符合的情况下，我们就切换回slowpath的  
interpreter的情况。

#### 坏处就是代码有两份，有时候JVM的内存占用可能是因为我们编译的代码太多了。这

就是动态语言的好处，是基于动态的profile的优化，更加aggressive的一个方法。

### MoreC++.........................................................................................................................

#### 前面就讲完了书上的面向对象部分，最后我们来讲一下C++的部分。

#### 对于C++ 98 来说，是和C差不多的。内存都是程序员自己来管。简单的比较好做，因

为我们有构造器和析构器。比如我们在A()构造器中有new的话，那么就在~A()析构器中就  
delete即可。  
复杂一点的程序是很难管理的。这也是为什么JAVA受欢迎的原因，因为JAVA有GC，  
很少有memoryleak的情况。

因为C++的特性，所以经常出现（甚至在内核代码中）都会有use-after-free，double-free，  
memoryleak这种bug。能不能给C++加GC呢？我们看了lab 7 ，tiger纯静态编译也可以加一  
个GC进去，所以这也不是完全不可能。

#### 对于C++来说，因为它本身有虚表这种东西，我们可以改虚表的格式。包括说

root-detection这种事情，在call的时候可以加一个bitmap来做。barrier是说在GC中需要  
有一些不变量来执行并行/增量垃圾回收。tiggering可以让allocator来主动触发垃圾回收。  
C++之父说：也不是不可以，但是怎么和以前的feature兼容是比较麻烦的。另一个角度，c++  
和c更像，更加注重efficiency。GC是有性能损耗的。

### RAII（ResourceAcquisitionisInitialization）................................................................

c++也不是完全没有提内存管理的方法，比如RAII，它是一种泛化的思想，并不局限于  
内存管理。它现在是一种STL的方式来辅助使用，并不强制我们使用。

#### RAII不是一个具体的实现，更像是一个方法论和思想，如果我们使用它的话，会让我们

编程的鲁棒性更好。没有人强制c++中不能使用mallocfree等。  
RAII其实就是resourceacquisitionisinitialization的简称。在面向对象中，万物皆对象，  
比如文件在C++中也可以认为是一个对象，平时我们用的网络、硬盘、内存都可以抽象成对  
象，有这么一个概念之后，我们在初始化对象的时候，我们做的就是resourceacquisition，  
我们把资源和对象绑定在一起了，它们的生命周期应当是一样的。当我们object释放的时候，  
我们也同时释放资源。  
上面的代码用了c-style，所以RAII并不局限于面向对象和C++。打开以后，我们的  
file\_handle就对应了文件的使用。

当我们函数退出的时候，f自然释放，c++runtime会帮我们调用destructor。这样就实  
现了一个自然的资源管理。这样就比我们写new和delete要简单一些。我们把资源管理很  
自然地对应到了程序对象的生命周期。

#### 上面就是一个把锁认为是资源的例子。下学期讲OS的时候，我们还可以把锁认为是访

问变量的一个权限token。我们拿到锁才能有访问某个变量的能力。  
通常锁就是lock和unlock，但是问题就是说拿锁放锁容易写错。如上例所示忘记放锁  
的情况。

解决方法就是加了对锁的引用，lk把拿锁和放锁封装起来了。lk初始化的函数就是拿锁  
了，而离开scope的时候，析构器就会自然放锁。这样就把pair放到了变量里去，把pair  
function的问题隐藏掉了。

```
这里可以清楚地看到_MyMutex的构造的时候就是加锁，而析构的时候就是放锁。
任意的资源都可以这样管，我们在C++ 98 的时候也可以这样去写。
```

讲了这些以后，我们回到smartpointer上。因为动态分配的内存是不知道什么时候恢复  
的，我们也用RAII这个思路就得到了智能指针这件事情。当我们acquire的时候，就分配一  
块内存，而析构的时候就把对象回收。

```
uniquepointer就暗示了pointer的独有性，它会被一个对象独占。
```

CPU的owner就是当前在运行的程序，而在unique\_ptr的owner就是拥有pointer的那  
个人。move就是把ownership转移给别人。

```
unique_ptr就三个东西：创建、move和decontruct。
```

```
STLdelete可以被继承，去做一个真正的delete工作。
```

C++讲完了，我们稍微看一下Rust。C++是有library来实现的，没有一个强制性去要求  
share\_pointer。而rust就做了很多的enforcement，要求一定要按照这个语言要求去实现，

#### 因为它的编译器检查非常严格，希望把很多问题暴露在编译器。方法是类似的。

我们来看一下这个例子，let就是一个赋值。String::from可以认为是一个字符串常量  
hello。在C++中就会检查copyconstructor，而rust这里就是一个move。move后s 1 就变成  
null了，后面就不能print。  
好处就是一旦我们习惯了rust的思维，通过编译之后基本上很少出错。

其实还有很多feature可以去探索。这些是C++中已经支持的一些feature。RTTI可能就  
是typeid在运行时可以得到类型。C++中有相应的lambda和closure的支持。future允许我  
们定义一个未来返回值的类型，也就是支持异步编程。C++不断在发展出现一些新feature。